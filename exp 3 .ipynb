{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c29959b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow has access to the following devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "\n",
    "# See TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b80360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 10:26:18.443956: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-20 10:26:18.444395: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_10619/4164730389.py:26: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_10619/4164730389.py:248: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_10619/4164730389.py:152: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "2022-04-20 10:26:18.674801: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-20 10:26:18.674823: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-04-20 10:26:18.836650: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-20 10:26:18.837572: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 10:26:18.866124: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 10:26:19.345995: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 5s 13ms/sample - loss: 0.0605\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      " 13/180 [=>............................] - ETA: 2s - loss: 0.0699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 10:26:23.774183: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 10:26:23.782069: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0544\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0513\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0489\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0468\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0450\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0434\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0419\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0404\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0390\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0377\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0365\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0355\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0348\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0342\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0339\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0335\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0332\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0330\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0327\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0325\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0323\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0321\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0318\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0316\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0314\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0312\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0310\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0307\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0305\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0303\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0301\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0300\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0299\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0299\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0299\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0299\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0298\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0298\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0297\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0297\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0296\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0296\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0296\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0296\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0295\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0295\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0295\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0294\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0294\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0294\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0293\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0293\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0293\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0292\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0292\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0291\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0291\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0290\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0290\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0289\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0289\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0289\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0288\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0288\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0287\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0287\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0286\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0286\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0285\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0285\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0284\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0284\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0283\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0283\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0282\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0282\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0281\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0281\n",
      "Epoch: 79\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0280\n",
      "Epoch: 80\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0279\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0279\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0278\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0278\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0277\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0277\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0276\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0276\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0275\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0275\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0274\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0274\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0273\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0272\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0272\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0271\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0271\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0270\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0270\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0269\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0269\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0268\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0268\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0267\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0266\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0266\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0265\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0265\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0264\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0264\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0263\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0263\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0262\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0262\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0261\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0260\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0260\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0259\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0259\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0258\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0258\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0257\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0257\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0256\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0256\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0255\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0255\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0254\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0254\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0253\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0252\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0252\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0251\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0251\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0250\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0250\n",
      "Epoch: 136\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0249\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0249\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0248\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0248\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0247\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0247\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0246\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0246\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0245\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0245\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0244\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0244\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0243\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0243\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0242\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0242\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0242\n",
      "Epoch: 153\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0241\n",
      "Epoch: 154\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0241\n",
      "Epoch: 155\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0240\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0240\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0240\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0239\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0239\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0239\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0239\n",
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0236\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0236\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0236\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0235\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0235\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0234\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0234\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0233\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0232\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0232\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0231\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0230\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0230\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0229\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0228\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0227\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0227\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0226\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0225\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0224\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0223\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0223\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0220\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0220\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0219\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0218\n",
      "Epoch: 205\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0217\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0215\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0214\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0213\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0212\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0211\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0211\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0210\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0209\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0209\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0208\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0208\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0208\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0207\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0207\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0207\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0207\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0208\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0208\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0208\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0208\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0208\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0209\n",
      "Epoch: 229\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0210\n",
      "Epoch: 230\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0211\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0213\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0217\n",
      "Epoch: 235\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0218\n",
      "Epoch: 236\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0224\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0213\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0223\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0218\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0227\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0210\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0224\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0225\n",
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0215\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0223\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0213\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0225\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0224\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0212\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0363\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0359\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0338\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0320\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0311\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0305\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0300\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0297\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0294\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0292\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0290\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0289\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0288\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0287\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0286\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0285\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0288\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0284\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0283\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0282\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0281\n",
      "Epoch: 273\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0299\n",
      "Epoch: 274\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0281\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0281\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0282\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0281\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0279\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0278\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0277\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0291\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0277\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0276\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0274\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0297\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0277\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0275\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0274\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0273\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0271\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0272\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0272\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0270\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0268\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0283\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0269\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0267\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0264\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0281\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0266\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0265\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0261\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0275\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0263\n",
      "Epoch: 305\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0261\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0260\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0270\n",
      "Epoch: 308\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0259\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0271\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0275\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0269\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0268\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0267\n",
      "Epoch: 314\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0266\n",
      "Epoch: 315\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0266\n",
      "Epoch: 316\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0266\n",
      "Epoch: 317\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0266\n",
      "Epoch: 318\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0265\n",
      "Epoch: 319\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0265\n",
      "Epoch: 320\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0265\n",
      "Epoch: 321\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0265\n",
      "Epoch: 322\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0265\n",
      "Epoch: 323\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0265\n",
      "Epoch: 324\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0265\n",
      "Epoch: 325\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0264\n",
      "Epoch: 326\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0264\n",
      "Epoch: 327\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0264\n",
      "Epoch: 328\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0264\n",
      "Epoch: 329\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0264\n",
      "Epoch: 330\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0264\n",
      "Epoch: 331\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0263\n",
      "Epoch: 332\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0263\n",
      "Epoch: 333\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0263\n",
      "Epoch: 334\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0262\n",
      "Epoch: 335\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0262\n",
      "Epoch: 336\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0261\n",
      "Epoch: 337\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0261\n",
      "Epoch: 338\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0260\n",
      "Epoch: 339\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0259\n",
      "Epoch: 340\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0258\n",
      "Epoch: 341\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0258\n",
      "Epoch: 342\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0257\n",
      "Epoch: 343\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0256\n",
      "Epoch: 344\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0255\n",
      "Epoch: 345\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0253\n",
      "Epoch: 346\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0252\n",
      "Epoch: 347\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0251\n",
      "Epoch: 348\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0250\n",
      "Epoch: 349\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0248\n",
      "Epoch: 350\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0247\n",
      "Epoch: 351\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0246\n",
      "Epoch: 352\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0245\n",
      "Epoch: 353\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0244\n",
      "Epoch: 354\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0243\n",
      "Epoch: 355\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0243\n",
      "Epoch: 356\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0242\n",
      "Epoch: 357\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0241\n",
      "Epoch: 358\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0241\n",
      "Epoch: 359\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0240\n",
      "Epoch: 360\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0240\n",
      "Epoch: 361\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0239\n",
      "Epoch: 362\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0239\n",
      "Epoch: 363\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0239\n",
      "Epoch: 364\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0238\n",
      "Epoch: 365\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 366\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0238\n",
      "Epoch: 367\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 368\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0237\n",
      "Epoch: 369\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 370\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0236\n",
      "Epoch: 371\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0236\n",
      "Epoch: 372\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0236\n",
      "Epoch: 373\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0236\n",
      "Epoch: 374\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0235\n",
      "Epoch: 375\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0235\n",
      "Epoch: 376\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0235\n",
      "Epoch: 377\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0235\n",
      "Epoch: 378\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0234\n",
      "Epoch: 379\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0234\n",
      "Epoch: 380\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0234\n",
      "Epoch: 381\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0234\n",
      "Epoch: 382\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0233\n",
      "Epoch: 383\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0233\n",
      "Epoch: 384\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0233\n",
      "Epoch: 385\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0233\n",
      "Epoch: 386\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0232\n",
      "Epoch: 387\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0232\n",
      "Epoch: 388\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0232\n",
      "Epoch: 389\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0232\n",
      "Epoch: 390\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0231\n",
      "Epoch: 391\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0231\n",
      "Epoch: 392\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0231\n",
      "Epoch: 393\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0231\n",
      "Epoch: 394\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0231\n",
      "Epoch: 395\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0231\n",
      "Epoch: 396\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0231\n",
      "Epoch: 397\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0231\n",
      "Epoch: 398\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0231\n",
      "Epoch: 399\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0231\n",
      "Epoch: 400\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0230\n",
      "Epoch: 401\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0230\n",
      "Epoch: 402\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0230\n",
      "Epoch: 403\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0230\n",
      "Epoch: 404\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0230\n",
      "Epoch: 405\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0230\n",
      "Epoch: 406\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0229\n",
      "Epoch: 407\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0229\n",
      "Epoch: 408\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0229\n",
      "Epoch: 409\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0228\n",
      "Epoch: 410\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0227\n",
      "Epoch: 411\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0226\n",
      "Epoch: 412\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0225\n",
      "Epoch: 413\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0224\n",
      "Epoch: 414\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0224\n",
      "Epoch: 415\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0223\n",
      "Epoch: 416\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0223\n",
      "Epoch: 417\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0223\n",
      "Epoch: 418\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0222\n",
      "Epoch: 419\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0222\n",
      "Epoch: 420\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0222\n",
      "Epoch: 421\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0222\n",
      "Epoch: 422\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0222\n",
      "Epoch: 423\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 424\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 425\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0222\n",
      "Epoch: 426\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 427\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0222\n",
      "Epoch: 428\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0222\n",
      "Epoch: 429\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 430\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 431\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 432\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 433\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0222\n",
      "Epoch: 434\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 435\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 436\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0222\n",
      "Epoch: 437\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 438\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0222\n",
      "Epoch: 439\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0222\n",
      "Epoch: 440\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 441\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 442\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 443\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0222\n",
      "Epoch: 444\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 445\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0222\n",
      "Epoch: 446\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 447\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 448\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 449\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 450\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 451\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 452\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 453\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 454\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 455\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 456\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 457\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 458\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 459\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 460\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 461\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 462\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0220\n",
      "Epoch: 463\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0220\n",
      "Epoch: 464\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0220\n",
      "Epoch: 465\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0220\n",
      "Epoch: 466\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0220\n",
      "Epoch: 467\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0220\n",
      "Epoch: 468\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0220\n",
      "Epoch: 469\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0220\n",
      "Epoch: 470\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0220\n",
      "Epoch: 471\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0220\n",
      "Epoch: 472\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0220\n",
      "Epoch: 473\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 474\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 475\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 476\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 477\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 478\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 479\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 480\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 481\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 482\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 483\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 484\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0218\n",
      "Epoch: 485\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0218\n",
      "Epoch: 486\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0218\n",
      "Epoch: 487\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0218\n",
      "Epoch: 488\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0218\n",
      "Epoch: 489\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0218\n",
      "Epoch: 490\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0218\n",
      "Epoch: 491\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0218\n",
      "Epoch: 492\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0218\n",
      "Epoch: 493\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0218\n",
      "Epoch: 494\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0218\n",
      "Epoch: 495\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0217\n",
      "Epoch: 496\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0217\n",
      "Epoch: 497\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0217\n",
      "Epoch: 498\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0217\n",
      "Epoch: 499\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0217\n",
      "Epoch: 500\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0217\n",
      "Epoch: 501\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0217\n",
      "Epoch: 502\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0217\n",
      "Epoch: 503\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0217\n",
      "Epoch: 504\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0217\n",
      "Epoch: 505\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0216\n",
      "Epoch: 506\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 507\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0216\n",
      "Epoch: 508\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 509\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 510\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 511\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 512\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 513\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 514\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 515\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0215\n",
      "Epoch: 516\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0215\n",
      "Epoch: 517\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0215\n",
      "Epoch: 518\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0215\n",
      "Epoch: 519\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0215\n",
      "Epoch: 520\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0215\n",
      "Epoch: 521\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0215\n",
      "Epoch: 522\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0215\n",
      "Epoch: 523\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0214\n",
      "Epoch: 524\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0214\n",
      "Epoch: 525\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0214\n",
      "Epoch: 526\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0214\n",
      "Epoch: 527\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0214\n",
      "Epoch: 528\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0214\n",
      "Epoch: 529\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0214\n",
      "Epoch: 530\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0213\n",
      "Epoch: 531\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0213\n",
      "Epoch: 532\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0213\n",
      "Epoch: 533\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0213\n",
      "Epoch: 534\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0213\n",
      "Epoch: 535\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0213\n",
      "Epoch: 536\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0212\n",
      "Epoch: 537\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0212\n",
      "Epoch: 538\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0212\n",
      "Epoch: 539\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0212\n",
      "Epoch: 540\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0212\n",
      "Epoch: 541\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0212\n",
      "Epoch: 542\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0211\n",
      "Epoch: 543\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0211\n",
      "Epoch: 544\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0211\n",
      "Epoch: 545\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0211\n",
      "Epoch: 546\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0210\n",
      "Epoch: 547\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0210\n",
      "Epoch: 548\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0210\n",
      "Epoch: 549\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0210\n",
      "Epoch: 550\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0210\n",
      "Epoch: 551\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0209\n",
      "Epoch: 552\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0209\n",
      "Epoch: 553\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0209\n",
      "Epoch: 554\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0209\n",
      "Epoch: 555\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0208\n",
      "Epoch: 556\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0208\n",
      "Epoch: 557\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0208\n",
      "Epoch: 558\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0208\n",
      "Epoch: 559\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0208\n",
      "Epoch: 560\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0207\n",
      "Epoch: 561\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0207\n",
      "Epoch: 562\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0207\n",
      "Epoch: 563\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0207\n",
      "Epoch: 564\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0207\n",
      "Epoch: 565\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0207\n",
      "Epoch: 566\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0206\n",
      "Epoch: 567\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0206\n",
      "Epoch: 568\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0206\n",
      "Epoch: 569\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0206\n",
      "Epoch: 570\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0206\n",
      "Epoch: 571\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0206\n",
      "Epoch: 572\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0205\n",
      "Epoch: 573\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0205\n",
      "Epoch: 574\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0205\n",
      "Epoch: 575\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0205\n",
      "Epoch: 576\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0205\n",
      "Epoch: 577\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0205\n",
      "Epoch: 578\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0205\n",
      "Epoch: 579\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0205\n",
      "Epoch: 580\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0204\n",
      "Epoch: 581\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0204\n",
      "Epoch: 582\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0204\n",
      "Epoch: 583\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0204\n",
      "Epoch: 584\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0204\n",
      "Epoch: 585\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0204\n",
      "Epoch: 586\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0204\n",
      "Epoch: 587\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0204\n",
      "Epoch: 588\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0203\n",
      "Epoch: 589\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0203\n",
      "Epoch: 590\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0203\n",
      "Epoch: 591\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0203\n",
      "Epoch: 592\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0203\n",
      "Epoch: 593\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0203\n",
      "Epoch: 594\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0203\n",
      "Epoch: 595\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0203\n",
      "Epoch: 596\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0203\n",
      "Epoch: 597\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0202\n",
      "Epoch: 598\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 599\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0202\n",
      "Epoch: 600\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0202\n",
      "Epoch: 601\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 602\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 603\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 604\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 605\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 606\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 607\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 608\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 609\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 610\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 611\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 612\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 613\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 614\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 615\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 616\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 617\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 618\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 619\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 620\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 621\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 622\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0201\n",
      "Epoch: 623\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 624\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0201\n",
      "Epoch: 625\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0201\n",
      "Epoch: 626\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 627\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 628\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 629\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 630\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 631\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 632\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 633\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 634\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0200\n",
      "Epoch: 635\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 636\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 637\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0200\n",
      "Epoch: 638\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0200\n",
      "Epoch: 639\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0200\n",
      "Epoch: 640\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0200\n",
      "Epoch: 641\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0200\n",
      "Epoch: 642\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 643\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 644\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 645\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0199\n",
      "Epoch: 646\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 647\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 648\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 649\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 650\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 651\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 652\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 653\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 654\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 655\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 656\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0199\n",
      "Epoch: 657\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0198\n",
      "Epoch: 658\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 659\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 660\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 661\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 662\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 663\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 664\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 665\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 666\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 667\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 668\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 669\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 670\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 671\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 672\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0198\n",
      "Epoch: 673\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 674\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 675\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 676\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 677\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 678\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 679\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 680\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 681\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 682\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 683\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 684\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 685\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 686\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 687\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 688\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 689\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 690\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 691\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 692\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 693\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 694\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 695\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 696\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 697\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 698\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 699\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 700\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 701\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 702\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 703\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 704\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0196\n",
      "Epoch: 705\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0196\n",
      "Epoch: 706\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 707\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 708\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 709\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 710\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 711\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 712\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 713\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 714\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 715\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 716\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 717\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 718\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0194\n",
      "Epoch: 719\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0194\n",
      "Epoch: 720\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0194\n",
      "Epoch: 721\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0194\n",
      "Epoch: 722\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0194\n",
      "Epoch: 723\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0194\n",
      "Epoch: 724\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0194\n",
      "Epoch: 725\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0194\n",
      "Epoch: 726\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0194\n",
      "Epoch: 727\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 728\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 729\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 730\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 731\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 732\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 733\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 734\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 735\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 736\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 737\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 738\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 739\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 740\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 741\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 742\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 743\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 744\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 745\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 746\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 747\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 748\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 749\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 750\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 751\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 752\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 753\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 754\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 755\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 756\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 757\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 758\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 759\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 760\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 761\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 762\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0193\n",
      "Epoch: 763\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 764\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 765\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 766\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 767\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 768\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 769\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 770\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 771\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 772\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0192\n",
      "Epoch: 773\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 774\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0192\n",
      "Epoch: 775\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0192\n",
      "Epoch: 776\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 777\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0192\n",
      "Epoch: 778\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0192\n",
      "Epoch: 779\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0192\n",
      "Epoch: 780\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0192\n",
      "Epoch: 781\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0192\n",
      "Epoch: 782\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 783\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 784\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 785\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 786\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 787\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 788\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 789\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 790\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 791\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 792\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 793\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 794\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 795\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 796\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 797\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 798\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Epoch: 799\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0192\n",
      "Forecasting Training Data\n",
      "Month=1, Predicted=9.856731, Expected=9.510000\n",
      "Month=2, Predicted=9.839931, Expected=9.796000\n",
      "Month=3, Predicted=9.603132, Expected=9.468500\n",
      "Month=4, Predicted=9.660261, Expected=9.672000\n",
      "Month=5, Predicted=9.981588, Expected=9.610000\n",
      "Month=6, Predicted=9.526674, Expected=9.240000\n",
      "Month=7, Predicted=9.858405, Expected=10.318300\n",
      "Month=8, Predicted=9.988893, Expected=8.974800\n",
      "Month=9, Predicted=9.598263, Expected=9.114000\n",
      "Month=10, Predicted=9.430208, Expected=9.300000\n",
      "Month=11, Predicted=9.130133, Expected=8.400000\n",
      "Month=12, Predicted=9.244737, Expected=9.300000\n",
      "Month=13, Predicted=9.153909, Expected=9.000000\n",
      "Month=14, Predicted=9.081685, Expected=9.300000\n",
      "Month=15, Predicted=9.259145, Expected=9.460000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-04-20 10:59:01.656413: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=16, Predicted=9.646382, Expected=9.145000\n",
      "Month=17, Predicted=9.307178, Expected=9.021000\n",
      "Month=18, Predicted=9.049291, Expected=8.750000\n",
      "Month=19, Predicted=8.796409, Expected=8.710000\n",
      "Month=20, Predicted=8.572538, Expected=8.370000\n",
      "Month=21, Predicted=8.497794, Expected=8.504000\n",
      "Month=22, Predicted=8.736752, Expected=9.819700\n",
      "Month=23, Predicted=9.196057, Expected=9.827300\n",
      "Month=24, Predicted=10.052131, Expected=9.929800\n",
      "Month=25, Predicted=9.638355, Expected=9.288000\n",
      "Month=26, Predicted=9.422741, Expected=9.300000\n",
      "Month=27, Predicted=9.387556, Expected=9.060000\n",
      "Month=28, Predicted=9.019095, Expected=8.835000\n",
      "Month=29, Predicted=8.788947, Expected=8.388600\n",
      "Month=30, Predicted=8.669567, Expected=8.400000\n",
      "Month=31, Predicted=8.685002, Expected=8.525000\n",
      "Month=32, Predicted=8.497266, Expected=8.250000\n",
      "Month=33, Predicted=8.721239, Expected=8.419000\n",
      "Month=34, Predicted=8.652784, Expected=9.455000\n",
      "Month=35, Predicted=8.908675, Expected=8.540000\n",
      "Month=36, Predicted=9.127518, Expected=9.455000\n",
      "Month=37, Predicted=9.262553, Expected=9.000000\n",
      "Month=38, Predicted=9.454329, Expected=9.599000\n",
      "Month=39, Predicted=9.589696, Expected=9.436000\n",
      "Month=40, Predicted=9.471346, Expected=9.539800\n",
      "Month=41, Predicted=9.368813, Expected=9.028600\n",
      "Month=42, Predicted=9.006127, Expected=8.932000\n",
      "Month=43, Predicted=8.979074, Expected=8.993000\n",
      "Month=44, Predicted=8.928066, Expected=8.678400\n",
      "Month=45, Predicted=8.867386, Expected=9.011100\n",
      "Month=46, Predicted=9.095958, Expected=9.630000\n",
      "Month=47, Predicted=9.253233, Expected=8.590400\n",
      "Month=48, Predicted=9.248898, Expected=9.736300\n",
      "Month=49, Predicted=9.573648, Expected=9.384500\n",
      "Month=50, Predicted=9.803238, Expected=9.947200\n",
      "Month=51, Predicted=9.872753, Expected=9.577100\n",
      "Month=52, Predicted=9.452489, Expected=9.117200\n",
      "Month=53, Predicted=9.099780, Expected=9.122500\n",
      "Month=54, Predicted=9.065476, Expected=8.880000\n",
      "Month=55, Predicted=8.808170, Expected=8.709200\n",
      "Month=56, Predicted=8.862030, Expected=8.428200\n",
      "Month=57, Predicted=8.668165, Expected=9.907600\n",
      "Month=58, Predicted=9.483113, Expected=9.145000\n",
      "Month=59, Predicted=9.195697, Expected=8.498000\n",
      "Month=60, Predicted=9.116368, Expected=9.362000\n",
      "Month=61, Predicted=9.307307, Expected=9.000000\n",
      "Month=62, Predicted=9.174997, Expected=9.455000\n",
      "Month=63, Predicted=9.315070, Expected=9.300000\n",
      "Month=64, Predicted=9.557979, Expected=8.990000\n",
      "Month=65, Predicted=9.034434, Expected=8.990000\n",
      "Month=66, Predicted=8.994944, Expected=8.790000\n",
      "Month=67, Predicted=8.763154, Expected=8.835000\n",
      "Month=68, Predicted=8.759059, Expected=8.700000\n",
      "Month=69, Predicted=8.771526, Expected=8.935000\n",
      "Month=70, Predicted=9.080566, Expected=8.835000\n",
      "Month=71, Predicted=8.909741, Expected=8.265000\n",
      "Month=72, Predicted=8.876692, Expected=8.835000\n",
      "Month=73, Predicted=8.765316, Expected=8.550000\n",
      "Month=74, Predicted=8.488482, Expected=8.680000\n",
      "Month=75, Predicted=9.126045, Expected=8.400000\n",
      "Month=76, Predicted=8.455355, Expected=8.525000\n",
      "Month=77, Predicted=8.680298, Expected=8.370000\n",
      "Month=78, Predicted=8.438311, Expected=7.890000\n",
      "Month=79, Predicted=8.490894, Expected=7.812000\n",
      "Month=80, Predicted=8.108979, Expected=7.620000\n",
      "Month=81, Predicted=7.844395, Expected=7.718000\n",
      "Month=82, Predicted=8.029737, Expected=8.323500\n",
      "Month=83, Predicted=8.061353, Expected=6.860000\n",
      "Month=84, Predicted=8.004923, Expected=8.308000\n",
      "Month=85, Predicted=8.073284, Expected=8.100000\n",
      "Month=86, Predicted=8.536919, Expected=8.525000\n",
      "Month=87, Predicted=8.441395, Expected=8.250000\n",
      "Month=88, Predicted=8.456327, Expected=8.215000\n",
      "Month=89, Predicted=8.146505, Expected=8.122600\n",
      "Month=90, Predicted=8.103970, Expected=7.778100\n",
      "Month=91, Predicted=7.942057, Expected=7.954600\n",
      "Month=92, Predicted=7.863142, Expected=7.420000\n",
      "Month=93, Predicted=7.617909, Expected=7.538300\n",
      "Month=94, Predicted=7.890253, Expected=7.905000\n",
      "Month=95, Predicted=7.556211, Expected=7.140000\n",
      "Month=96, Predicted=7.898255, Expected=8.432000\n",
      "Month=97, Predicted=8.205901, Expected=7.710000\n",
      "Month=98, Predicted=8.225183, Expected=7.967000\n",
      "Month=99, Predicted=7.754005, Expected=7.320000\n",
      "Month=100, Predicted=7.584897, Expected=7.502000\n",
      "Month=101, Predicted=7.550032, Expected=7.409000\n",
      "Month=102, Predicted=7.355253, Expected=7.200600\n",
      "Month=103, Predicted=7.409178, Expected=7.865000\n",
      "Month=104, Predicted=7.659765, Expected=6.690000\n",
      "Month=105, Predicted=7.277702, Expected=6.879400\n",
      "Month=106, Predicted=7.201134, Expected=7.440000\n",
      "Month=107, Predicted=6.972520, Expected=6.860000\n",
      "Month=108, Predicted=7.338682, Expected=7.595000\n",
      "Month=109, Predicted=7.455070, Expected=7.200000\n",
      "Month=110, Predicted=7.760457, Expected=7.130000\n",
      "Month=111, Predicted=7.146306, Expected=6.900000\n",
      "Month=112, Predicted=6.973565, Expected=7.130000\n",
      "Month=113, Predicted=7.139650, Expected=7.130000\n",
      "Month=114, Predicted=7.086800, Expected=6.840000\n",
      "Month=115, Predicted=6.967170, Expected=7.006000\n",
      "Month=116, Predicted=7.004592, Expected=6.780000\n",
      "Month=117, Predicted=6.910485, Expected=7.089600\n",
      "Month=118, Predicted=7.213908, Expected=6.882000\n",
      "Month=119, Predicted=6.933899, Expected=6.446700\n",
      "Month=120, Predicted=6.899617, Expected=6.882000\n",
      "Month=121, Predicted=6.792377, Expected=6.600000\n",
      "Month=122, Predicted=6.673374, Expected=6.820000\n",
      "Month=123, Predicted=7.187699, Expected=6.600000\n",
      "Month=124, Predicted=6.596117, Expected=6.820000\n",
      "Month=125, Predicted=6.965008, Expected=6.665000\n",
      "Month=126, Predicted=6.723236, Expected=6.450000\n",
      "Month=127, Predicted=6.712853, Expected=6.665000\n",
      "Month=128, Predicted=6.656416, Expected=6.450000\n",
      "Month=129, Predicted=6.621730, Expected=6.722100\n",
      "Month=130, Predicted=6.939075, Expected=6.820000\n",
      "Month=131, Predicted=6.718374, Expected=6.160000\n",
      "Month=132, Predicted=6.614249, Expected=6.820000\n",
      "Month=133, Predicted=6.738534, Expected=6.480000\n",
      "Month=134, Predicted=6.702552, Expected=6.596900\n",
      "Month=135, Predicted=6.681152, Expected=6.492000\n",
      "Month=136, Predicted=6.566061, Expected=6.510000\n",
      "Month=137, Predicted=6.574806, Expected=6.339500\n",
      "Month=138, Predicted=6.464065, Expected=6.001600\n",
      "Month=139, Predicted=6.310927, Expected=6.107000\n",
      "Month=140, Predicted=6.257564, Expected=5.790000\n",
      "Month=141, Predicted=6.046930, Expected=5.885000\n",
      "Month=142, Predicted=6.267759, Expected=7.280000\n",
      "Month=143, Predicted=6.573892, Expected=5.941600\n",
      "Month=144, Predicted=6.757385, Expected=6.810000\n",
      "Month=145, Predicted=6.554624, Expected=6.182000\n",
      "Month=146, Predicted=6.521202, Expected=6.293000\n",
      "Month=147, Predicted=6.314231, Expected=6.118600\n",
      "Month=148, Predicted=6.186229, Expected=6.138000\n",
      "Month=149, Predicted=6.154586, Expected=6.107000\n",
      "Month=150, Predicted=6.044066, Expected=5.913000\n",
      "Month=151, Predicted=5.890826, Expected=6.141100\n",
      "Month=152, Predicted=6.099868, Expected=6.248000\n",
      "Month=153, Predicted=6.237725, Expected=5.829700\n",
      "Month=154, Predicted=6.132582, Expected=6.829300\n",
      "Month=155, Predicted=6.698650, Expected=6.694400\n",
      "Month=156, Predicted=7.230268, Expected=7.726200\n",
      "Month=157, Predicted=7.512071, Expected=7.054400\n",
      "Month=158, Predicted=7.216709, Expected=7.268900\n",
      "Month=159, Predicted=7.166681, Expected=7.020000\n",
      "Month=160, Predicted=6.876391, Expected=6.510000\n",
      "Month=161, Predicted=6.581464, Expected=6.370500\n",
      "Month=162, Predicted=6.264535, Expected=5.730000\n",
      "Month=163, Predicted=5.914392, Expected=5.828000\n",
      "Month=164, Predicted=6.077315, Expected=5.580000\n",
      "Month=165, Predicted=5.591201, Expected=5.709900\n",
      "Month=166, Predicted=6.063357, Expected=6.696000\n",
      "Month=167, Predicted=6.127371, Expected=6.248000\n",
      "Month=168, Predicted=6.477464, Expected=6.711600\n",
      "Month=169, Predicted=6.765371, Expected=6.600100\n",
      "Month=170, Predicted=7.192393, Expected=7.508200\n",
      "Month=171, Predicted=7.601277, Expected=7.765000\n",
      "Month=172, Predicted=7.537741, Expected=7.285000\n",
      "Month=173, Predicted=7.123082, Expected=6.959500\n",
      "Month=174, Predicted=6.756482, Expected=6.450000\n",
      "Month=175, Predicted=6.466918, Expected=6.572000\n",
      "Month=176, Predicted=6.504115, Expected=6.600000\n",
      "Month=177, Predicted=6.465186, Expected=4.265300\n",
      "Month=178, Predicted=6.424947, Expected=7.367000\n",
      "Month=179, Predicted=6.884208, Expected=6.544000\n",
      "Month=180, Predicted=6.940342, Expected=6.940800\n",
      "Train RMSE: 0.41109\n",
      "Train RMSPE: 6.23600\n",
      "Train MAE: 0.30202\n",
      "Train MAPE: 4.05377\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=6.859432, Expected=6.786000\n",
      "Month=2, Predicted=6.863445, Expected=6.981200\n",
      "Month=3, Predicted=7.020691, Expected=6.756000\n",
      "Month=4, Predicted=6.896320, Expected=6.733200\n",
      "Month=5, Predicted=6.857316, Expected=6.671200\n",
      "Month=6, Predicted=6.860133, Expected=6.295600\n",
      "Month=7, Predicted=6.529885, Expected=6.432500\n",
      "Month=8, Predicted=6.533645, Expected=6.153000\n",
      "Month=9, Predicted=6.301387, Expected=6.389500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=10, Predicted=6.683537, Expected=7.192000\n",
      "Month=11, Predicted=6.696776, Expected=6.524000\n",
      "Month=12, Predicted=7.014381, Expected=7.238500\n",
      "Month=13, Predicted=7.009559, Expected=6.990000\n",
      "Month=14, Predicted=7.522126, Expected=7.254000\n",
      "Month=15, Predicted=7.283226, Expected=6.720000\n",
      "Month=16, Predicted=6.854843, Expected=6.944000\n",
      "Month=17, Predicted=6.931906, Expected=7.052500\n",
      "Month=18, Predicted=7.146083, Expected=6.690000\n",
      "Month=19, Predicted=6.741525, Expected=6.909900\n",
      "Month=20, Predicted=6.796395, Expected=6.819000\n",
      "Month=21, Predicted=6.936742, Expected=7.167200\n",
      "Month=22, Predicted=7.051923, Expected=7.254000\n",
      "Month=23, Predicted=7.355555, Expected=6.664000\n",
      "Month=24, Predicted=6.648645, Expected=7.393500\n",
      "Month=25, Predicted=7.383598, Expected=7.125000\n",
      "Month=26, Predicted=7.413283, Expected=7.347000\n",
      "Month=27, Predicted=7.236684, Expected=7.216500\n",
      "Month=28, Predicted=7.390698, Expected=7.254000\n",
      "Month=29, Predicted=7.341010, Expected=7.238500\n",
      "Month=30, Predicted=7.390808, Expected=6.990000\n",
      "Month=31, Predicted=7.225039, Expected=7.192000\n",
      "Month=32, Predicted=7.165182, Expected=6.900000\n",
      "Month=33, Predicted=7.022405, Expected=7.427300\n",
      "Month=34, Predicted=7.424001, Expected=7.300500\n",
      "Month=35, Predicted=7.367542, Expected=6.902000\n",
      "Month=36, Predicted=6.996106, Expected=7.409000\n",
      "Month=37, Predicted=7.358944, Expected=7.179000\n",
      "Month=38, Predicted=7.463223, Expected=7.424500\n",
      "Month=39, Predicted=7.325689, Expected=7.275000\n",
      "Month=40, Predicted=7.445550, Expected=7.316000\n",
      "Month=41, Predicted=7.337654, Expected=7.086300\n",
      "Month=42, Predicted=7.196627, Expected=7.020000\n",
      "Month=43, Predicted=6.988820, Expected=7.270500\n",
      "Month=44, Predicted=7.200806, Expected=7.168800\n",
      "Month=45, Predicted=7.287112, Expected=7.448600\n",
      "Month=46, Predicted=7.532398, Expected=7.440200\n",
      "Test RMSE: 0.29146\n",
      "Test RMSPE: 4.21692\n",
      "Test MAE: 0.22831\n",
      "Test MAPE: 3.28361\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# d-lstm static \n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "\t\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons[0], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\t#model.add(LSTM(neurons[1], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\t#model.add(Dropout(0.3))\n",
    "\t#model.add(LSTM(neurons[2], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\t#model.add(Dropout(0.3))\n",
    "\t# model.add(LSTM(neurons[3], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\t# model.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\t\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tprint('Epoch:',i)\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\t\n",
    "\treturn model\n",
    "\t\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=5\n",
    "\tneurons= [ 5 , 4, 2] \n",
    "\tn_epochs=800\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7ffed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 11:21:05.591932: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-20 11:21:05.591998: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_11123/633475735.py:27: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_11123/633475735.py:241: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_11123/633475735.py:145: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 11:21:05.797980: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-20 11:21:05.798000: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 11:21:06.053282: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-20 11:21:06.053436: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 11:21:06.071306: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 11:21:06.109056: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0701\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0700\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0700\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0699\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0699\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0699\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0699\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0699\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0698\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0698\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0698\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0698\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0698\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0698\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0698\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0698\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0697\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0697\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0697\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0697\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0697\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0697\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0696\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0696\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0696\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0696\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0696\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0696\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0695\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0695\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0695\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0695\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0695\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0694\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0694\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0694\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0694\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0694\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0693\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0693\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0693\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0693\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0693\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0692\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0692\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0692\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0692\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0692\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0691\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0691\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0691\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0691\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0691\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0690\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0690\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0690\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0690\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0690\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0690\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0689\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0689\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0689\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0689\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0689\n",
      "Epoch: 79\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0689\n",
      "Epoch: 80\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0688\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0688\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0688\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0688\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0688\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0688\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0687\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0687\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0687\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0687\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0687\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0687\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0686\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0686\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0686\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0686\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0686\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0686\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0685\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0685\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0685\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0685\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0685\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0684\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0684\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0684\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0683\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0683\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0682\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0681\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0679\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0679\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0678\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0677\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0677\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0676\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0676\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0675\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0675\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0675\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0675\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0674\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0674\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0674\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0674\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0674\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0674\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0674\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0674\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 136\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0673\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 153\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 154\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 155\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0672\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0672\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0672\n",
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0672\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0672\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 205\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 229\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 230\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 235\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0671\n",
      "Epoch: 236\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0671\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0671\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0671\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0671\n",
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0671\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0671\n",
      "Epoch: 273\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 274\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0671\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0670\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 305\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 308\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 314\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 315\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 316\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 317\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 318\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 319\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 320\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 321\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 322\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 323\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 324\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 325\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 326\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 327\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 328\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 329\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 330\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 331\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 332\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 333\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 334\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 335\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 336\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 337\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 338\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 339\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 340\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 341\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 342\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 343\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 344\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 345\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 346\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 347\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 348\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 349\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 350\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 351\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 352\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 353\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 354\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 355\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 356\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 357\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 358\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 359\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 360\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 361\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 362\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 363\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 364\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 365\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 366\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 367\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 368\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 369\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 370\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 371\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 372\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 373\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 374\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 375\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 376\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 377\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 378\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 379\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 380\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 381\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 382\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 383\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 384\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 385\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 386\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 387\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 388\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 389\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 390\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 391\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 392\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 393\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 394\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 395\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 396\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 397\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 398\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 399\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 400\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 401\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 402\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 403\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 404\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 405\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 406\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 407\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 408\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 409\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 410\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 411\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 412\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 413\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 414\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 415\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 416\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 417\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 418\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 419\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 420\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 421\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 422\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 423\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 424\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 425\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 426\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 427\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 428\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 429\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 430\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 431\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 432\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 433\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 434\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 435\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 436\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 437\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 438\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 439\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 440\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 441\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 442\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 443\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 444\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 445\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 446\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 447\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 448\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 449\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 450\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 451\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 452\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 453\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 454\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 455\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 456\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 457\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 458\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 459\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 460\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 461\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 462\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 463\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 464\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 465\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 466\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 467\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 468\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 469\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 470\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 471\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 472\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 473\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 474\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 475\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 476\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 477\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 478\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 479\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 480\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 481\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 482\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 483\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 484\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 485\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 486\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 487\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 488\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 489\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 490\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 491\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 492\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 493\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 494\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 495\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 496\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 497\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 498\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 499\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 500\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 501\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 502\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 503\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 504\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 505\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 506\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 507\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 508\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 509\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 510\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 511\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 512\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 513\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 514\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 515\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 516\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 517\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 518\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 519\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 520\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 521\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 522\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 523\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 524\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 525\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 526\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 527\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 528\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 529\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 530\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 531\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 532\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 533\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 534\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 535\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 536\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 537\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 538\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 539\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 540\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 541\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 542\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 543\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 544\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 545\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 546\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 547\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 548\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 549\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 550\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 551\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 552\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0670\n",
      "Epoch: 553\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 554\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 555\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 556\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 557\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 558\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 559\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 560\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 561\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 562\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 563\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 564\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 565\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 566\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 567\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 568\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 569\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 570\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 571\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 572\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 573\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 574\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 575\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 576\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 577\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 578\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 579\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 580\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 581\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 582\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 583\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 584\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 585\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 586\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 587\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 588\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 589\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 590\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 591\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 592\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 593\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 594\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 595\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 596\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 597\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 598\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0670\n",
      "Epoch: 599\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 600\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 601\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 602\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 603\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 604\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 605\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 606\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 607\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 608\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 609\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 610\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 611\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 612\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 613\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 614\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 615\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 616\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 617\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 618\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 619\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 620\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 621\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 622\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 623\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 624\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 625\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 626\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 627\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 628\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 629\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 630\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 631\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 632\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 633\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 634\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 635\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 636\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 637\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 638\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 639\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 640\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 641\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 642\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 643\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0669\n",
      "Epoch: 644\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 645\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 646\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 647\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 648\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 649\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 650\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 651\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 652\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 653\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 654\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0669\n",
      "Epoch: 655\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0669\n",
      "Epoch: 656\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 657\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0669\n",
      "Epoch: 658\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0669\n",
      "Epoch: 659\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0669\n",
      "Epoch: 660\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0669\n",
      "Epoch: 661\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 662\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0669\n",
      "Epoch: 663\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0669\n",
      "Epoch: 664\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0669\n",
      "Epoch: 665\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0669\n",
      "Epoch: 666\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0669\n",
      "Epoch: 667\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0669\n",
      "Epoch: 668\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0669\n",
      "Epoch: 669\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 670\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 671\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0669\n",
      "Epoch: 672\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 673\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 674\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 675\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 676\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 677\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 678\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 679\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 680\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 681\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 682\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 683\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 684\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 685\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 686\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 687\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 688\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 689\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 690\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 691\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 692\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 693\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 694\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 695\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 696\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 697\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 698\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 699\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 700\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 701\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 702\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 703\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 704\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 705\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 706\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 707\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 708\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 709\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 710\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 711\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 712\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 713\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 714\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 715\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 716\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 717\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 718\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 719\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 720\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 721\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 722\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 723\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 724\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 725\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 726\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 727\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 728\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 729\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 730\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 731\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 732\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 733\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 734\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 735\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 736\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 737\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 738\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 739\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 740\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 741\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 742\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 743\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 744\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 745\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 746\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 747\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 748\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 749\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 750\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 751\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 752\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 753\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 754\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 755\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 756\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 757\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 758\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 759\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 760\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 761\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 762\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 763\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 764\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 765\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 766\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 767\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 768\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 769\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 770\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 771\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 772\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 773\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 774\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 775\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 776\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 777\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 778\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 779\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 780\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 781\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 782\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 783\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 784\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 785\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 786\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 787\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 788\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 789\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 790\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 791\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 792\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 793\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 794\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 795\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 796\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 797\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 798\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 799\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 800\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 801\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 802\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 803\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 804\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 805\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 806\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 807\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 808\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 809\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 810\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 811\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 812\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 813\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 814\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 815\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 816\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 817\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 818\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 819\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 820\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 821\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 822\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 823\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 824\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 825\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 826\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 827\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 828\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 829\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 830\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 831\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 832\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 833\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 834\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 835\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 836\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 837\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 838\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 839\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 840\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 841\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 842\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 843\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 844\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 845\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 846\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 847\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 848\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 849\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 850\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 851\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 852\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 853\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 854\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 855\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 856\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 857\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 858\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 859\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 860\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 861\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 862\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 863\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 864\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 865\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 866\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 867\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 868\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 869\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 870\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 871\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 872\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 873\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 874\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 875\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 876\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 877\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 878\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 879\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 880\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 881\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 882\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 883\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 884\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 885\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 886\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 887\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 888\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 889\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 890\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 891\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 892\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 893\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 894\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 895\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 896\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 897\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 898\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 899\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 900\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 901\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 902\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 903\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 904\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 905\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 906\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 907\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 908\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 909\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 910\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 911\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 912\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 913\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 914\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 915\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 916\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 917\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 918\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 919\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 920\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 921\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 922\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 923\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 924\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 925\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 926\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 927\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 928\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 929\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 930\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 931\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 932\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 933\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 934\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 935\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 936\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 937\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 938\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 939\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 940\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 941\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 942\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 943\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 944\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 945\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 946\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 947\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 948\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 949\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 950\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 951\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 952\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 953\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 954\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 955\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 956\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 957\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 958\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 959\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 960\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 961\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 962\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 963\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 964\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 965\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 966\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 967\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 968\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 969\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 970\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 971\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 972\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 973\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 974\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 975\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0668\n",
      "Epoch: 976\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 977\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0668\n",
      "Epoch: 978\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 979\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 980\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 981\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 982\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 983\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 984\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 985\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 986\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 987\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 988\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 989\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 990\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 991\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 992\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0668\n",
      "Epoch: 993\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 994\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0668\n",
      "Epoch: 995\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0669\n",
      "Epoch: 996\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0668\n",
      "Epoch: 997\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Epoch: 998\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0668\n",
      "Epoch: 999\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0669\n",
      "Forecasting Training Data\n",
      "Month=1, Predicted=10.682000, Expected=9.510000\n",
      "Month=2, Predicted=9.893500, Expected=9.796000\n",
      "Month=3, Predicted=10.179500, Expected=9.468500\n",
      "Month=4, Predicted=9.852000, Expected=9.672000\n",
      "Month=5, Predicted=10.055500, Expected=9.610000\n",
      "Month=6, Predicted=9.993500, Expected=9.240000\n",
      "Month=7, Predicted=9.623500, Expected=10.318300\n",
      "Month=8, Predicted=10.701800, Expected=8.974800\n",
      "Month=9, Predicted=9.358300, Expected=9.114000\n",
      "Month=10, Predicted=9.497500, Expected=9.300000\n",
      "Month=11, Predicted=9.683500, Expected=8.400000\n",
      "Month=12, Predicted=8.783500, Expected=9.300000\n",
      "Month=13, Predicted=9.683500, Expected=9.000000\n",
      "Month=14, Predicted=9.383500, Expected=9.300000\n",
      "Month=15, Predicted=9.683500, Expected=9.460000\n",
      "Month=16, Predicted=9.843500, Expected=9.145000\n",
      "Month=17, Predicted=9.528500, Expected=9.021000\n",
      "Month=18, Predicted=9.404500, Expected=8.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-04-20 11:56:11.566445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=19, Predicted=9.133500, Expected=8.710000\n",
      "Month=20, Predicted=9.093500, Expected=8.370000\n",
      "Month=21, Predicted=8.753500, Expected=8.504000\n",
      "Month=22, Predicted=8.887500, Expected=9.819700\n",
      "Month=23, Predicted=10.203200, Expected=9.827300\n",
      "Month=24, Predicted=10.210800, Expected=9.929800\n",
      "Month=25, Predicted=10.313300, Expected=9.288000\n",
      "Month=26, Predicted=9.671500, Expected=9.300000\n",
      "Month=27, Predicted=9.683500, Expected=9.060000\n",
      "Month=28, Predicted=9.443500, Expected=8.835000\n",
      "Month=29, Predicted=9.218500, Expected=8.388600\n",
      "Month=30, Predicted=8.772100, Expected=8.400000\n",
      "Month=31, Predicted=8.783500, Expected=8.525000\n",
      "Month=32, Predicted=8.908500, Expected=8.250000\n",
      "Month=33, Predicted=8.633500, Expected=8.419000\n",
      "Month=34, Predicted=8.802500, Expected=9.455000\n",
      "Month=35, Predicted=9.838500, Expected=8.540000\n",
      "Month=36, Predicted=8.923500, Expected=9.455000\n",
      "Month=37, Predicted=9.838500, Expected=9.000000\n",
      "Month=38, Predicted=9.383500, Expected=9.599000\n",
      "Month=39, Predicted=9.982500, Expected=9.436000\n",
      "Month=40, Predicted=9.819500, Expected=9.539800\n",
      "Month=41, Predicted=9.923300, Expected=9.028600\n",
      "Month=42, Predicted=9.412100, Expected=8.932000\n",
      "Month=43, Predicted=9.315500, Expected=8.993000\n",
      "Month=44, Predicted=9.376500, Expected=8.678400\n",
      "Month=45, Predicted=9.061900, Expected=9.011100\n",
      "Month=46, Predicted=9.394600, Expected=9.630000\n",
      "Month=47, Predicted=10.013500, Expected=8.590400\n",
      "Month=48, Predicted=8.973900, Expected=9.736300\n",
      "Month=49, Predicted=10.119800, Expected=9.384500\n",
      "Month=50, Predicted=9.768000, Expected=9.947200\n",
      "Month=51, Predicted=10.330700, Expected=9.577100\n",
      "Month=52, Predicted=9.960600, Expected=9.117200\n",
      "Month=53, Predicted=9.500700, Expected=9.122500\n",
      "Month=54, Predicted=9.506000, Expected=8.880000\n",
      "Month=55, Predicted=9.263500, Expected=8.709200\n",
      "Month=56, Predicted=9.092700, Expected=8.428200\n",
      "Month=57, Predicted=8.811700, Expected=9.907600\n",
      "Month=58, Predicted=10.291100, Expected=9.145000\n",
      "Month=59, Predicted=9.528500, Expected=8.498000\n",
      "Month=60, Predicted=8.881500, Expected=9.362000\n",
      "Month=61, Predicted=9.745500, Expected=9.000000\n",
      "Month=62, Predicted=9.383500, Expected=9.455000\n",
      "Month=63, Predicted=9.838500, Expected=9.300000\n",
      "Month=64, Predicted=9.683500, Expected=8.990000\n",
      "Month=65, Predicted=9.373500, Expected=8.990000\n",
      "Month=66, Predicted=9.373500, Expected=8.790000\n",
      "Month=67, Predicted=9.173500, Expected=8.835000\n",
      "Month=68, Predicted=9.218500, Expected=8.700000\n",
      "Month=69, Predicted=9.083500, Expected=8.935000\n",
      "Month=70, Predicted=9.318500, Expected=8.835000\n",
      "Month=71, Predicted=9.218500, Expected=8.265000\n",
      "Month=72, Predicted=8.648500, Expected=8.835000\n",
      "Month=73, Predicted=9.218500, Expected=8.550000\n",
      "Month=74, Predicted=8.933500, Expected=8.680000\n",
      "Month=75, Predicted=9.063500, Expected=8.400000\n",
      "Month=76, Predicted=8.783500, Expected=8.525000\n",
      "Month=77, Predicted=8.908500, Expected=8.370000\n",
      "Month=78, Predicted=8.753500, Expected=7.890000\n",
      "Month=79, Predicted=8.273500, Expected=7.812000\n",
      "Month=80, Predicted=8.195500, Expected=7.620000\n",
      "Month=81, Predicted=8.003500, Expected=7.718000\n",
      "Month=82, Predicted=8.101500, Expected=8.323500\n",
      "Month=83, Predicted=8.707000, Expected=6.860000\n",
      "Month=84, Predicted=7.243500, Expected=8.308000\n",
      "Month=85, Predicted=8.691500, Expected=8.100000\n",
      "Month=86, Predicted=8.483500, Expected=8.525000\n",
      "Month=87, Predicted=8.908500, Expected=8.250000\n",
      "Month=88, Predicted=8.633500, Expected=8.215000\n",
      "Month=89, Predicted=8.598500, Expected=8.122600\n",
      "Month=90, Predicted=8.506100, Expected=7.778100\n",
      "Month=91, Predicted=8.161600, Expected=7.954600\n",
      "Month=92, Predicted=8.338100, Expected=7.420000\n",
      "Month=93, Predicted=7.803500, Expected=7.538300\n",
      "Month=94, Predicted=7.921800, Expected=7.905000\n",
      "Month=95, Predicted=8.288500, Expected=7.140000\n",
      "Month=96, Predicted=7.523500, Expected=8.432000\n",
      "Month=97, Predicted=8.815500, Expected=7.710000\n",
      "Month=98, Predicted=8.093500, Expected=7.967000\n",
      "Month=99, Predicted=8.350500, Expected=7.320000\n",
      "Month=100, Predicted=7.703500, Expected=7.502000\n",
      "Month=101, Predicted=7.885500, Expected=7.409000\n",
      "Month=102, Predicted=7.792500, Expected=7.200600\n",
      "Month=103, Predicted=7.584100, Expected=7.865000\n",
      "Month=104, Predicted=8.248500, Expected=6.690000\n",
      "Month=105, Predicted=7.073500, Expected=6.879400\n",
      "Month=106, Predicted=7.262900, Expected=7.440000\n",
      "Month=107, Predicted=7.823500, Expected=6.860000\n",
      "Month=108, Predicted=7.243500, Expected=7.595000\n",
      "Month=109, Predicted=7.978500, Expected=7.200000\n",
      "Month=110, Predicted=7.583500, Expected=7.130000\n",
      "Month=111, Predicted=7.513500, Expected=6.900000\n",
      "Month=112, Predicted=7.283500, Expected=7.130000\n",
      "Month=113, Predicted=7.513500, Expected=7.130000\n",
      "Month=114, Predicted=7.513500, Expected=6.840000\n",
      "Month=115, Predicted=7.223500, Expected=7.006000\n",
      "Month=116, Predicted=7.389500, Expected=6.780000\n",
      "Month=117, Predicted=7.163500, Expected=7.089600\n",
      "Month=118, Predicted=7.473100, Expected=6.882000\n",
      "Month=119, Predicted=7.265500, Expected=6.446700\n",
      "Month=120, Predicted=6.830200, Expected=6.882000\n",
      "Month=121, Predicted=7.265500, Expected=6.600000\n",
      "Month=122, Predicted=6.983500, Expected=6.820000\n",
      "Month=123, Predicted=7.203500, Expected=6.600000\n",
      "Month=124, Predicted=6.983500, Expected=6.820000\n",
      "Month=125, Predicted=7.203500, Expected=6.665000\n",
      "Month=126, Predicted=7.048500, Expected=6.450000\n",
      "Month=127, Predicted=6.833500, Expected=6.665000\n",
      "Month=128, Predicted=7.048500, Expected=6.450000\n",
      "Month=129, Predicted=6.833500, Expected=6.722100\n",
      "Month=130, Predicted=7.105600, Expected=6.820000\n",
      "Month=131, Predicted=7.203500, Expected=6.160000\n",
      "Month=132, Predicted=6.543500, Expected=6.820000\n",
      "Month=133, Predicted=7.203500, Expected=6.480000\n",
      "Month=134, Predicted=6.863500, Expected=6.596900\n",
      "Month=135, Predicted=6.980400, Expected=6.492000\n",
      "Month=136, Predicted=6.875500, Expected=6.510000\n",
      "Month=137, Predicted=6.893500, Expected=6.339500\n",
      "Month=138, Predicted=6.723000, Expected=6.001600\n",
      "Month=139, Predicted=6.385100, Expected=6.107000\n",
      "Month=140, Predicted=6.490500, Expected=5.790000\n",
      "Month=141, Predicted=6.173500, Expected=5.885000\n",
      "Month=142, Predicted=6.268500, Expected=7.280000\n",
      "Month=143, Predicted=7.663500, Expected=5.941600\n",
      "Month=144, Predicted=6.325100, Expected=6.810000\n",
      "Month=145, Predicted=7.193500, Expected=6.182000\n",
      "Month=146, Predicted=6.565500, Expected=6.293000\n",
      "Month=147, Predicted=6.676500, Expected=6.118600\n",
      "Month=148, Predicted=6.502100, Expected=6.138000\n",
      "Month=149, Predicted=6.521500, Expected=6.107000\n",
      "Month=150, Predicted=6.490500, Expected=5.913000\n",
      "Month=151, Predicted=6.296500, Expected=6.141100\n",
      "Month=152, Predicted=6.524600, Expected=6.248000\n",
      "Month=153, Predicted=6.631500, Expected=5.829700\n",
      "Month=154, Predicted=6.213200, Expected=6.829300\n",
      "Month=155, Predicted=7.212800, Expected=6.694400\n",
      "Month=156, Predicted=7.077900, Expected=7.726200\n",
      "Month=157, Predicted=8.109700, Expected=7.054400\n",
      "Month=158, Predicted=7.437900, Expected=7.268900\n",
      "Month=159, Predicted=7.652400, Expected=7.020000\n",
      "Month=160, Predicted=7.403500, Expected=6.510000\n",
      "Month=161, Predicted=6.893500, Expected=6.370500\n",
      "Month=162, Predicted=6.754000, Expected=5.730000\n",
      "Month=163, Predicted=6.113500, Expected=5.828000\n",
      "Month=164, Predicted=6.211500, Expected=5.580000\n",
      "Month=165, Predicted=5.963500, Expected=5.709900\n",
      "Month=166, Predicted=6.093400, Expected=6.696000\n",
      "Month=167, Predicted=7.079500, Expected=6.248000\n",
      "Month=168, Predicted=6.631500, Expected=6.711600\n",
      "Month=169, Predicted=7.095100, Expected=6.600100\n",
      "Month=170, Predicted=6.983600, Expected=7.508200\n",
      "Month=171, Predicted=7.891700, Expected=7.765000\n",
      "Month=172, Predicted=8.148500, Expected=7.285000\n",
      "Month=173, Predicted=7.668500, Expected=6.959500\n",
      "Month=174, Predicted=7.343000, Expected=6.450000\n",
      "Month=175, Predicted=6.833500, Expected=6.572000\n",
      "Month=176, Predicted=6.955500, Expected=6.600000\n",
      "Month=177, Predicted=6.983500, Expected=4.265300\n",
      "Month=178, Predicted=4.648800, Expected=7.367000\n",
      "Month=179, Predicted=7.750500, Expected=6.544000\n",
      "Month=180, Predicted=6.927500, Expected=6.940800\n",
      "Train RMSE: 0.71899\n",
      "Train RMSPE: 10.37443\n",
      "Train MAE: 0.58691\n",
      "Train MAPE: 7.85592\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=7.324300, Expected=6.786000\n",
      "Month=2, Predicted=7.169500, Expected=6.981200\n",
      "Month=3, Predicted=7.364700, Expected=6.756000\n",
      "Month=4, Predicted=7.139500, Expected=6.733200\n",
      "Month=5, Predicted=7.116700, Expected=6.671200\n",
      "Month=6, Predicted=7.054700, Expected=6.295600\n",
      "Month=7, Predicted=6.679100, Expected=6.432500\n",
      "Month=8, Predicted=6.816000, Expected=6.153000\n",
      "Month=9, Predicted=6.536500, Expected=6.389500\n",
      "Month=10, Predicted=6.773000, Expected=7.192000\n",
      "Month=11, Predicted=7.575500, Expected=6.524000\n",
      "Month=12, Predicted=6.907500, Expected=7.238500\n",
      "Month=13, Predicted=7.622000, Expected=6.990000\n",
      "Month=14, Predicted=7.373500, Expected=7.254000\n",
      "Month=15, Predicted=7.637500, Expected=6.720000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=16, Predicted=7.103500, Expected=6.944000\n",
      "Month=17, Predicted=7.327500, Expected=7.052500\n",
      "Month=18, Predicted=7.436000, Expected=6.690000\n",
      "Month=19, Predicted=7.073500, Expected=6.909900\n",
      "Month=20, Predicted=7.293400, Expected=6.819000\n",
      "Month=21, Predicted=7.202500, Expected=7.167200\n",
      "Month=22, Predicted=7.550700, Expected=7.254000\n",
      "Month=23, Predicted=7.637500, Expected=6.664000\n",
      "Month=24, Predicted=7.047500, Expected=7.393500\n",
      "Month=25, Predicted=7.777000, Expected=7.125000\n",
      "Month=26, Predicted=7.508500, Expected=7.347000\n",
      "Month=27, Predicted=7.730500, Expected=7.216500\n",
      "Month=28, Predicted=7.600000, Expected=7.254000\n",
      "Month=29, Predicted=7.637500, Expected=7.238500\n",
      "Month=30, Predicted=7.622000, Expected=6.990000\n",
      "Month=31, Predicted=7.373500, Expected=7.192000\n",
      "Month=32, Predicted=7.575500, Expected=6.900000\n",
      "Month=33, Predicted=7.283500, Expected=7.427300\n",
      "Month=34, Predicted=7.810800, Expected=7.300500\n",
      "Month=35, Predicted=7.684000, Expected=6.902000\n",
      "Month=36, Predicted=7.285500, Expected=7.409000\n",
      "Month=37, Predicted=7.792500, Expected=7.179000\n",
      "Month=38, Predicted=7.562500, Expected=7.424500\n",
      "Month=39, Predicted=7.808000, Expected=7.275000\n",
      "Month=40, Predicted=7.658500, Expected=7.316000\n",
      "Month=41, Predicted=7.699500, Expected=7.086300\n",
      "Month=42, Predicted=7.469800, Expected=7.020000\n",
      "Month=43, Predicted=7.403500, Expected=7.270500\n",
      "Month=44, Predicted=7.654000, Expected=7.168800\n",
      "Month=45, Predicted=7.552300, Expected=7.448600\n",
      "Month=46, Predicted=7.832100, Expected=7.440200\n",
      "Test RMSE: 0.49898\n",
      "Test RMSPE: 7.30912\n",
      "Test MAE: 0.43192\n",
      "Test MAPE: 6.24960\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# oil static.py bi lstm \n",
    "# without dense \n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='relu')))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=2\n",
    "\tneurons=[5,4,2] \n",
    "\tn_epochs=1000\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6acb20d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 12:04:35.444959: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-20 12:04:35.445234: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_11123/3394901000.py:24: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_11123/3394901000.py:239: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_11123/3394901000.py:143: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 12:04:35.843944: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 12:04:35.872125: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 12:04:35.932459: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 3s 13ms/sample - loss: 0.0497\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0390\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0345\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0331\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0324\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0319\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0315\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0312\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0310\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0308\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0307\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0305\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0304\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0303\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0302\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0301\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0300\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0300\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0299\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0299\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0298\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0297\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0297\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0296\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0296\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0295\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0295\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0295\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0294\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0294\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0293\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0293\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0293\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0292\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0292\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0292\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0291\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0291\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0291\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0290\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0290\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0290\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0289\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0289\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0289\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0289\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0288\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0288\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0288\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0288\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0287\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0287\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0287\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0287\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0286\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0286\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0286\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0286\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0285\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0285\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0285\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0285\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0284\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0284\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0284\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0284\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0284\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0283\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0283\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0283\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0282\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0282\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0282\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0282\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0282\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0281\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0281\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0281\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0281\n",
      "Epoch: 79\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0281\n",
      "Epoch: 80\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0280\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0280\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0280\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0280\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0279\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0279\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0279\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0279\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0278\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0278\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0278\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0278\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0278\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0278\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0277\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0277\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0277\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0276\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0276\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0276\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0276\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0275\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0276\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0275\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0275\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0275\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0274\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0274\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0274\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0274\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0274\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0273\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0273\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0273\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0273\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0272\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0272\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0272\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0272\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0271\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0271\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0271\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0270\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0270\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0270\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0270\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0269\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0269\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0269\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0268\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0269\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0268\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0268\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0267\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0267\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0266\n",
      "Epoch: 136\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0267\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0266\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0266\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0265\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0266\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0265\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0265\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0264\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0264\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0264\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0264\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0263\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0263\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0262\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0262\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0262\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0261\n",
      "Epoch: 153\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0260\n",
      "Epoch: 154\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0261\n",
      "Epoch: 155\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0260\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0259\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0260\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0258\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0259\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0258\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0258\n",
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0258\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0257\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0257\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0256\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0256\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0256\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0255\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0256\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0255\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0254\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0253\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0254\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0252\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0252\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0252\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0252\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0253\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0250\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0251\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0250\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0250\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0249\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0249\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0247\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0249\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0247\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0248\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0246\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0246\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0246\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0246\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0245\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0244\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0245\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0244\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0244\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0243\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0243\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0243\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0242\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0243\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0241\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0242\n",
      "Epoch: 205\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0241\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0242\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0240\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0240\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0240\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0239\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0239\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0240\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0239\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0239\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0235\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0238\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0236\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0238\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0235\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0237\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0234\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0236\n",
      "Epoch: 229\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0235\n",
      "Epoch: 230\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0235\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0234\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0235\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0233\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0233\n",
      "Epoch: 235\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0231\n",
      "Epoch: 236\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0233\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0232\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0232\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0232\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0232\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0231\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0231\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0232\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0232\n",
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0232\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0229\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0231\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0230\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0228\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0228\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0228\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0228\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0228\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0228\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0227\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0227\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0227\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0228\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0228\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0227\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0227\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0227\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0228\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0226\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0227\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0225\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0226\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0225\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0226\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0225\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0226\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0224\n",
      "Epoch: 273\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0224\n",
      "Epoch: 274\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0224\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0224\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0223\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0222\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0223\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0222\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0223\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0222\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0221\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0223\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0224\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0223\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0222\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0222\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0222\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0222\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0223\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0222\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0223\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0222\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0220\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0221\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0219\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0221\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0220\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0221\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0219\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0221\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0219\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0220\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0219\n",
      "Epoch: 305\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0220\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0218\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0220\n",
      "Epoch: 308\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0217\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0219\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0217\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0218\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0217\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0218\n",
      "Epoch: 314\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0219\n",
      "Epoch: 315\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0217\n",
      "Epoch: 316\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0219\n",
      "Epoch: 317\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0217\n",
      "Epoch: 318\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0216\n",
      "Epoch: 319\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0218\n",
      "Epoch: 320\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0215\n",
      "Epoch: 321\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0217\n",
      "Epoch: 322\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0216\n",
      "Epoch: 323\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0218\n",
      "Epoch: 324\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0216\n",
      "Epoch: 325\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0218\n",
      "Epoch: 326\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0214\n",
      "Epoch: 327\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0217\n",
      "Epoch: 328\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0215\n",
      "Epoch: 329\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0216\n",
      "Epoch: 330\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0215\n",
      "Epoch: 331\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0215\n",
      "Epoch: 332\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0214\n",
      "Epoch: 333\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0215\n",
      "Epoch: 334\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0215\n",
      "Epoch: 335\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0214\n",
      "Epoch: 336\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0215\n",
      "Epoch: 337\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0215\n",
      "Epoch: 338\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0213\n",
      "Epoch: 339\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0215\n",
      "Epoch: 340\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0212\n",
      "Epoch: 341\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0214\n",
      "Epoch: 342\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0212\n",
      "Epoch: 343\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0215\n",
      "Epoch: 344\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0214\n",
      "Epoch: 345\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0213\n",
      "Epoch: 346\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0214\n",
      "Epoch: 347\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0212\n",
      "Epoch: 348\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0213\n",
      "Epoch: 349\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0214\n",
      "Epoch: 350\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0213\n",
      "Epoch: 351\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0212\n",
      "Epoch: 352\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0213\n",
      "Epoch: 353\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0213\n",
      "Epoch: 354\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0211\n",
      "Epoch: 355\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0212\n",
      "Epoch: 356\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0211\n",
      "Epoch: 357\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0214\n",
      "Epoch: 358\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0210\n",
      "Epoch: 359\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0213\n",
      "Epoch: 360\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0213\n",
      "Epoch: 361\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0213\n",
      "Epoch: 362\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0210\n",
      "Epoch: 363\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0213\n",
      "Epoch: 364\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0213\n",
      "Epoch: 365\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0210\n",
      "Epoch: 366\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0211\n",
      "Epoch: 367\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0211\n",
      "Epoch: 368\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0212\n",
      "Epoch: 369\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0211\n",
      "Epoch: 370\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0211\n",
      "Epoch: 371\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0209\n",
      "Epoch: 372\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0212\n",
      "Epoch: 373\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0211\n",
      "Epoch: 374\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0211\n",
      "Epoch: 375\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0211\n",
      "Epoch: 376\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0210\n",
      "Epoch: 377\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0212\n",
      "Epoch: 378\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0209\n",
      "Epoch: 379\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0211\n",
      "Epoch: 380\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0209\n",
      "Epoch: 381\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0209\n",
      "Epoch: 382\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0209\n",
      "Epoch: 383\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0209\n",
      "Epoch: 384\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0210\n",
      "Epoch: 385\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0210\n",
      "Epoch: 386\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0209\n",
      "Epoch: 387\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0208\n",
      "Epoch: 388\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0210\n",
      "Epoch: 389\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0210\n",
      "Epoch: 390\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0208\n",
      "Epoch: 391\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0210\n",
      "Epoch: 392\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0207\n",
      "Epoch: 393\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0210\n",
      "Epoch: 394\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0209\n",
      "Epoch: 395\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0208\n",
      "Epoch: 396\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0207\n",
      "Epoch: 397\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0206\n",
      "Epoch: 398\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0207\n",
      "Epoch: 399\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0208\n",
      "Epoch: 400\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0208\n",
      "Epoch: 401\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0207\n",
      "Epoch: 402\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0207\n",
      "Epoch: 403\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0208\n",
      "Epoch: 404\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0207\n",
      "Epoch: 405\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0206\n",
      "Epoch: 406\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0208\n",
      "Epoch: 407\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0206\n",
      "Epoch: 408\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0207\n",
      "Epoch: 409\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0206\n",
      "Epoch: 410\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0207\n",
      "Epoch: 411\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0207\n",
      "Epoch: 412\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0208\n",
      "Epoch: 413\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0207\n",
      "Epoch: 414\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0206\n",
      "Epoch: 415\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0206\n",
      "Epoch: 416\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0206\n",
      "Epoch: 417\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0206\n",
      "Epoch: 418\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 419\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0207\n",
      "Epoch: 420\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0206\n",
      "Epoch: 421\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0204\n",
      "Epoch: 422\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0206\n",
      "Epoch: 423\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 424\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0206\n",
      "Epoch: 425\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0206\n",
      "Epoch: 426\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 427\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 428\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 429\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 430\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 431\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 432\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0206\n",
      "Epoch: 433\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 434\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 435\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0203\n",
      "Epoch: 436\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 437\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0204\n",
      "Epoch: 438\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 439\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0204\n",
      "Epoch: 440\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0203\n",
      "Epoch: 441\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 442\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0204\n",
      "Epoch: 443\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0205\n",
      "Epoch: 444\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0203\n",
      "Epoch: 445\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0204\n",
      "Epoch: 446\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0203\n",
      "Epoch: 447\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0204\n",
      "Epoch: 448\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0204\n",
      "Epoch: 449\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0203\n",
      "Epoch: 450\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 451\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 452\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0204\n",
      "Epoch: 453\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0204\n",
      "Epoch: 454\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0203\n",
      "Epoch: 455\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 456\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 457\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0203\n",
      "Epoch: 458\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0203\n",
      "Epoch: 459\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 460\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 461\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0204\n",
      "Epoch: 462\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0204\n",
      "Epoch: 463\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 464\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 465\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0203\n",
      "Epoch: 466\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 467\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 468\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 469\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 470\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 471\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 472\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 473\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0203\n",
      "Epoch: 474\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 475\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0203\n",
      "Epoch: 476\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0203\n",
      "Epoch: 477\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 478\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 479\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 480\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 481\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 482\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 483\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 484\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 485\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 486\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0202\n",
      "Epoch: 487\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 488\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 489\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 490\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 491\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 492\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 493\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 494\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 495\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 496\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 497\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 498\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 499\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 500\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 501\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 502\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 503\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 504\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 505\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 506\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 507\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 508\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0201\n",
      "Epoch: 509\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 510\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 511\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0200\n",
      "Epoch: 512\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 513\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 514\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 515\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 516\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 517\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 518\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 519\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 520\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 521\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 522\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 523\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 524\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 525\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 526\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 527\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0199\n",
      "Epoch: 528\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 529\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 530\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 531\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 532\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 533\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 534\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 535\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 536\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 537\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0196\n",
      "Epoch: 538\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0198\n",
      "Epoch: 539\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 540\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 541\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0196\n",
      "Epoch: 542\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0196\n",
      "Epoch: 543\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0196\n",
      "Epoch: 544\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 545\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 546\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 547\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 548\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0196\n",
      "Epoch: 549\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 550\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0196\n",
      "Epoch: 551\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0196\n",
      "Epoch: 552\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0197\n",
      "Epoch: 553\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0195\n",
      "Epoch: 554\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0196\n",
      "Epoch: 555\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0195\n",
      "Epoch: 556\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0196\n",
      "Epoch: 557\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0196\n",
      "Epoch: 558\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0197\n",
      "Epoch: 559\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0195\n",
      "Epoch: 560\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0197\n",
      "Epoch: 561\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 562\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0197\n",
      "Epoch: 563\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0195\n",
      "Epoch: 564\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0196\n",
      "Epoch: 565\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0196\n",
      "Epoch: 566\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0196\n",
      "Epoch: 567\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0195\n",
      "Epoch: 568\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0195\n",
      "Epoch: 569\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0195\n",
      "Epoch: 570\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0195\n",
      "Epoch: 571\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0195\n",
      "Epoch: 572\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0195\n",
      "Epoch: 573\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 25ms/sample - loss: 0.0195\n",
      "Epoch: 574\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 24ms/sample - loss: 0.0195\n",
      "Epoch: 575\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0194\n",
      "Epoch: 576\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0196\n",
      "Epoch: 577\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0195\n",
      "Epoch: 578\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0195\n",
      "Epoch: 579\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 0.0193\n",
      "Epoch: 580\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0196\n",
      "Epoch: 581\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0194\n",
      "Epoch: 582\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0195\n",
      "Epoch: 583\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0194\n",
      "Epoch: 584\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0194\n",
      "Epoch: 585\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0193\n",
      "Epoch: 586\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0194\n",
      "Epoch: 587\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0195\n",
      "Epoch: 588\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0195\n",
      "Epoch: 589\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0194\n",
      "Epoch: 590\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0195\n",
      "Epoch: 591\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0193\n",
      "Epoch: 592\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0195\n",
      "Epoch: 593\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0194\n",
      "Epoch: 594\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0195\n",
      "Epoch: 595\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0193\n",
      "Epoch: 596\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0193\n",
      "Epoch: 597\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0193\n",
      "Epoch: 598\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0193\n",
      "Epoch: 599\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0192\n",
      "Epoch: 600\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0194\n",
      "Epoch: 601\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0193\n",
      "Epoch: 602\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0194\n",
      "Epoch: 603\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0193\n",
      "Epoch: 604\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0193\n",
      "Epoch: 605\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0193\n",
      "Epoch: 606\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0194\n",
      "Epoch: 607\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0193\n",
      "Epoch: 608\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0193\n",
      "Epoch: 609\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0193\n",
      "Epoch: 610\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0194\n",
      "Epoch: 611\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0192\n",
      "Epoch: 612\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0193\n",
      "Epoch: 613\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0192\n",
      "Epoch: 614\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0193\n",
      "Epoch: 615\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0192\n",
      "Epoch: 616\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0192\n",
      "Epoch: 617\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0193\n",
      "Epoch: 618\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0192\n",
      "Epoch: 619\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0192\n",
      "Epoch: 620\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0193\n",
      "Epoch: 621\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0192\n",
      "Epoch: 622\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0194\n",
      "Epoch: 623\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0191\n",
      "Epoch: 624\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0192\n",
      "Epoch: 625\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 626\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 627\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0192\n",
      "Epoch: 628\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0192\n",
      "Epoch: 629\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 630\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0192\n",
      "Epoch: 631\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0192\n",
      "Epoch: 632\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0191\n",
      "Epoch: 633\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 634\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0193\n",
      "Epoch: 635\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 636\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0193\n",
      "Epoch: 637\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0190\n",
      "Epoch: 638\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 639\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0191\n",
      "Epoch: 640\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0191\n",
      "Epoch: 641\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 642\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0190\n",
      "Epoch: 643\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0190\n",
      "Epoch: 644\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0191\n",
      "Epoch: 645\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0191\n",
      "Epoch: 646\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0191\n",
      "Epoch: 647\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 648\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0192\n",
      "Epoch: 649\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0190\n",
      "Epoch: 650\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 651\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0190\n",
      "Epoch: 652\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0190\n",
      "Epoch: 653\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0190\n",
      "Epoch: 654\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0190\n",
      "Epoch: 655\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0191\n",
      "Epoch: 656\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0190\n",
      "Epoch: 657\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0189\n",
      "Epoch: 658\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0191\n",
      "Epoch: 659\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0188\n",
      "Epoch: 660\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0190\n",
      "Epoch: 661\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0189\n",
      "Epoch: 662\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0189\n",
      "Epoch: 663\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0190\n",
      "Epoch: 664\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0191\n",
      "Epoch: 665\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0189\n",
      "Epoch: 666\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0191\n",
      "Epoch: 667\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0188\n",
      "Epoch: 668\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0190\n",
      "Epoch: 669\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0187\n",
      "Epoch: 670\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0190\n",
      "Epoch: 671\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0187\n",
      "Epoch: 672\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0190\n",
      "Epoch: 673\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0189\n",
      "Epoch: 674\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0189\n",
      "Epoch: 675\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0189\n",
      "Epoch: 676\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0189\n",
      "Epoch: 677\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0188\n",
      "Epoch: 678\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0189\n",
      "Epoch: 679\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0188\n",
      "Epoch: 680\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0189\n",
      "Epoch: 681\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0190\n",
      "Epoch: 682\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0188\n",
      "Epoch: 683\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0187\n",
      "Epoch: 684\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0189\n",
      "Epoch: 685\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0188\n",
      "Epoch: 686\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0188\n",
      "Epoch: 687\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0188\n",
      "Epoch: 688\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0188\n",
      "Epoch: 689\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0187\n",
      "Epoch: 690\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0188\n",
      "Epoch: 691\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0188\n",
      "Epoch: 692\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0188\n",
      "Epoch: 693\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0187\n",
      "Epoch: 694\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0188\n",
      "Epoch: 695\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0186\n",
      "Epoch: 696\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0189\n",
      "Epoch: 697\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0187\n",
      "Epoch: 698\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0188\n",
      "Epoch: 699\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0187\n",
      "Epoch: 700\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0189\n",
      "Epoch: 701\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0186\n",
      "Epoch: 702\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0187\n",
      "Epoch: 703\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0187\n",
      "Epoch: 704\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 705\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0187\n",
      "Epoch: 706\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0187\n",
      "Epoch: 707\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0185\n",
      "Epoch: 708\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0187\n",
      "Epoch: 709\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 710\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0188\n",
      "Epoch: 711\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 712\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0185\n",
      "Epoch: 713\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 714\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0187\n",
      "Epoch: 715\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0185\n",
      "Epoch: 716\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 717\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 718\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0187\n",
      "Epoch: 719\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 720\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 721\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 722\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 723\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0185\n",
      "Epoch: 724\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0185\n",
      "Epoch: 725\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0185\n",
      "Epoch: 726\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 727\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 728\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 729\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 730\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 731\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 732\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0187\n",
      "Epoch: 733\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 734\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 735\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 736\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0185\n",
      "Epoch: 737\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 738\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 739\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0182\n",
      "Epoch: 740\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0185\n",
      "Epoch: 741\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 742\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 743\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 744\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 745\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 746\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0186\n",
      "Epoch: 747\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 748\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0185\n",
      "Epoch: 749\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 750\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0185\n",
      "Epoch: 751\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0182\n",
      "Epoch: 752\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 753\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0182\n",
      "Epoch: 754\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 755\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0182\n",
      "Epoch: 756\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 757\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 758\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 759\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 760\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0185\n",
      "Epoch: 761\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 762\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0185\n",
      "Epoch: 763\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 764\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 765\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 766\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0182\n",
      "Epoch: 767\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0182\n",
      "Epoch: 768\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 769\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0181\n",
      "Epoch: 770\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 771\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0182\n",
      "Epoch: 772\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 773\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0182\n",
      "Epoch: 774\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 775\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0181\n",
      "Epoch: 776\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0182\n",
      "Epoch: 777\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0181\n",
      "Epoch: 778\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0183\n",
      "Epoch: 779\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0182\n",
      "Epoch: 780\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0184\n",
      "Epoch: 781\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0181\n",
      "Epoch: 782\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0183\n",
      "Epoch: 783\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0182\n",
      "Epoch: 784\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0182\n",
      "Epoch: 785\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0180\n",
      "Epoch: 786\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0182\n",
      "Epoch: 787\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0180\n",
      "Epoch: 788\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0181\n",
      "Epoch: 789\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0181\n",
      "Epoch: 790\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0181\n",
      "Epoch: 791\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0180\n",
      "Epoch: 792\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0183\n",
      "Epoch: 793\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0181\n",
      "Epoch: 794\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0182\n",
      "Epoch: 795\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0181\n",
      "Epoch: 796\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0183\n",
      "Epoch: 797\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0180\n",
      "Epoch: 798\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0181\n",
      "Epoch: 799\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0180\n",
      "Forecasting Training Data\n",
      "Month=1, Predicted=9.773115, Expected=9.510000\n",
      "Month=2, Predicted=9.945341, Expected=9.796000\n",
      "Month=3, Predicted=9.537498, Expected=9.468500\n",
      "Month=4, Predicted=9.673108, Expected=9.672000\n",
      "Month=5, Predicted=9.982364, Expected=9.610000\n",
      "Month=6, Predicted=9.387355, Expected=9.240000\n",
      "Month=7, Predicted=9.784697, Expected=10.318300\n",
      "Month=8, Predicted=9.797422, Expected=8.974800\n",
      "Month=9, Predicted=9.505750, Expected=9.114000\n",
      "Month=10, Predicted=9.573045, Expected=9.300000\n",
      "Month=11, Predicted=8.727603, Expected=8.400000\n",
      "Month=12, Predicted=9.383449, Expected=9.300000\n",
      "Month=13, Predicted=9.027504, Expected=9.000000\n",
      "Month=14, Predicted=9.681750, Expected=9.300000\n",
      "Month=15, Predicted=9.497178, Expected=9.460000\n",
      "Month=16, Predicted=8.967735, Expected=9.145000\n",
      "Month=17, Predicted=9.325685, Expected=9.021000\n",
      "Month=18, Predicted=8.888882, Expected=8.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-04-20 12:36:25.069107: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=19, Predicted=9.179914, Expected=8.710000\n",
      "Month=20, Predicted=8.618754, Expected=8.370000\n",
      "Month=21, Predicted=8.859569, Expected=8.504000\n",
      "Month=22, Predicted=8.838228, Expected=9.819700\n",
      "Month=23, Predicted=9.469123, Expected=9.827300\n",
      "Month=24, Predicted=10.298928, Expected=9.929800\n",
      "Month=25, Predicted=9.472516, Expected=9.288000\n",
      "Month=26, Predicted=9.935997, Expected=9.300000\n",
      "Month=27, Predicted=9.006805, Expected=9.060000\n",
      "Month=28, Predicted=9.314660, Expected=8.835000\n",
      "Month=29, Predicted=8.911151, Expected=8.388600\n",
      "Month=30, Predicted=8.424237, Expected=8.400000\n",
      "Month=31, Predicted=8.381300, Expected=8.525000\n",
      "Month=32, Predicted=8.095396, Expected=8.250000\n",
      "Month=33, Predicted=8.328345, Expected=8.419000\n",
      "Month=34, Predicted=8.704502, Expected=9.455000\n",
      "Month=35, Predicted=9.093552, Expected=8.540000\n",
      "Month=36, Predicted=9.048765, Expected=9.455000\n",
      "Month=37, Predicted=9.200268, Expected=9.000000\n",
      "Month=38, Predicted=9.467244, Expected=9.599000\n",
      "Month=39, Predicted=9.411132, Expected=9.436000\n",
      "Month=40, Predicted=9.829379, Expected=9.539800\n",
      "Month=41, Predicted=9.601707, Expected=9.028600\n",
      "Month=42, Predicted=9.442959, Expected=8.932000\n",
      "Month=43, Predicted=8.592108, Expected=8.993000\n",
      "Month=44, Predicted=8.832920, Expected=8.678400\n",
      "Month=45, Predicted=8.901030, Expected=9.011100\n",
      "Month=46, Predicted=9.199144, Expected=9.630000\n",
      "Month=47, Predicted=8.674259, Expected=8.590400\n",
      "Month=48, Predicted=9.480199, Expected=9.736300\n",
      "Month=49, Predicted=9.572710, Expected=9.384500\n",
      "Month=50, Predicted=10.179936, Expected=9.947200\n",
      "Month=51, Predicted=9.684835, Expected=9.577100\n",
      "Month=52, Predicted=9.847809, Expected=9.117200\n",
      "Month=53, Predicted=9.022643, Expected=9.122500\n",
      "Month=54, Predicted=9.076503, Expected=8.880000\n",
      "Month=55, Predicted=9.153353, Expected=8.709200\n",
      "Month=56, Predicted=8.765994, Expected=8.428200\n",
      "Month=57, Predicted=8.692782, Expected=9.907600\n",
      "Month=58, Predicted=9.035842, Expected=9.145000\n",
      "Month=59, Predicted=8.798937, Expected=8.498000\n",
      "Month=60, Predicted=9.467746, Expected=9.362000\n",
      "Month=61, Predicted=9.084591, Expected=9.000000\n",
      "Month=62, Predicted=9.506200, Expected=9.455000\n",
      "Month=63, Predicted=9.269089, Expected=9.300000\n",
      "Month=64, Predicted=9.611582, Expected=8.990000\n",
      "Month=65, Predicted=9.287026, Expected=8.990000\n",
      "Month=66, Predicted=8.986042, Expected=8.790000\n",
      "Month=67, Predicted=9.017906, Expected=8.835000\n",
      "Month=68, Predicted=8.915373, Expected=8.700000\n",
      "Month=69, Predicted=8.671726, Expected=8.935000\n",
      "Month=70, Predicted=8.879390, Expected=8.835000\n",
      "Month=71, Predicted=8.768363, Expected=8.265000\n",
      "Month=72, Predicted=8.545320, Expected=8.835000\n",
      "Month=73, Predicted=8.559713, Expected=8.550000\n",
      "Month=74, Predicted=8.819133, Expected=8.680000\n",
      "Month=75, Predicted=8.970411, Expected=8.400000\n",
      "Month=76, Predicted=8.481613, Expected=8.525000\n",
      "Month=77, Predicted=8.805599, Expected=8.370000\n",
      "Month=78, Predicted=8.222288, Expected=7.890000\n",
      "Month=79, Predicted=8.069096, Expected=7.812000\n",
      "Month=80, Predicted=7.550967, Expected=7.620000\n",
      "Month=81, Predicted=7.976844, Expected=7.718000\n",
      "Month=82, Predicted=7.844916, Expected=8.323500\n",
      "Month=83, Predicted=7.233126, Expected=6.860000\n",
      "Month=84, Predicted=8.345285, Expected=8.308000\n",
      "Month=85, Predicted=8.198738, Expected=8.100000\n",
      "Month=86, Predicted=8.589488, Expected=8.525000\n",
      "Month=87, Predicted=8.231057, Expected=8.250000\n",
      "Month=88, Predicted=8.548101, Expected=8.215000\n",
      "Month=89, Predicted=8.135355, Expected=8.122600\n",
      "Month=90, Predicted=8.169351, Expected=7.778100\n",
      "Month=91, Predicted=8.259157, Expected=7.954600\n",
      "Month=92, Predicted=8.310864, Expected=7.420000\n",
      "Month=93, Predicted=7.850650, Expected=7.538300\n",
      "Month=94, Predicted=7.556077, Expected=7.905000\n",
      "Month=95, Predicted=6.999524, Expected=7.140000\n",
      "Month=96, Predicted=8.087264, Expected=8.432000\n",
      "Month=97, Predicted=7.934158, Expected=7.710000\n",
      "Month=98, Predicted=8.058126, Expected=7.967000\n",
      "Month=99, Predicted=7.667912, Expected=7.320000\n",
      "Month=100, Predicted=7.980347, Expected=7.502000\n",
      "Month=101, Predicted=7.281829, Expected=7.409000\n",
      "Month=102, Predicted=7.290880, Expected=7.200600\n",
      "Month=103, Predicted=7.611070, Expected=7.865000\n",
      "Month=104, Predicted=7.411574, Expected=6.690000\n",
      "Month=105, Predicted=7.597846, Expected=6.879400\n",
      "Month=106, Predicted=7.183226, Expected=7.440000\n",
      "Month=107, Predicted=6.699140, Expected=6.860000\n",
      "Month=108, Predicted=7.382061, Expected=7.595000\n",
      "Month=109, Predicted=7.383575, Expected=7.200000\n",
      "Month=110, Predicted=7.414981, Expected=7.130000\n",
      "Month=111, Predicted=6.919748, Expected=6.900000\n",
      "Month=112, Predicted=7.305043, Expected=7.130000\n",
      "Month=113, Predicted=7.304238, Expected=7.130000\n",
      "Month=114, Predicted=6.644904, Expected=6.840000\n",
      "Month=115, Predicted=7.188709, Expected=7.006000\n",
      "Month=116, Predicted=7.310130, Expected=6.780000\n",
      "Month=117, Predicted=6.876720, Expected=7.089600\n",
      "Month=118, Predicted=7.186908, Expected=6.882000\n",
      "Month=119, Predicted=6.977966, Expected=6.446700\n",
      "Month=120, Predicted=6.529986, Expected=6.882000\n",
      "Month=121, Predicted=6.760272, Expected=6.600000\n",
      "Month=122, Predicted=6.916680, Expected=6.820000\n",
      "Month=123, Predicted=7.064972, Expected=6.600000\n",
      "Month=124, Predicted=6.722537, Expected=6.820000\n",
      "Month=125, Predicted=6.988039, Expected=6.665000\n",
      "Month=126, Predicted=6.693918, Expected=6.450000\n",
      "Month=127, Predicted=6.815709, Expected=6.665000\n",
      "Month=128, Predicted=6.829475, Expected=6.450000\n",
      "Month=129, Predicted=6.565797, Expected=6.722100\n",
      "Month=130, Predicted=6.830843, Expected=6.820000\n",
      "Month=131, Predicted=6.221671, Expected=6.160000\n",
      "Month=132, Predicted=6.846710, Expected=6.820000\n",
      "Month=133, Predicted=6.532627, Expected=6.480000\n",
      "Month=134, Predicted=6.727630, Expected=6.596900\n",
      "Month=135, Predicted=6.891092, Expected=6.492000\n",
      "Month=136, Predicted=6.245374, Expected=6.510000\n",
      "Month=137, Predicted=6.335145, Expected=6.339500\n",
      "Month=138, Predicted=6.454389, Expected=6.001600\n",
      "Month=139, Predicted=6.231446, Expected=6.107000\n",
      "Month=140, Predicted=6.375336, Expected=5.790000\n",
      "Month=141, Predicted=5.938006, Expected=5.885000\n",
      "Month=142, Predicted=6.145635, Expected=7.280000\n",
      "Month=143, Predicted=6.193531, Expected=5.941600\n",
      "Month=144, Predicted=6.786941, Expected=6.810000\n",
      "Month=145, Predicted=6.355584, Expected=6.182000\n",
      "Month=146, Predicted=6.542026, Expected=6.293000\n",
      "Month=147, Predicted=6.087669, Expected=6.118600\n",
      "Month=148, Predicted=6.027699, Expected=6.138000\n",
      "Month=149, Predicted=6.147121, Expected=6.107000\n",
      "Month=150, Predicted=5.721259, Expected=5.913000\n",
      "Month=151, Predicted=6.193006, Expected=6.141100\n",
      "Month=152, Predicted=6.242561, Expected=6.248000\n",
      "Month=153, Predicted=5.696665, Expected=5.829700\n",
      "Month=154, Predicted=6.112974, Expected=6.829300\n",
      "Month=155, Predicted=6.404090, Expected=6.694400\n",
      "Month=156, Predicted=7.772846, Expected=7.726200\n",
      "Month=157, Predicted=7.224548, Expected=7.054400\n",
      "Month=158, Predicted=7.517836, Expected=7.268900\n",
      "Month=159, Predicted=6.981540, Expected=7.020000\n",
      "Month=160, Predicted=7.166801, Expected=6.510000\n",
      "Month=161, Predicted=6.469402, Expected=6.370500\n",
      "Month=162, Predicted=5.951202, Expected=5.730000\n",
      "Month=163, Predicted=5.898322, Expected=5.828000\n",
      "Month=164, Predicted=5.602136, Expected=5.580000\n",
      "Month=165, Predicted=5.642705, Expected=5.709900\n",
      "Month=166, Predicted=5.953247, Expected=6.696000\n",
      "Month=167, Predicted=6.140948, Expected=6.248000\n",
      "Month=168, Predicted=6.847776, Expected=6.711600\n",
      "Month=169, Predicted=6.569522, Expected=6.600100\n",
      "Month=170, Predicted=6.901114, Expected=7.508200\n",
      "Month=171, Predicted=7.070329, Expected=7.765000\n",
      "Month=172, Predicted=7.295694, Expected=7.285000\n",
      "Month=173, Predicted=7.647647, Expected=6.959500\n",
      "Month=174, Predicted=6.708307, Expected=6.450000\n",
      "Month=175, Predicted=6.388060, Expected=6.572000\n",
      "Month=176, Predicted=6.662734, Expected=6.600000\n",
      "Month=177, Predicted=5.658093, Expected=4.265300\n",
      "Month=178, Predicted=7.333959, Expected=7.367000\n",
      "Month=179, Predicted=6.509882, Expected=6.544000\n",
      "Month=180, Predicted=6.839659, Expected=6.940800\n",
      "Train RMSE: 0.36387\n",
      "Train RMSPE: 5.07238\n",
      "Train MAE: 0.27089\n",
      "Train MAPE: 3.54527\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=6.505035, Expected=6.786000\n",
      "Month=2, Predicted=6.961184, Expected=6.981200\n",
      "Month=3, Predicted=7.017814, Expected=6.756000\n",
      "Month=4, Predicted=6.869866, Expected=6.733200\n",
      "Month=5, Predicted=6.754427, Expected=6.671200\n",
      "Month=6, Predicted=6.560818, Expected=6.295600\n",
      "Month=7, Predicted=6.836198, Expected=6.432500\n",
      "Month=8, Predicted=6.743599, Expected=6.153000\n",
      "Month=9, Predicted=6.236481, Expected=6.389500\n",
      "Month=10, Predicted=6.616651, Expected=7.192000\n",
      "Month=11, Predicted=6.575966, Expected=6.524000\n",
      "Month=12, Predicted=6.861217, Expected=7.238500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=13, Predicted=6.966441, Expected=6.990000\n",
      "Month=14, Predicted=7.366460, Expected=7.254000\n",
      "Month=15, Predicted=7.421742, Expected=6.720000\n",
      "Month=16, Predicted=7.180200, Expected=6.944000\n",
      "Month=17, Predicted=7.039934, Expected=7.052500\n",
      "Month=18, Predicted=6.506920, Expected=6.690000\n",
      "Month=19, Predicted=6.896070, Expected=6.909900\n",
      "Month=20, Predicted=7.240758, Expected=6.819000\n",
      "Month=21, Predicted=6.738189, Expected=7.167200\n",
      "Month=22, Predicted=6.885376, Expected=7.254000\n",
      "Month=23, Predicted=6.580728, Expected=6.664000\n",
      "Month=24, Predicted=7.229574, Expected=7.393500\n",
      "Month=25, Predicted=7.175849, Expected=7.125000\n",
      "Month=26, Predicted=7.485343, Expected=7.347000\n",
      "Month=27, Predicted=7.574934, Expected=7.216500\n",
      "Month=28, Predicted=7.203614, Expected=7.254000\n",
      "Month=29, Predicted=7.170729, Expected=7.238500\n",
      "Month=30, Predicted=6.717854, Expected=6.990000\n",
      "Month=31, Predicted=7.317925, Expected=7.192000\n",
      "Month=32, Predicted=7.415355, Expected=6.900000\n",
      "Month=33, Predicted=7.081956, Expected=7.427300\n",
      "Month=34, Predicted=7.112947, Expected=7.300500\n",
      "Month=35, Predicted=7.656105, Expected=6.902000\n",
      "Month=36, Predicted=7.233159, Expected=7.409000\n",
      "Month=37, Predicted=7.205509, Expected=7.179000\n",
      "Month=38, Predicted=7.493666, Expected=7.424500\n",
      "Month=39, Predicted=7.585270, Expected=7.275000\n",
      "Month=40, Predicted=7.290285, Expected=7.316000\n",
      "Month=41, Predicted=7.288081, Expected=7.086300\n",
      "Month=42, Predicted=7.258667, Expected=7.020000\n",
      "Month=43, Predicted=7.008729, Expected=7.270500\n",
      "Month=44, Predicted=7.012947, Expected=7.168800\n",
      "Month=45, Predicted=7.102856, Expected=7.448600\n",
      "Month=46, Predicted=7.265307, Expected=7.440200\n",
      "Test RMSE: 0.29825\n",
      "Test RMSPE: 4.33104\n",
      "Test MAE: 0.23483\n",
      "Test MAPE: 3.37810\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bilstm static 3 layer \n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='relu')))\n",
    "    model.add(Dense(1))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=2\n",
    "\tneurons=[5,4,2] \n",
    "\tn_epochs=800\n",
    "\t\n",
    "\t\n",
    "mode\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d6bc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 23:54:40.705197: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-20 23:54:40.705229: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_19346/1688501583.py:24: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_19346/1688501583.py:241: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_19346/1688501583.py:145: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 23:54:42.741721: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-20 23:54:42.742430: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 23:54:42.816809: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-20 23:54:42.950988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 24s 120ms/sample - loss: 0.0470\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 0.0394\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0357\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0342\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0334\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0329\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0325\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 0.0321\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 0.0317\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0314\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0312\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0311\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0308\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0306\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0305\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0303\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0303\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0302\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0299\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0294\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0291\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0299\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0291\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0293\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0289\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0294\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0286\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0280\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0275\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0295\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0279\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0270\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0264\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0272\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0265\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0268\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0289\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0284\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0269\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0261\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0257\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0252\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0248\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0235\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0244\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0240\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0263\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0237\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0227\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0233\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0207\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0196\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0267\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 0.0195\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0196\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0230\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0204\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0184\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0217\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0198\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0211\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0187\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0196\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0163\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0154\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0201\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0201\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0176\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0143\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0149\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0144\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0147\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0193\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 0.0149\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0166\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0119\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0153\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0110\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 0.0202\n",
      "Epoch: 79\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0155\n",
      "Epoch: 80\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0134\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0109\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 0.0092\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 0.0090\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 0.0085\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0074\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0071\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0086\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0074\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0078\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0098\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0085\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0090\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0136\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0093\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0114\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0092\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0117\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0087\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0061\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0062\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0066\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0059\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0054\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0064\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0062\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0070\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0062\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0207\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0283\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0279\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0193\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0158\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0134\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0104\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0087\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0071\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0074\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0077\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0099\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0071\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0055\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0055\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0043\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 0.0041\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0054\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0055\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0092\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0184\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0148\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0082\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0055\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0055\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 0.0050\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0058\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0090\n",
      "Epoch: 136\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0060\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0053\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0051\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0035\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0040\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0034\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0035\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0035\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0059\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0062\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0054\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0198\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0152\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0056\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0040\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0039\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0030\n",
      "Epoch: 153\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0033\n",
      "Epoch: 154\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0045\n",
      "Epoch: 155\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0030\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0035\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0032\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0039\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0071\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0079\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0046\n",
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0050\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0037\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0035\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0031\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0040\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0037\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0023\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0038\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0040\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0040\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0034\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0030\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0025\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0034\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0024\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0072\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0076\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0049\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0030\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0025\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0013\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0011\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0056\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0033\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0034\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0028\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0017\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 7.8233e-04\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 9.4715e-04\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0011\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0015\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0048\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0075\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0189\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0155\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0086\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0031\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0019\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0029\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0084\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0033\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0012\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 4.8878e-04\n",
      "Epoch: 205\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 3.3106e-04\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 2.7002e-04\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 2.9809e-04\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 8.4861e-04\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 9.8118e-04\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 6.7784e-04\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 5.4724e-04\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 6.2047e-04\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0012\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0073\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0127\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0136\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0084\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0063\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0034\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0018\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 9.7309e-04\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 5.8373e-04\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 4.2921e-04\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 3.7897e-04\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 3.1621e-04\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 2.5654e-04\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 2.8310e-04\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 3.6716e-04\n",
      "Epoch: 229\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 4.4510e-04\n",
      "Epoch: 230\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 22s 124ms/sample - loss: 6.8915e-04\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 7.3129e-04\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0038\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0209\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0070\n",
      "Epoch: 235\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0084\n",
      "Epoch: 236\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0037\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0093\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0128\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0061\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0027\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0016\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 8.2135e-04\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 2.8026e-04\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 1.8031e-04\n",
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 2.7356e-04\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 6.4552e-04\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 4.9540e-04\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 4.1963e-04\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 3.9724e-04\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 2.9441e-04\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.3275e-04\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 6.9298e-04\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0094\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0137\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0177\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0077\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0027\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0013\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 6.4863e-04\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 3.6304e-04\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 3.4201e-04\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 3.1158e-04\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 3.5092e-04\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 5.2495e-04\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 8.4101e-04\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 7.0545e-04\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 5.8543e-04\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 8.8590e-04\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0015\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0024\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0073\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0060\n",
      "Epoch: 273\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0048\n",
      "Epoch: 274\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0049\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0039\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0040\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0024\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0023\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0030\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 9.9550e-04\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.7050e-04\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 2.3436e-04\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 2.2590e-04\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 1.5721e-04\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 1.4625e-04\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 2.1232e-04\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.8644e-04\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 7.7770e-04\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0012\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0015\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0024\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0060\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0093\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0070\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0015\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 7.4215e-04\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 4.0665e-04\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 3.2926e-04\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.0036e-04\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 1.7778e-04\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.2285e-04\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 2.6256e-04\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 2.7060e-04\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0011\n",
      "Epoch: 305\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0027\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0014\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0016\n",
      "Epoch: 308\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 7.8684e-04\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 5.2001e-04\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 2.9574e-04\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 2.9115e-04\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 3.0221e-04\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 3.7669e-04\n",
      "Epoch: 314\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 6.1107e-04\n",
      "Epoch: 315\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 6.1416e-04\n",
      "Epoch: 316\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 6.3742e-04\n",
      "Epoch: 317\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0016\n",
      "Epoch: 318\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0158\n",
      "Epoch: 319\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0169\n",
      "Epoch: 320\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0104\n",
      "Epoch: 321\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0082\n",
      "Epoch: 322\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0030\n",
      "Epoch: 323\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0019\n",
      "Epoch: 324\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0021\n",
      "Epoch: 325\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 8.3273e-04\n",
      "Epoch: 326\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.9423e-04\n",
      "Epoch: 327\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 2.6835e-04\n",
      "Epoch: 328\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 1.8875e-04\n",
      "Epoch: 329\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 2.0457e-04\n",
      "Epoch: 330\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 1.9493e-04\n",
      "Epoch: 331\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 2.1586e-04\n",
      "Epoch: 332\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 2.6306e-04\n",
      "Epoch: 333\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.9941e-04\n",
      "Epoch: 334\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 5.2125e-04\n",
      "Epoch: 335\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 5.7399e-04\n",
      "Epoch: 336\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 6.4405e-04\n",
      "Epoch: 337\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0022\n",
      "Epoch: 338\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0077\n",
      "Epoch: 339\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0051\n",
      "Epoch: 340\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0033\n",
      "Epoch: 341\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0023\n",
      "Epoch: 342\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 6.9918e-04\n",
      "Epoch: 343\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 3.3059e-04\n",
      "Epoch: 344\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 1.1290e-04\n",
      "Epoch: 345\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 8.3480e-05\n",
      "Epoch: 346\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 3.6403e-05\n",
      "Epoch: 347\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 3.3073e-05\n",
      "Epoch: 348\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 3.2497e-05\n",
      "Epoch: 349\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 2.9372e-05\n",
      "Epoch: 350\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 5.3392e-05\n",
      "Epoch: 351\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 8.9612e-05\n",
      "Epoch: 352\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 2.2439e-04\n",
      "Epoch: 353\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 4.2297e-04\n",
      "Epoch: 354\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0010\n",
      "Epoch: 355\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0012\n",
      "Epoch: 356\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0041\n",
      "Epoch: 357\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0096\n",
      "Epoch: 358\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0049\n",
      "Epoch: 359\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0026\n",
      "Epoch: 360\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0018\n",
      "Epoch: 361\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0010\n",
      "Epoch: 362\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 6.5220e-04\n",
      "Epoch: 363\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0012\n",
      "Epoch: 364\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 4.7216e-04\n",
      "Epoch: 365\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 2.1510e-04\n",
      "Epoch: 366\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 1.5195e-04\n",
      "Epoch: 367\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 9.0391e-05\n",
      "Epoch: 368\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 6.4419e-05\n",
      "Epoch: 369\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 8.3952e-05\n",
      "Epoch: 370\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 8.0469e-05\n",
      "Epoch: 371\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 1.5128e-04\n",
      "Epoch: 372\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 2.6754e-04\n",
      "Epoch: 373\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 4.5836e-04\n",
      "Epoch: 374\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 7.9123e-04\n",
      "Epoch: 375\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0024\n",
      "Epoch: 376\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0038\n",
      "Epoch: 377\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0041\n",
      "Epoch: 378\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0098\n",
      "Epoch: 379\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0065\n",
      "Epoch: 380\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0023\n",
      "Epoch: 381\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 6.3419e-04\n",
      "Epoch: 382\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 2.9162e-04\n",
      "Epoch: 383\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 2.4269e-04\n",
      "Epoch: 384\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 1.6351e-04\n",
      "Epoch: 385\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 7.1117e-05\n",
      "Epoch: 386\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 4.2025e-05\n",
      "Epoch: 387\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.8144e-05\n",
      "Epoch: 388\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.9954e-05\n",
      "Epoch: 389\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 4.0411e-05\n",
      "Epoch: 390\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 5.9784e-05\n",
      "Epoch: 391\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 1.2126e-04\n",
      "Epoch: 392\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 2.2041e-04\n",
      "Epoch: 393\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 3.9382e-04\n",
      "Epoch: 394\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0012\n",
      "Epoch: 395\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0050\n",
      "Epoch: 396\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0058\n",
      "Epoch: 397\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0036\n",
      "Epoch: 398\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0016\n",
      "Epoch: 399\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 6.6893e-04\n",
      "Epoch: 400\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 2.3150e-04\n",
      "Epoch: 401\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 9.2607e-05\n",
      "Epoch: 402\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 5.1623e-05\n",
      "Epoch: 403\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.5972e-05\n",
      "Epoch: 404\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.1663e-05\n",
      "Epoch: 405\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 5.7236e-05\n",
      "Epoch: 406\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 1.2823e-04\n",
      "Epoch: 407\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.1825e-04\n",
      "Epoch: 408\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 5.1123e-04\n",
      "Epoch: 409\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 5.8008e-04\n",
      "Epoch: 410\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 5.0050e-04\n",
      "Epoch: 411\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 3.9249e-04\n",
      "Epoch: 412\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0011\n",
      "Epoch: 413\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0048\n",
      "Epoch: 414\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 0.0043\n",
      "Epoch: 415\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0021\n",
      "Epoch: 416\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 4.6611e-04\n",
      "Epoch: 417\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 1.6140e-04\n",
      "Epoch: 418\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 9.8627e-05\n",
      "Epoch: 419\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 6.7666e-05\n",
      "Epoch: 420\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 5.1294e-05\n",
      "Epoch: 421\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 3.7438e-05\n",
      "Epoch: 422\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 2.9163e-05\n",
      "Epoch: 423\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 3.5878e-05\n",
      "Epoch: 424\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 4.5980e-05\n",
      "Epoch: 425\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.0044e-04\n",
      "Epoch: 426\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 2.0612e-04\n",
      "Epoch: 427\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0031\n",
      "Epoch: 428\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 0.0166\n",
      "Epoch: 429\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0069\n",
      "Epoch: 430\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0071\n",
      "Epoch: 431\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0174\n",
      "Epoch: 432\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0045\n",
      "Epoch: 433\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 0.0014\n",
      "Epoch: 434\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 4.3599e-04\n",
      "Epoch: 435\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.9820e-04\n",
      "Epoch: 436\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.0045e-04\n",
      "Epoch: 437\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 5.6575e-05\n",
      "Epoch: 438\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 3.6726e-05\n",
      "Epoch: 439\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 2.4604e-05\n",
      "Epoch: 440\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 1.8484e-05\n",
      "Epoch: 441\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 1.2772e-05\n",
      "Epoch: 442\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 1.0518e-05\n",
      "Epoch: 443\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 1.0367e-05\n",
      "Epoch: 444\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 1.8847e-05\n",
      "Epoch: 445\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 4.3469e-05\n",
      "Epoch: 446\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 1.1349e-04\n",
      "Epoch: 447\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 2.9605e-04\n",
      "Epoch: 448\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 5.6022e-04\n",
      "Epoch: 449\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14574s 81s/sample - loss: 7.6553e-04\n",
      "Epoch: 450\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 8.4277e-04\n",
      "Epoch: 451\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0014\n",
      "Epoch: 452\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 135ms/sample - loss: 5.8733e-04\n",
      "Epoch: 453\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 141ms/sample - loss: 0.0041\n",
      "Epoch: 454\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 140ms/sample - loss: 0.0085\n",
      "Epoch: 455\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0039\n",
      "Epoch: 456\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 135ms/sample - loss: 0.0022\n",
      "Epoch: 457\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 132ms/sample - loss: 9.4707e-04\n",
      "Epoch: 458\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 132ms/sample - loss: 6.6846e-04\n",
      "Epoch: 459\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 26s 142ms/sample - loss: 3.1538e-04\n",
      "Epoch: 460\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 1.7392e-04\n",
      "Epoch: 461\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 139ms/sample - loss: 6.1742e-05\n",
      "Epoch: 462\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 4.2239e-05\n",
      "Epoch: 463\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 2.7519e-05\n",
      "Epoch: 464\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 2.1888e-05\n",
      "Epoch: 465\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 2.0832e-05\n",
      "Epoch: 466\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 2.5970e-05\n",
      "Epoch: 467\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 2.9131e-05\n",
      "Epoch: 468\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 7.2534e-05\n",
      "Epoch: 469\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 1.4907e-04\n",
      "Epoch: 470\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 3.9753e-04\n",
      "Epoch: 471\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 9.7221e-04\n",
      "Epoch: 472\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0013\n",
      "Epoch: 473\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 8.6794e-04\n",
      "Epoch: 474\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 8.6281e-04\n",
      "Epoch: 475\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 9.4257e-04\n",
      "Epoch: 476\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 7.6428e-04\n",
      "Epoch: 477\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 5.9018e-04\n",
      "Epoch: 478\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 5.2700e-04\n",
      "Epoch: 479\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0041\n",
      "Epoch: 480\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0062\n",
      "Epoch: 481\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0042\n",
      "Epoch: 482\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 0.0027\n",
      "Epoch: 483\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0015\n",
      "Epoch: 484\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0026\n",
      "Epoch: 485\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0013\n",
      "Epoch: 486\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 3.2783e-04\n",
      "Epoch: 487\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 1.7416e-04\n",
      "Epoch: 488\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 1.1491e-04\n",
      "Epoch: 489\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 1.1952e-04\n",
      "Epoch: 490\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 133ms/sample - loss: 8.3936e-05\n",
      "Epoch: 491\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 133ms/sample - loss: 9.1967e-05\n",
      "Epoch: 492\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 134ms/sample - loss: 1.1309e-04\n",
      "Epoch: 493\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 134ms/sample - loss: 1.1535e-04\n",
      "Epoch: 494\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 133ms/sample - loss: 1.4541e-04\n",
      "Epoch: 495\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 133ms/sample - loss: 1.9498e-04\n",
      "Epoch: 496\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 134ms/sample - loss: 3.1235e-04\n",
      "Epoch: 497\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 134ms/sample - loss: 6.5642e-04\n",
      "Epoch: 498\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 134ms/sample - loss: 8.2910e-04\n",
      "Epoch: 499\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 135ms/sample - loss: 0.0037\n",
      "Epoch: 500\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 139ms/sample - loss: 0.0053\n",
      "Epoch: 501\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 27s 149ms/sample - loss: 0.0050\n",
      "Epoch: 502\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 29s 161ms/sample - loss: 0.0039\n",
      "Epoch: 503\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 30s 167ms/sample - loss: 0.0014\n",
      "Epoch: 504\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 29s 163ms/sample - loss: 5.6755e-04\n",
      "Epoch: 505\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 28s 157ms/sample - loss: 3.0156e-04\n",
      "Epoch: 506\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 27s 150ms/sample - loss: 1.6376e-04\n",
      "Epoch: 507\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 26s 146ms/sample - loss: 1.4698e-04\n",
      "Epoch: 508\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 142ms/sample - loss: 1.1522e-04\n",
      "Epoch: 509\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 138ms/sample - loss: 1.1928e-04\n",
      "Epoch: 510\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 138ms/sample - loss: 1.5829e-04\n",
      "Epoch: 511\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 142ms/sample - loss: 1.1729e-04\n",
      "Epoch: 512\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 141ms/sample - loss: 1.6563e-04\n",
      "Epoch: 513\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 26s 142ms/sample - loss: 2.6697e-04\n",
      "Epoch: 514\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 139ms/sample - loss: 5.0564e-04\n",
      "Epoch: 515\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 26s 142ms/sample - loss: 5.6881e-04\n",
      "Epoch: 516\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 26s 144ms/sample - loss: 5.5711e-04\n",
      "Epoch: 517\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 26s 142ms/sample - loss: 8.1558e-04\n",
      "Epoch: 518\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 139ms/sample - loss: 0.0011\n",
      "Epoch: 519\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 138ms/sample - loss: 0.0022\n",
      "Epoch: 520\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 137ms/sample - loss: 0.0013\n",
      "Epoch: 521\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 137ms/sample - loss: 8.3916e-04\n",
      "Epoch: 522\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 136ms/sample - loss: 3.8552e-04\n",
      "Epoch: 523\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 136ms/sample - loss: 2.3359e-04\n",
      "Epoch: 524\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 136ms/sample - loss: 1.4735e-04\n",
      "Epoch: 525\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 135ms/sample - loss: 1.6124e-04\n",
      "Epoch: 526\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 135ms/sample - loss: 1.3463e-04\n",
      "Epoch: 527\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 135ms/sample - loss: 1.9568e-04\n",
      "Epoch: 528\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 24s 133ms/sample - loss: 1.8964e-04\n",
      "Epoch: 529\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 132ms/sample - loss: 2.5115e-04\n",
      "Epoch: 530\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 133ms/sample - loss: 4.9541e-04\n",
      "Epoch: 531\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 132ms/sample - loss: 0.0018\n",
      "Epoch: 532\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 132ms/sample - loss: 0.0021\n",
      "Epoch: 533\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 133ms/sample - loss: 0.0018\n",
      "Epoch: 534\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 133ms/sample - loss: 0.0012\n",
      "Epoch: 535\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 0.0014\n",
      "Epoch: 536\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 0.0018\n",
      "Epoch: 537\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 134ms/sample - loss: 6.6024e-04\n",
      "Epoch: 538\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 132ms/sample - loss: 5.5537e-04\n",
      "Epoch: 539\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 3.1890e-04\n",
      "Epoch: 540\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 1.5567e-04\n",
      "Epoch: 541\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.0111e-04\n",
      "Epoch: 542\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 8.6046e-05\n",
      "Epoch: 543\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 7.8394e-05\n",
      "Epoch: 544\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 8.8933e-05\n",
      "Epoch: 545\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.2520e-04\n",
      "Epoch: 546\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 2.1055e-04\n",
      "Epoch: 547\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 4.1289e-04\n",
      "Epoch: 548\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 139ms/sample - loss: 5.3863e-04\n",
      "Epoch: 549\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 7.1779e-04\n",
      "Epoch: 550\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 0.0078\n",
      "Epoch: 551\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 136ms/sample - loss: 0.0082\n",
      "Epoch: 552\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0053\n",
      "Epoch: 553\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 0.0019\n",
      "Epoch: 554\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 0.0014\n",
      "Epoch: 555\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.9225e-04\n",
      "Epoch: 556\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 9.5037e-05\n",
      "Epoch: 557\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 6.1523e-05\n",
      "Epoch: 558\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 2.7104e-05\n",
      "Epoch: 559\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.8076e-05\n",
      "Epoch: 560\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.5234e-05\n",
      "Epoch: 561\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.2866e-05\n",
      "Epoch: 562\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 9.7689e-06\n",
      "Epoch: 563\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 1.0386e-05\n",
      "Epoch: 564\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.2316e-05\n",
      "Epoch: 565\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 2.6023e-05\n",
      "Epoch: 566\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 6.0144e-05\n",
      "Epoch: 567\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.4592e-04\n",
      "Epoch: 568\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 2.5623e-04\n",
      "Epoch: 569\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 5.7287e-04\n",
      "Epoch: 570\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 8.6235e-04\n",
      "Epoch: 571\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0030\n",
      "Epoch: 572\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0046\n",
      "Epoch: 573\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0045\n",
      "Epoch: 574\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0023\n",
      "Epoch: 575\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 7.9191e-04\n",
      "Epoch: 576\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 4.7144e-04\n",
      "Epoch: 577\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 0.0045\n",
      "Epoch: 578\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 3.3983e-04\n",
      "Epoch: 579\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.1672e-04\n",
      "Epoch: 580\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 4.6257e-05\n",
      "Epoch: 581\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 2.7459e-05\n",
      "Epoch: 582\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 2.0197e-05\n",
      "Epoch: 583\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 1.6549e-05\n",
      "Epoch: 584\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 3.0178e-05\n",
      "Epoch: 585\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 6.0665e-05\n",
      "Epoch: 586\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 1.4006e-04\n",
      "Epoch: 587\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 24s 131ms/sample - loss: 2.3718e-04\n",
      "Epoch: 588\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 3.3843e-04\n",
      "Epoch: 589\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 3.6300e-04\n",
      "Epoch: 590\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 6.3484e-04\n",
      "Epoch: 591\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 0.0028\n",
      "Epoch: 592\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 0.0040\n",
      "Epoch: 593\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 130ms/sample - loss: 0.0035\n",
      "Epoch: 594\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 8.8342e-04\n",
      "Epoch: 595\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 0.0013\n",
      "Epoch: 596\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 0.0047\n",
      "Epoch: 597\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 9.5352e-04\n",
      "Epoch: 598\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 6.3566e-04\n",
      "Epoch: 599\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 2.5678e-04\n",
      "Epoch: 600\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 1.0409e-04\n",
      "Epoch: 601\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 129ms/sample - loss: 3.7405e-05\n",
      "Epoch: 602\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 2.6179e-05\n",
      "Epoch: 603\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 2.3487e-05\n",
      "Epoch: 604\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 1.7345e-05\n",
      "Epoch: 605\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 1.5451e-05\n",
      "Epoch: 606\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 1.4502e-05\n",
      "Epoch: 607\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 2.2376e-05\n",
      "Epoch: 608\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 128ms/sample - loss: 3.1148e-05\n",
      "Epoch: 609\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 6.8134e-05\n",
      "Epoch: 610\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 1.8592e-04\n",
      "Epoch: 611\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 3.9585e-04\n",
      "Epoch: 612\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 5.0349e-04\n",
      "Epoch: 613\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 7.2849e-04\n",
      "Epoch: 614\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 4.6944e-04\n",
      "Epoch: 615\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 5.0250e-04\n",
      "Epoch: 616\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 3.2639e-04\n",
      "Epoch: 617\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 6.8900e-04\n",
      "Epoch: 618\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 6.3215e-04\n",
      "Epoch: 619\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 127ms/sample - loss: 0.0011\n",
      "Epoch: 620\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0032\n",
      "Epoch: 621\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 126ms/sample - loss: 0.0036\n",
      "Epoch: 622\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 0.0012\n",
      "Epoch: 623\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 125ms/sample - loss: 3.0720e-04\n",
      "Epoch: 624\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 23s 125ms/sample - loss: 1.7747e-04\n",
      "Epoch: 625\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 124ms/sample - loss: 1.3255e-04\n",
      "Epoch: 626\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 8.6645e-05\n",
      "Epoch: 627\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 7.2308e-05\n",
      "Epoch: 628\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 6.5524e-05\n",
      "Epoch: 629\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 7.2848e-05\n",
      "Epoch: 630\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 8.8689e-05\n",
      "Epoch: 631\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 1.0263e-04\n",
      "Epoch: 632\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 1.7685e-04\n",
      "Epoch: 633\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 2.1326e-04\n",
      "Epoch: 634\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 2.9644e-04\n",
      "Epoch: 635\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 3.5706e-04\n",
      "Epoch: 636\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 5.4396e-04\n",
      "Epoch: 637\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0042\n",
      "Epoch: 638\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 0.0049\n",
      "Epoch: 639\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 123ms/sample - loss: 7.4324e-04\n",
      "Epoch: 640\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 5.2916e-04\n",
      "Epoch: 641\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 119ms/sample - loss: 3.5816e-04\n",
      "Epoch: 642\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 119ms/sample - loss: 1.6313e-04\n",
      "Epoch: 643\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 119ms/sample - loss: 5.3927e-05\n",
      "Epoch: 644\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.1215e-05\n",
      "Epoch: 645\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 119ms/sample - loss: 2.4006e-05\n",
      "Epoch: 646\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 119ms/sample - loss: 2.5238e-05\n",
      "Epoch: 647\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 119ms/sample - loss: 3.2331e-05\n",
      "Epoch: 648\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 119ms/sample - loss: 4.5214e-05\n",
      "Epoch: 649\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 8.1093e-05\n",
      "Epoch: 650\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.5541e-04\n",
      "Epoch: 651\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 2.5758e-04\n",
      "Epoch: 652\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 119ms/sample - loss: 3.3406e-04\n",
      "Epoch: 653\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.6091e-04\n",
      "Epoch: 654\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 7.2666e-04\n",
      "Epoch: 655\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 119ms/sample - loss: 5.7525e-04\n",
      "Epoch: 656\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 6.8892e-04\n",
      "Epoch: 657\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 5.8010e-04\n",
      "Epoch: 658\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 2.9968e-04\n",
      "Epoch: 659\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 2.0484e-04\n",
      "Epoch: 660\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.4891e-04\n",
      "Epoch: 661\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 119ms/sample - loss: 1.2723e-04\n",
      "Epoch: 662\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.0356e-04\n",
      "Epoch: 663\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 119ms/sample - loss: 1.4752e-04\n",
      "Epoch: 664\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 119ms/sample - loss: 2.0315e-04\n",
      "Epoch: 665\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.0559e-04\n",
      "Epoch: 666\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 8.2546e-04\n",
      "Epoch: 667\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0034\n",
      "Epoch: 668\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0049\n",
      "Epoch: 669\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 119ms/sample - loss: 0.0014\n",
      "Epoch: 670\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 8.1431e-04\n",
      "Epoch: 671\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.5689e-04\n",
      "Epoch: 672\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.0810e-04\n",
      "Epoch: 673\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 5.0320e-05\n",
      "Epoch: 674\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.4071e-05\n",
      "Epoch: 675\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.3973e-05\n",
      "Epoch: 676\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 21s 119ms/sample - loss: 4.0168e-05\n",
      "Epoch: 677\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 2.0138e-05\n",
      "Epoch: 678\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.5760e-05\n",
      "Epoch: 679\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 2.3171e-05\n",
      "Epoch: 680\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.5044e-05\n",
      "Epoch: 681\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 9.1851e-05\n",
      "Epoch: 682\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.7909e-04\n",
      "Epoch: 683\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.6486e-04\n",
      "Epoch: 684\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 6.9344e-04\n",
      "Epoch: 685\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 5.5713e-04\n",
      "Epoch: 686\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.2781e-04\n",
      "Epoch: 687\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.7290e-04\n",
      "Epoch: 688\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.5659e-04\n",
      "Epoch: 689\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 2.0720e-04\n",
      "Epoch: 690\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.7267e-04\n",
      "Epoch: 691\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.5306e-04\n",
      "Epoch: 692\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.1804e-04\n",
      "Epoch: 693\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0054\n",
      "Epoch: 694\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0040\n",
      "Epoch: 695\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0024\n",
      "Epoch: 696\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0012\n",
      "Epoch: 697\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.2076e-04\n",
      "Epoch: 698\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.2860e-04\n",
      "Epoch: 699\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 7.8456e-05\n",
      "Epoch: 700\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.7383e-05\n",
      "Epoch: 701\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.2091e-05\n",
      "Epoch: 702\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.1184e-05\n",
      "Epoch: 703\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.1407e-05\n",
      "Epoch: 704\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.3210e-05\n",
      "Epoch: 705\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.7378e-05\n",
      "Epoch: 706\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 7.4495e-05\n",
      "Epoch: 707\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.1703e-04\n",
      "Epoch: 708\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.3548e-04\n",
      "Epoch: 709\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.3906e-04\n",
      "Epoch: 710\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.3000e-04\n",
      "Epoch: 711\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0017\n",
      "Epoch: 712\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0147\n",
      "Epoch: 713\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0064\n",
      "Epoch: 714\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0027\n",
      "Epoch: 715\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0018\n",
      "Epoch: 716\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0016\n",
      "Epoch: 717\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0012\n",
      "Epoch: 718\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0011\n",
      "Epoch: 719\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0028\n",
      "Epoch: 720\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0019\n",
      "Epoch: 721\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 7.8532e-04\n",
      "Epoch: 722\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.4913e-04\n",
      "Epoch: 723\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.2046e-04\n",
      "Epoch: 724\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 8.1215e-05\n",
      "Epoch: 725\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 7.5110e-05\n",
      "Epoch: 726\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 6.0016e-05\n",
      "Epoch: 727\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 8.2794e-05\n",
      "Epoch: 728\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 7.2423e-05\n",
      "Epoch: 729\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 6.7078e-05\n",
      "Epoch: 730\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 6.9637e-05\n",
      "Epoch: 731\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.1343e-04\n",
      "Epoch: 732\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 2.0915e-04\n",
      "Epoch: 733\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 2.7353e-04\n",
      "Epoch: 734\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 2.8372e-04\n",
      "Epoch: 735\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 2.1206e-04\n",
      "Epoch: 736\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 2.2548e-04\n",
      "Epoch: 737\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 2.7210e-04\n",
      "Epoch: 738\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.6229e-04\n",
      "Epoch: 739\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.1579e-04\n",
      "Epoch: 740\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.5817e-04\n",
      "Epoch: 741\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 4.7602e-04\n",
      "Epoch: 742\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 3.8543e-04\n",
      "Epoch: 743\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 6.2550e-04\n",
      "Epoch: 744\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 9.6314e-04\n",
      "Epoch: 745\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0040\n",
      "Epoch: 746\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0021\n",
      "Epoch: 747\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0029\n",
      "Epoch: 748\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.8035e-04\n",
      "Epoch: 749\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 2.5443e-04\n",
      "Epoch: 750\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 8.2682e-05\n",
      "Epoch: 751\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.4808e-05\n",
      "Epoch: 752\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.9377e-05\n",
      "Epoch: 753\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.7098e-05\n",
      "Epoch: 754\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.1917e-05\n",
      "Epoch: 755\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.8451e-05\n",
      "Epoch: 756\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 2.0837e-05\n",
      "Epoch: 757\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.7357e-05\n",
      "Epoch: 758\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 6.1740e-05\n",
      "Epoch: 759\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.1721e-04\n",
      "Epoch: 760\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 1.9859e-04\n",
      "Epoch: 761\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 2.2942e-04\n",
      "Epoch: 762\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.0381e-04\n",
      "Epoch: 763\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.3320e-04\n",
      "Epoch: 764\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 4.2023e-04\n",
      "Epoch: 765\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.9261e-04\n",
      "Epoch: 766\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 3.9127e-04\n",
      "Epoch: 767\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 2.5683e-04\n",
      "Epoch: 768\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 0.0019\n",
      "Epoch: 769\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 8.7724e-04\n",
      "Epoch: 770\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 3.9652e-04\n",
      "Epoch: 771\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 2.5236e-04\n",
      "Epoch: 772\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 1.3760e-04\n",
      "Epoch: 773\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 1.5998e-04\n",
      "Epoch: 774\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 9.7143e-05\n",
      "Epoch: 775\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 6.1615e-05\n",
      "Epoch: 776\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 6.1462e-05\n",
      "Epoch: 777\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 5.0352e-05\n",
      "Epoch: 778\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 8.3609e-05\n",
      "Epoch: 779\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 1.2192e-04\n",
      "Epoch: 780\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 2.3949e-04\n",
      "Epoch: 781\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 4.5493e-04\n",
      "Epoch: 782\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0018\n",
      "Epoch: 783\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 0.0023\n",
      "Epoch: 784\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0044\n",
      "Epoch: 785\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 122ms/sample - loss: 0.0026\n",
      "Epoch: 786\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 4.7168e-04\n",
      "Epoch: 787\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 1.6596e-04\n",
      "Epoch: 788\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 1.0503e-04\n",
      "Epoch: 789\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 6.8889e-05\n",
      "Epoch: 790\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 3.2566e-05\n",
      "Epoch: 791\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 2.4446e-05\n",
      "Epoch: 792\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 2.2302e-05\n",
      "Epoch: 793\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 2.2101e-05\n",
      "Epoch: 794\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 2.1018e-05\n",
      "Epoch: 795\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 2.1941e-05\n",
      "Epoch: 796\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 2.4356e-05\n",
      "Epoch: 797\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 5.3950e-05\n",
      "Epoch: 798\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 9.1972e-05\n",
      "Epoch: 799\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 120ms/sample - loss: 1.8090e-04\n",
      "Forecasting Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-04-21 08:58:01.763631: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=1, Predicted=9.767529, Expected=9.510000\n",
      "Month=2, Predicted=9.761249, Expected=9.796000\n",
      "Month=3, Predicted=9.638562, Expected=9.468500\n",
      "Month=4, Predicted=10.390788, Expected=9.672000\n",
      "Month=5, Predicted=10.014854, Expected=9.610000\n",
      "Month=6, Predicted=9.338771, Expected=9.240000\n",
      "Month=7, Predicted=9.912014, Expected=10.318300\n",
      "Month=8, Predicted=9.420004, Expected=8.974800\n",
      "Month=9, Predicted=9.546350, Expected=9.114000\n",
      "Month=10, Predicted=9.342233, Expected=9.300000\n",
      "Month=11, Predicted=9.022005, Expected=8.400000\n",
      "Month=12, Predicted=9.746230, Expected=9.300000\n",
      "Month=13, Predicted=7.230894, Expected=9.000000\n",
      "Month=14, Predicted=8.635469, Expected=9.300000\n",
      "Month=15, Predicted=8.476689, Expected=9.460000\n",
      "Month=16, Predicted=7.346045, Expected=9.145000\n",
      "Month=17, Predicted=8.482458, Expected=9.021000\n",
      "Month=18, Predicted=8.781409, Expected=8.750000\n",
      "Month=19, Predicted=8.523994, Expected=8.710000\n",
      "Month=20, Predicted=7.505432, Expected=8.370000\n",
      "Month=21, Predicted=10.537552, Expected=8.504000\n",
      "Month=22, Predicted=8.750160, Expected=9.819700\n",
      "Month=23, Predicted=11.057863, Expected=9.827300\n",
      "Month=24, Predicted=11.108576, Expected=9.929800\n",
      "Month=25, Predicted=8.313892, Expected=9.288000\n",
      "Month=26, Predicted=9.493060, Expected=9.300000\n",
      "Month=27, Predicted=8.766057, Expected=9.060000\n",
      "Month=28, Predicted=8.240939, Expected=8.835000\n",
      "Month=29, Predicted=9.886487, Expected=8.388600\n",
      "Month=30, Predicted=9.604214, Expected=8.400000\n",
      "Month=31, Predicted=7.322716, Expected=8.525000\n",
      "Month=32, Predicted=6.632055, Expected=8.250000\n",
      "Month=33, Predicted=9.377028, Expected=8.419000\n",
      "Month=34, Predicted=8.937404, Expected=9.455000\n",
      "Month=35, Predicted=7.750933, Expected=8.540000\n",
      "Month=36, Predicted=9.760164, Expected=9.455000\n",
      "Month=37, Predicted=9.530924, Expected=9.000000\n",
      "Month=38, Predicted=9.182371, Expected=9.599000\n",
      "Month=39, Predicted=9.239385, Expected=9.436000\n",
      "Month=40, Predicted=8.235256, Expected=9.539800\n",
      "Month=41, Predicted=9.556261, Expected=9.028600\n",
      "Month=42, Predicted=7.958556, Expected=8.932000\n",
      "Month=43, Predicted=7.911306, Expected=8.993000\n",
      "Month=44, Predicted=8.166307, Expected=8.678400\n",
      "Month=45, Predicted=9.958955, Expected=9.011100\n",
      "Month=46, Predicted=10.176745, Expected=9.630000\n",
      "Month=47, Predicted=7.678939, Expected=8.590400\n",
      "Month=48, Predicted=10.375978, Expected=9.736300\n",
      "Month=49, Predicted=9.299254, Expected=9.384500\n",
      "Month=50, Predicted=9.945857, Expected=9.947200\n",
      "Month=51, Predicted=9.903388, Expected=9.577100\n",
      "Month=52, Predicted=8.483305, Expected=9.117200\n",
      "Month=53, Predicted=9.113244, Expected=9.122500\n",
      "Month=54, Predicted=8.260038, Expected=8.880000\n",
      "Month=55, Predicted=8.038399, Expected=8.709200\n",
      "Month=56, Predicted=10.111154, Expected=8.428200\n",
      "Month=57, Predicted=10.565633, Expected=9.907600\n",
      "Month=58, Predicted=9.554065, Expected=9.145000\n",
      "Month=59, Predicted=8.662335, Expected=8.498000\n",
      "Month=60, Predicted=9.739344, Expected=9.362000\n",
      "Month=61, Predicted=7.971996, Expected=9.000000\n",
      "Month=62, Predicted=9.970157, Expected=9.455000\n",
      "Month=63, Predicted=8.273454, Expected=9.300000\n",
      "Month=64, Predicted=8.693004, Expected=8.990000\n",
      "Month=65, Predicted=8.221789, Expected=8.990000\n",
      "Month=66, Predicted=8.599452, Expected=8.790000\n",
      "Month=67, Predicted=7.719218, Expected=8.835000\n",
      "Month=68, Predicted=9.525553, Expected=8.700000\n",
      "Month=69, Predicted=9.461894, Expected=8.935000\n",
      "Month=70, Predicted=8.878733, Expected=8.835000\n",
      "Month=71, Predicted=8.494512, Expected=8.265000\n",
      "Month=72, Predicted=10.000592, Expected=8.835000\n",
      "Month=73, Predicted=7.843609, Expected=8.550000\n",
      "Month=74, Predicted=8.883989, Expected=8.680000\n",
      "Month=75, Predicted=8.761220, Expected=8.400000\n",
      "Month=76, Predicted=8.255206, Expected=8.525000\n",
      "Month=77, Predicted=8.307496, Expected=8.370000\n",
      "Month=78, Predicted=7.341658, Expected=7.890000\n",
      "Month=79, Predicted=10.465155, Expected=7.812000\n",
      "Month=80, Predicted=7.729928, Expected=7.620000\n",
      "Month=81, Predicted=6.788398, Expected=7.718000\n",
      "Month=82, Predicted=9.155576, Expected=8.323500\n",
      "Month=83, Predicted=6.859099, Expected=6.860000\n",
      "Month=84, Predicted=8.666446, Expected=8.308000\n",
      "Month=85, Predicted=8.691081, Expected=8.100000\n",
      "Month=86, Predicted=8.919956, Expected=8.525000\n",
      "Month=87, Predicted=8.383262, Expected=8.250000\n",
      "Month=88, Predicted=6.792447, Expected=8.215000\n",
      "Month=89, Predicted=8.427953, Expected=8.122600\n",
      "Month=90, Predicted=7.343326, Expected=7.778100\n",
      "Month=91, Predicted=7.994288, Expected=7.954600\n",
      "Month=92, Predicted=7.227094, Expected=7.420000\n",
      "Month=93, Predicted=8.359160, Expected=7.538300\n",
      "Month=94, Predicted=7.676886, Expected=7.905000\n",
      "Month=95, Predicted=7.436378, Expected=7.140000\n",
      "Month=96, Predicted=8.501240, Expected=8.432000\n",
      "Month=97, Predicted=6.371178, Expected=7.710000\n",
      "Month=98, Predicted=9.314691, Expected=7.967000\n",
      "Month=99, Predicted=7.394453, Expected=7.320000\n",
      "Month=100, Predicted=6.655354, Expected=7.502000\n",
      "Month=101, Predicted=6.619192, Expected=7.409000\n",
      "Month=102, Predicted=6.938420, Expected=7.200600\n",
      "Month=103, Predicted=7.309980, Expected=7.865000\n",
      "Month=104, Predicted=8.045089, Expected=6.690000\n",
      "Month=105, Predicted=8.077438, Expected=6.879400\n",
      "Month=106, Predicted=6.932597, Expected=7.440000\n",
      "Month=107, Predicted=7.408803, Expected=6.860000\n",
      "Month=108, Predicted=6.145341, Expected=7.595000\n",
      "Month=109, Predicted=5.509015, Expected=7.200000\n",
      "Month=110, Predicted=5.530825, Expected=7.130000\n",
      "Month=111, Predicted=7.018506, Expected=6.900000\n",
      "Month=112, Predicted=7.578049, Expected=7.130000\n",
      "Month=113, Predicted=6.476403, Expected=7.130000\n",
      "Month=114, Predicted=7.446033, Expected=6.840000\n",
      "Month=115, Predicted=8.909723, Expected=7.006000\n",
      "Month=116, Predicted=6.371320, Expected=6.780000\n",
      "Month=117, Predicted=6.640211, Expected=7.089600\n",
      "Month=118, Predicted=7.492273, Expected=6.882000\n",
      "Month=119, Predicted=5.316590, Expected=6.446700\n",
      "Month=120, Predicted=6.929594, Expected=6.882000\n",
      "Month=121, Predicted=5.933728, Expected=6.600000\n",
      "Month=122, Predicted=7.276719, Expected=6.820000\n",
      "Month=123, Predicted=7.269893, Expected=6.600000\n",
      "Month=124, Predicted=6.947694, Expected=6.820000\n",
      "Month=125, Predicted=6.856760, Expected=6.665000\n",
      "Month=126, Predicted=6.403059, Expected=6.450000\n",
      "Month=127, Predicted=5.729611, Expected=6.665000\n",
      "Month=128, Predicted=6.139168, Expected=6.450000\n",
      "Month=129, Predicted=6.317842, Expected=6.722100\n",
      "Month=130, Predicted=7.598457, Expected=6.820000\n",
      "Month=131, Predicted=5.075693, Expected=6.160000\n",
      "Month=132, Predicted=7.192347, Expected=6.820000\n",
      "Month=133, Predicted=5.568566, Expected=6.480000\n",
      "Month=134, Predicted=5.749207, Expected=6.596900\n",
      "Month=135, Predicted=6.468794, Expected=6.492000\n",
      "Month=136, Predicted=6.076211, Expected=6.510000\n",
      "Month=137, Predicted=5.934452, Expected=6.339500\n",
      "Month=138, Predicted=6.150878, Expected=6.001600\n",
      "Month=139, Predicted=5.526100, Expected=6.107000\n",
      "Month=140, Predicted=5.488808, Expected=5.790000\n",
      "Month=141, Predicted=7.728124, Expected=5.885000\n",
      "Month=142, Predicted=6.587506, Expected=7.280000\n",
      "Month=143, Predicted=5.999004, Expected=5.941600\n",
      "Month=144, Predicted=7.441906, Expected=6.810000\n",
      "Month=145, Predicted=6.104817, Expected=6.182000\n",
      "Month=146, Predicted=6.676514, Expected=6.293000\n",
      "Month=147, Predicted=5.434566, Expected=6.118600\n",
      "Month=148, Predicted=4.338643, Expected=6.138000\n",
      "Month=149, Predicted=5.445592, Expected=6.107000\n",
      "Month=150, Predicted=5.568756, Expected=5.913000\n",
      "Month=151, Predicted=5.228520, Expected=6.141100\n",
      "Month=152, Predicted=5.711966, Expected=6.248000\n",
      "Month=153, Predicted=5.189371, Expected=5.829700\n",
      "Month=154, Predicted=7.642464, Expected=6.829300\n",
      "Month=155, Predicted=6.290276, Expected=6.694400\n",
      "Month=156, Predicted=8.308990, Expected=7.726200\n",
      "Month=157, Predicted=5.749229, Expected=7.054400\n",
      "Month=158, Predicted=5.647644, Expected=7.268900\n",
      "Month=159, Predicted=7.019673, Expected=7.020000\n",
      "Month=160, Predicted=5.032489, Expected=6.510000\n",
      "Month=161, Predicted=5.597458, Expected=6.370500\n",
      "Month=162, Predicted=8.453878, Expected=5.730000\n",
      "Month=163, Predicted=6.122502, Expected=5.828000\n",
      "Month=164, Predicted=6.520466, Expected=5.580000\n",
      "Month=165, Predicted=6.928085, Expected=5.709900\n",
      "Month=166, Predicted=8.266524, Expected=6.696000\n",
      "Month=167, Predicted=6.754546, Expected=6.248000\n",
      "Month=168, Predicted=6.561469, Expected=6.711600\n",
      "Month=169, Predicted=6.371599, Expected=6.600100\n",
      "Month=170, Predicted=6.820225, Expected=7.508200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=171, Predicted=7.090058, Expected=7.765000\n",
      "Month=172, Predicted=5.631652, Expected=7.285000\n",
      "Month=173, Predicted=8.128133, Expected=6.959500\n",
      "Month=174, Predicted=5.300048, Expected=6.450000\n",
      "Month=175, Predicted=6.280148, Expected=6.572000\n",
      "Month=176, Predicted=6.463325, Expected=6.600000\n",
      "Month=177, Predicted=4.207476, Expected=4.265300\n",
      "Month=178, Predicted=6.288983, Expected=7.367000\n",
      "Month=179, Predicted=5.937988, Expected=6.544000\n",
      "Month=180, Predicted=6.927446, Expected=6.940800\n",
      "Train RMSE: 0.85480\n",
      "Train RMSPE: 11.59038\n",
      "Train MAE: 0.67517\n",
      "Train MAPE: 8.90734\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=6.318529, Expected=6.786000\n",
      "Month=2, Predicted=6.431212, Expected=6.981200\n",
      "Month=3, Predicted=6.307203, Expected=6.756000\n",
      "Month=4, Predicted=5.837920, Expected=6.733200\n",
      "Month=5, Predicted=6.519721, Expected=6.671200\n",
      "Month=6, Predicted=5.529536, Expected=6.295600\n",
      "Month=7, Predicted=7.421076, Expected=6.432500\n",
      "Month=8, Predicted=5.559741, Expected=6.153000\n",
      "Month=9, Predicted=6.316904, Expected=6.389500\n",
      "Month=10, Predicted=6.700169, Expected=7.192000\n",
      "Month=11, Predicted=6.104353, Expected=6.524000\n",
      "Month=12, Predicted=7.286361, Expected=7.238500\n",
      "Month=13, Predicted=6.999923, Expected=6.990000\n",
      "Month=14, Predicted=6.526865, Expected=7.254000\n",
      "Month=15, Predicted=7.489665, Expected=6.720000\n",
      "Month=16, Predicted=5.832720, Expected=6.944000\n",
      "Month=17, Predicted=6.439034, Expected=7.052500\n",
      "Month=18, Predicted=6.425159, Expected=6.690000\n",
      "Month=19, Predicted=6.447929, Expected=6.909900\n",
      "Month=20, Predicted=5.248272, Expected=6.819000\n",
      "Month=21, Predicted=6.392437, Expected=7.167200\n",
      "Month=22, Predicted=7.163767, Expected=7.254000\n",
      "Month=23, Predicted=5.608358, Expected=6.664000\n",
      "Month=24, Predicted=7.632573, Expected=7.393500\n",
      "Month=25, Predicted=6.131741, Expected=7.125000\n",
      "Month=26, Predicted=7.077625, Expected=7.347000\n",
      "Month=27, Predicted=7.315346, Expected=7.216500\n",
      "Month=28, Predicted=7.065080, Expected=7.254000\n",
      "Month=29, Predicted=6.685856, Expected=7.238500\n",
      "Month=30, Predicted=6.576580, Expected=6.990000\n",
      "Month=31, Predicted=6.845928, Expected=7.192000\n",
      "Month=32, Predicted=6.469798, Expected=6.900000\n",
      "Month=33, Predicted=6.729199, Expected=7.427300\n",
      "Month=34, Predicted=7.495104, Expected=7.300500\n",
      "Month=35, Predicted=6.237358, Expected=6.902000\n",
      "Month=36, Predicted=6.865767, Expected=7.409000\n",
      "Month=37, Predicted=6.440287, Expected=7.179000\n",
      "Month=38, Predicted=7.216064, Expected=7.424500\n",
      "Month=39, Predicted=7.449578, Expected=7.275000\n",
      "Month=40, Predicted=7.957803, Expected=7.316000\n",
      "Month=41, Predicted=7.406913, Expected=7.086300\n",
      "Month=42, Predicted=6.409735, Expected=7.020000\n",
      "Month=43, Predicted=6.256289, Expected=7.270500\n",
      "Month=44, Predicted=7.154944, Expected=7.168800\n",
      "Month=45, Predicted=7.330030, Expected=7.448600\n",
      "Month=46, Predicted=6.668897, Expected=7.440200\n",
      "Test RMSE: 0.61581\n",
      "Test RMSPE: 8.90497\n",
      "Test MAE: 0.51277\n",
      "Test MAPE: 7.37271\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(tf.keras.layers.GRU(256,return_sequences=True)))\n",
    "    model.add(Bidirectional(tf.keras.layers.GRU(128,return_sequences=True)))\n",
    "    model.add(Bidirectional(tf.keras.layers.GRU(64)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')   \n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size , verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=5\n",
    "\tneurons=[6,5,4,2] \n",
    "\tn_epochs=800\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "043cc7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_19346/1014239271.py:24: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "2022-04-21 09:14:31.003479: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-21 09:14:31.003512: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_19346/1014239271.py:240: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_19346/1014239271.py:144: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "2022-04-21 09:14:31.044060: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-21 09:14:31.044078: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 09:14:31.885876: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-21 09:14:32.026885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-21 09:14:32.185063: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 15s 75ms/sample - loss: 0.0502\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0425\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0411\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0403\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0392\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0377\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0354\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0340\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0324\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0315\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0315\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0293\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0292\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0387\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0321\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0300\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0288\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0283\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 75ms/sample - loss: 0.0280\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0296\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0289\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0275\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0278\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0280\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0283\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0277\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 74ms/sample - loss: 0.0269\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0267\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0269\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0264\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0259\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0253\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0243\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0248\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0240\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0231\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0233\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0225\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0221\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0212\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0215\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0209\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0201\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0196\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0190\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0186\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0188\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0185\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 76ms/sample - loss: 0.0183\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0231\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0208\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0161\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0151\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0141\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0158\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0123\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0113\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0125\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0152\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0125\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0094\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0123\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0110\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0108\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0103\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0092\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0089\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0091\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0113\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0088\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0071\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 74ms/sample - loss: 0.0076\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 74ms/sample - loss: 0.0085\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0087\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 74ms/sample - loss: 0.0073\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0057\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0052\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0052\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0056\n",
      "Epoch: 79\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0059\n",
      "Epoch: 80\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0077\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0075\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0106\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0080\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0060\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0059\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0050\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0050\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0057\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0047\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0064\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0054\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0053\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0056\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0053\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0075\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0051\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0047\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0039\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0048\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0060\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0051\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0038\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0048\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0037\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 69ms/sample - loss: 0.0041\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0048\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0080\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0069\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0065\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0036\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0041\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0045\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0056\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 69ms/sample - loss: 0.0057\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0034\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 75ms/sample - loss: 0.0033\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 80ms/sample - loss: 0.0035\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 94ms/sample - loss: 0.0032\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 87ms/sample - loss: 0.0031\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 80ms/sample - loss: 0.0035\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 82ms/sample - loss: 0.0042\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 80ms/sample - loss: 0.0040\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 79ms/sample - loss: 0.0046\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 79ms/sample - loss: 0.0053\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 75ms/sample - loss: 0.0032\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0039\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0036\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0036\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0049\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 69ms/sample - loss: 0.0039\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0045\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0044\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0036\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 69ms/sample - loss: 0.0034\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0030\n",
      "Epoch: 136\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0064\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0088\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0055\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0037\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0049\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0035\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0033\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0025\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0023\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0027\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0021\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0025\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0029\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0042\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0041\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0039\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0034\n",
      "Epoch: 153\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0034\n",
      "Epoch: 154\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0037\n",
      "Epoch: 155\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0050\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0034\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0039\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0032\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0026\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0024\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0029\n",
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0035\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0032\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0029\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0032\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0027\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0027\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0026\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0028\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0039\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0031\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0026\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0032\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0031\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0031\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 69ms/sample - loss: 0.0040\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0031\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 79ms/sample - loss: 0.0032\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0033\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0026\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0023\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0028\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0025\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0024\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0018\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0024\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0033\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0026\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0026\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0024\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0027\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0028\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0024\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0050\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0083\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0037\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0023\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0020\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0018\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0018\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0019\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0023\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0020\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0030\n",
      "Epoch: 205\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0032\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0032\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0023\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0023\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0020\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0015\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0014\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0016\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0020\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0022\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0018\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0075\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0071\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0055\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0037\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0025\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0019\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0014\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0015\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0011\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0012\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0018\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0017\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0021\n",
      "Epoch: 229\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0019\n",
      "Epoch: 230\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0016\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0017\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0015\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0015\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0012\n",
      "Epoch: 235\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0015\n",
      "Epoch: 236\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 75ms/sample - loss: 0.0025\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0029\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0021\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 77ms/sample - loss: 0.0020\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0017\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0015\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0014\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0020\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0026\n",
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0021\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0017\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0023\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0015\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0021\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0058\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0032\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0015\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0012\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 7.6105e-04\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 76ms/sample - loss: 7.1646e-04\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.9372e-04\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 84ms/sample - loss: 7.8763e-04\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 118ms/sample - loss: 0.0022\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 83ms/sample - loss: 0.0029\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 81ms/sample - loss: 0.0022\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 94ms/sample - loss: 0.0018\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 85ms/sample - loss: 9.3464e-04\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 78ms/sample - loss: 0.0014\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0014\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 9.3778e-04\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.4950e-04\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 7.2825e-04\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 8.2133e-04\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 7.7804e-04\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0011\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 8.5163e-04\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0013\n",
      "Epoch: 273\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0019\n",
      "Epoch: 274\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0053\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0037\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0036\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0014\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 5.1758e-04\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 3.0077e-04\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 1.7452e-04\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 1.5675e-04\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 1.9553e-04\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 2.5787e-04\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 3.5341e-04\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.9139e-04\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 4.9330e-04\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 5.4148e-04\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0037\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0059\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0035\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0023\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0011\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 4.6484e-04\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.0900e-04\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.4507e-04\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 3.2646e-04\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.2786e-04\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 3.3963e-04\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.5744e-04\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.6659e-04\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0017\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0022\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0011\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0020\n",
      "Epoch: 305\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0033\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0014\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.9223e-04\n",
      "Epoch: 308\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.6325e-04\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.3069e-04\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.4232e-04\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.7434e-04\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.0567e-04\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 2.5595e-04\n",
      "Epoch: 314\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.5033e-04\n",
      "Epoch: 315\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.2696e-04\n",
      "Epoch: 316\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.8502e-04\n",
      "Epoch: 317\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.0963e-04\n",
      "Epoch: 318\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0011\n",
      "Epoch: 319\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0015\n",
      "Epoch: 320\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0053\n",
      "Epoch: 321\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0024\n",
      "Epoch: 322\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0018\n",
      "Epoch: 323\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0011\n",
      "Epoch: 324\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 75ms/sample - loss: 7.3655e-04\n",
      "Epoch: 325\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 3.4178e-04\n",
      "Epoch: 326\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 2.0611e-04\n",
      "Epoch: 327\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 1.3940e-04\n",
      "Epoch: 328\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.2680e-04\n",
      "Epoch: 329\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 1.3469e-04\n",
      "Epoch: 330\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 1.9593e-04\n",
      "Epoch: 331\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.9602e-04\n",
      "Epoch: 332\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 3.4488e-04\n",
      "Epoch: 333\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.9111e-04\n",
      "Epoch: 334\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 7.7222e-04\n",
      "Epoch: 335\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 8.7422e-04\n",
      "Epoch: 336\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0010\n",
      "Epoch: 337\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0017\n",
      "Epoch: 338\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0066\n",
      "Epoch: 339\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0070\n",
      "Epoch: 340\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0015\n",
      "Epoch: 341\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.7724e-04\n",
      "Epoch: 342\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.5399e-04\n",
      "Epoch: 343\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.8215e-04\n",
      "Epoch: 344\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.1722e-04\n",
      "Epoch: 345\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.2252e-04\n",
      "Epoch: 346\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.4049e-04\n",
      "Epoch: 347\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.4691e-04\n",
      "Epoch: 348\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.2484e-04\n",
      "Epoch: 349\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.8632e-04\n",
      "Epoch: 350\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.2917e-04\n",
      "Epoch: 351\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 4.1821e-04\n",
      "Epoch: 352\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.8941e-04\n",
      "Epoch: 353\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0024\n",
      "Epoch: 354\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0031\n",
      "Epoch: 355\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0062\n",
      "Epoch: 356\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0022\n",
      "Epoch: 357\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 7.9912e-04\n",
      "Epoch: 358\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.0743e-04\n",
      "Epoch: 359\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.4358e-04\n",
      "Epoch: 360\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 9.5744e-05\n",
      "Epoch: 361\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.3178e-04\n",
      "Epoch: 362\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.4715e-04\n",
      "Epoch: 363\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.5018e-04\n",
      "Epoch: 364\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.1498e-04\n",
      "Epoch: 365\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.9481e-04\n",
      "Epoch: 366\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 7.3319e-04\n",
      "Epoch: 367\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 8.7645e-04\n",
      "Epoch: 368\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 9.3732e-04\n",
      "Epoch: 369\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0015\n",
      "Epoch: 370\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.7693e-04\n",
      "Epoch: 371\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 7.1201e-04\n",
      "Epoch: 372\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 74ms/sample - loss: 4.8392e-04\n",
      "Epoch: 373\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 74ms/sample - loss: 3.2219e-04\n",
      "Epoch: 374\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 75ms/sample - loss: 1.9320e-04\n",
      "Epoch: 375\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 77ms/sample - loss: 1.7821e-04\n",
      "Epoch: 376\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 77ms/sample - loss: 2.1099e-04\n",
      "Epoch: 377\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 76ms/sample - loss: 3.6912e-04\n",
      "Epoch: 378\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 77ms/sample - loss: 0.0037\n",
      "Epoch: 379\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 76ms/sample - loss: 0.0030\n",
      "Epoch: 380\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 77ms/sample - loss: 0.0014\n",
      "Epoch: 381\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 75ms/sample - loss: 7.9622e-04\n",
      "Epoch: 382\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 74ms/sample - loss: 5.9758e-04\n",
      "Epoch: 383\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 3.4580e-04\n",
      "Epoch: 384\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 3.2763e-04\n",
      "Epoch: 385\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.0547e-04\n",
      "Epoch: 386\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.7369e-04\n",
      "Epoch: 387\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.8788e-04\n",
      "Epoch: 388\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 4.1369e-04\n",
      "Epoch: 389\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.9870e-04\n",
      "Epoch: 390\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0026\n",
      "Epoch: 391\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0047\n",
      "Epoch: 392\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0018\n",
      "Epoch: 393\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 78ms/sample - loss: 0.0012\n",
      "Epoch: 394\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 75ms/sample - loss: 4.5726e-04\n",
      "Epoch: 395\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 18s 102ms/sample - loss: 1.5206e-04\n",
      "Epoch: 396\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 96ms/sample - loss: 5.6666e-05\n",
      "Epoch: 397\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 85ms/sample - loss: 4.0492e-05\n",
      "Epoch: 398\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 82ms/sample - loss: 3.1418e-05\n",
      "Epoch: 399\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 78ms/sample - loss: 3.8163e-05\n",
      "Epoch: 400\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 76ms/sample - loss: 6.3194e-05\n",
      "Epoch: 401\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 1.5842e-04\n",
      "Epoch: 402\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.8912e-04\n",
      "Epoch: 403\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 8.4354e-04\n",
      "Epoch: 404\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0024\n",
      "Epoch: 405\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0041\n",
      "Epoch: 406\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0013\n",
      "Epoch: 407\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 4.1785e-04\n",
      "Epoch: 408\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.2728e-04\n",
      "Epoch: 409\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.4152e-04\n",
      "Epoch: 410\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.9040e-04\n",
      "Epoch: 411\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.0241e-04\n",
      "Epoch: 412\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.4940e-04\n",
      "Epoch: 413\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.8632e-04\n",
      "Epoch: 414\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.0280e-04\n",
      "Epoch: 415\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.8837e-04\n",
      "Epoch: 416\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 8.9554e-04\n",
      "Epoch: 417\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0011\n",
      "Epoch: 418\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0011\n",
      "Epoch: 419\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.7784e-04\n",
      "Epoch: 420\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.5685e-04\n",
      "Epoch: 421\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.5257e-04\n",
      "Epoch: 422\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.3696e-04\n",
      "Epoch: 423\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.9584e-04\n",
      "Epoch: 424\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.4079e-04\n",
      "Epoch: 425\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.9571e-04\n",
      "Epoch: 426\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 7.6319e-04\n",
      "Epoch: 427\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 7.4077e-04\n",
      "Epoch: 428\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0025\n",
      "Epoch: 429\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0033\n",
      "Epoch: 430\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0012\n",
      "Epoch: 431\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0028\n",
      "Epoch: 432\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0027\n",
      "Epoch: 433\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 7.7926e-04\n",
      "Epoch: 434\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.2547e-04\n",
      "Epoch: 435\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.8487e-04\n",
      "Epoch: 436\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.6359e-04\n",
      "Epoch: 437\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 8.5210e-05\n",
      "Epoch: 438\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 8.6265e-05\n",
      "Epoch: 439\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.2462e-05\n",
      "Epoch: 440\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 9.3471e-05\n",
      "Epoch: 441\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.3253e-04\n",
      "Epoch: 442\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.8758e-04\n",
      "Epoch: 443\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.6067e-04\n",
      "Epoch: 444\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 7.9969e-04\n",
      "Epoch: 445\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 7.3632e-04\n",
      "Epoch: 446\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 8.5044e-04\n",
      "Epoch: 447\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.9374e-04\n",
      "Epoch: 448\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.7474e-04\n",
      "Epoch: 449\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.3659e-04\n",
      "Epoch: 450\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 7.0750e-04\n",
      "Epoch: 451\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.8669e-04\n",
      "Epoch: 452\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.6584e-04\n",
      "Epoch: 453\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.1791e-04\n",
      "Epoch: 454\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.7702e-04\n",
      "Epoch: 455\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.9171e-04\n",
      "Epoch: 456\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.5773e-04\n",
      "Epoch: 457\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 9.5835e-04\n",
      "Epoch: 458\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0040\n",
      "Epoch: 459\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0010\n",
      "Epoch: 460\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.7993e-04\n",
      "Epoch: 461\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.2390e-04\n",
      "Epoch: 462\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.7505e-04\n",
      "Epoch: 463\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.5873e-04\n",
      "Epoch: 464\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.0470e-04\n",
      "Epoch: 465\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.0986e-04\n",
      "Epoch: 466\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.6348e-04\n",
      "Epoch: 467\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.7238e-04\n",
      "Epoch: 468\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.8767e-04\n",
      "Epoch: 469\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.0506e-04\n",
      "Epoch: 470\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 7.8386e-04\n",
      "Epoch: 471\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.7354e-04\n",
      "Epoch: 472\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.9790e-04\n",
      "Epoch: 473\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.6422e-04\n",
      "Epoch: 474\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.8128e-04\n",
      "Epoch: 475\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.8946e-04\n",
      "Epoch: 476\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.7469e-04\n",
      "Epoch: 477\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.1781e-04\n",
      "Epoch: 478\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.4817e-04\n",
      "Epoch: 479\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.6096e-04\n",
      "Epoch: 480\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.2712e-04\n",
      "Epoch: 481\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.2767e-04\n",
      "Epoch: 482\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 9.1690e-04\n",
      "Epoch: 483\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 8.2396e-04\n",
      "Epoch: 484\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.6186e-04\n",
      "Epoch: 485\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.4490e-04\n",
      "Epoch: 486\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.9341e-04\n",
      "Epoch: 487\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 7.1465e-04\n",
      "Epoch: 488\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0012\n",
      "Epoch: 489\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.9322e-04\n",
      "Epoch: 490\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.5928e-04\n",
      "Epoch: 491\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.9285e-04\n",
      "Epoch: 492\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.5629e-04\n",
      "Epoch: 493\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.5448e-04\n",
      "Epoch: 494\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.8869e-04\n",
      "Epoch: 495\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.8420e-04\n",
      "Epoch: 496\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.2110e-04\n",
      "Epoch: 497\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.3068e-04\n",
      "Epoch: 498\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.6823e-04\n",
      "Epoch: 499\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.6494e-04\n",
      "Epoch: 500\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 7.2849e-04\n",
      "Epoch: 501\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0011\n",
      "Epoch: 502\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0012\n",
      "Epoch: 503\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.8114e-04\n",
      "Epoch: 504\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.9492e-04\n",
      "Epoch: 505\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.1367e-04\n",
      "Epoch: 506\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.1296e-04\n",
      "Epoch: 507\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 69ms/sample - loss: 1.5797e-04\n",
      "Epoch: 508\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.8455e-04\n",
      "Epoch: 509\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.5530e-04\n",
      "Epoch: 510\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.2197e-04\n",
      "Epoch: 511\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.3653e-04\n",
      "Epoch: 512\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.9804e-04\n",
      "Epoch: 513\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 6.2240e-04\n",
      "Epoch: 514\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 7.9804e-04\n",
      "Epoch: 515\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 77ms/sample - loss: 6.6807e-04\n",
      "Epoch: 516\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 7.9466e-04\n",
      "Epoch: 517\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 5.0928e-04\n",
      "Epoch: 518\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.4030e-04\n",
      "Epoch: 519\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.8580e-04\n",
      "Epoch: 520\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 1.6271e-04\n",
      "Epoch: 521\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 75ms/sample - loss: 2.6374e-04\n",
      "Epoch: 522\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 5.6058e-04\n",
      "Epoch: 523\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0010\n",
      "Epoch: 524\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 9.0862e-04\n",
      "Epoch: 525\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.3948e-04\n",
      "Epoch: 526\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0013\n",
      "Epoch: 527\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0051\n",
      "Epoch: 528\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 7.6146e-04\n",
      "Epoch: 529\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.6910e-04\n",
      "Epoch: 530\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 7.4966e-05\n",
      "Epoch: 531\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 2.5248e-05\n",
      "Epoch: 532\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 1.5436e-05\n",
      "Epoch: 533\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 13s 72ms/sample - loss: 1.1287e-05\n",
      "Epoch: 534\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 89ms/sample - loss: 1.4757e-05\n",
      "Epoch: 535\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 94ms/sample - loss: 2.1688e-05\n",
      "Epoch: 536\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 22s 121ms/sample - loss: 5.8814e-05\n",
      "Epoch: 537\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 18s 99ms/sample - loss: 1.8150e-04\n",
      "Epoch: 538\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 92ms/sample - loss: 3.9228e-04\n",
      "Epoch: 539\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 84ms/sample - loss: 3.8359e-04\n",
      "Epoch: 540\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 86ms/sample - loss: 3.5145e-04\n",
      "Epoch: 541\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 83ms/sample - loss: 3.5062e-04\n",
      "Epoch: 542\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 79ms/sample - loss: 5.2284e-04\n",
      "Epoch: 543\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 5.0181e-04\n",
      "Epoch: 544\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 5.1583e-04\n",
      "Epoch: 545\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.8485e-04\n",
      "Epoch: 546\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 2.2872e-04\n",
      "Epoch: 547\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 3.1600e-04\n",
      "Epoch: 548\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 4.1576e-04\n",
      "Epoch: 549\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.2596e-04\n",
      "Epoch: 550\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 7.7469e-04\n",
      "Epoch: 551\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.7267e-04\n",
      "Epoch: 552\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 8.7147e-04\n",
      "Epoch: 553\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 7.2199e-04\n",
      "Epoch: 554\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 9.0631e-04\n",
      "Epoch: 555\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.6249e-04\n",
      "Epoch: 556\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.5100e-04\n",
      "Epoch: 557\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 2.1346e-04\n",
      "Epoch: 558\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.8351e-04\n",
      "Epoch: 559\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 8.6902e-05\n",
      "Epoch: 560\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.2003e-04\n",
      "Epoch: 561\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.3536e-04\n",
      "Epoch: 562\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 9.0689e-05\n",
      "Epoch: 563\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.1067e-04\n",
      "Epoch: 564\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.2661e-04\n",
      "Epoch: 565\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.5296e-04\n",
      "Epoch: 566\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.4635e-04\n",
      "Epoch: 567\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0013\n",
      "Epoch: 568\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0071\n",
      "Epoch: 569\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.5659e-04\n",
      "Epoch: 570\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.0562e-04\n",
      "Epoch: 571\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.0163e-04\n",
      "Epoch: 572\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.1891e-05\n",
      "Epoch: 573\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 4.7954e-05\n",
      "Epoch: 574\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.4630e-05\n",
      "Epoch: 575\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 4.6643e-05\n",
      "Epoch: 576\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 4.8527e-05\n",
      "Epoch: 577\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 8.3708e-05\n",
      "Epoch: 578\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.4396e-04\n",
      "Epoch: 579\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.4093e-04\n",
      "Epoch: 580\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 8.0063e-04\n",
      "Epoch: 581\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.9181e-04\n",
      "Epoch: 582\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.4668e-04\n",
      "Epoch: 583\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.8589e-04\n",
      "Epoch: 584\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.5154e-04\n",
      "Epoch: 585\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 2.1128e-04\n",
      "Epoch: 586\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 74ms/sample - loss: 2.4547e-04\n",
      "Epoch: 587\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 2.6853e-04\n",
      "Epoch: 588\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 4.1700e-04\n",
      "Epoch: 589\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 4.8992e-04\n",
      "Epoch: 590\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 3.6440e-04\n",
      "Epoch: 591\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 3.5358e-04\n",
      "Epoch: 592\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 2.4813e-04\n",
      "Epoch: 593\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 2.7169e-04\n",
      "Epoch: 594\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 2.3260e-04\n",
      "Epoch: 595\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 2.6149e-04\n",
      "Epoch: 596\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 2.4955e-04\n",
      "Epoch: 597\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 3.6084e-04\n",
      "Epoch: 598\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.7262e-04\n",
      "Epoch: 599\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 9.6382e-04\n",
      "Epoch: 600\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0024\n",
      "Epoch: 601\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0014\n",
      "Epoch: 602\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.4433e-04\n",
      "Epoch: 603\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.0391e-04\n",
      "Epoch: 604\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.7701e-04\n",
      "Epoch: 605\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 8.9667e-05\n",
      "Epoch: 606\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 4.7998e-05\n",
      "Epoch: 607\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.0960e-05\n",
      "Epoch: 608\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.4031e-05\n",
      "Epoch: 609\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.0352e-05\n",
      "Epoch: 610\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.5007e-04\n",
      "Epoch: 611\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.4718e-04\n",
      "Epoch: 612\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.4534e-04\n",
      "Epoch: 613\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.5200e-04\n",
      "Epoch: 614\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.7737e-04\n",
      "Epoch: 615\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0012\n",
      "Epoch: 616\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0020\n",
      "Epoch: 617\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.6934e-04\n",
      "Epoch: 618\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.3878e-04\n",
      "Epoch: 619\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.3765e-04\n",
      "Epoch: 620\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 8.6551e-05\n",
      "Epoch: 621\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.5842e-05\n",
      "Epoch: 622\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.3906e-05\n",
      "Epoch: 623\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 7.5613e-05\n",
      "Epoch: 624\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 9.2558e-05\n",
      "Epoch: 625\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.5858e-04\n",
      "Epoch: 626\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.4756e-04\n",
      "Epoch: 627\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.7630e-04\n",
      "Epoch: 628\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.3977e-04\n",
      "Epoch: 629\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.1939e-04\n",
      "Epoch: 630\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.6705e-04\n",
      "Epoch: 631\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0013\n",
      "Epoch: 632\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0048\n",
      "Epoch: 633\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0011\n",
      "Epoch: 634\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 4.3126e-04\n",
      "Epoch: 635\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.2057e-04\n",
      "Epoch: 636\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.3480e-05\n",
      "Epoch: 637\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.7928e-05\n",
      "Epoch: 638\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.8632e-05\n",
      "Epoch: 639\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.3184e-05\n",
      "Epoch: 640\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.2488e-05\n",
      "Epoch: 641\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.1745e-05\n",
      "Epoch: 642\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.2335e-05\n",
      "Epoch: 643\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.0233e-05\n",
      "Epoch: 644\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.4117e-04\n",
      "Epoch: 645\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.9277e-04\n",
      "Epoch: 646\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.1440e-04\n",
      "Epoch: 647\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 9.7161e-04\n",
      "Epoch: 648\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 7.6555e-04\n",
      "Epoch: 649\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.7087e-04\n",
      "Epoch: 650\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.2850e-04\n",
      "Epoch: 651\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.8730e-04\n",
      "Epoch: 652\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.0202e-04\n",
      "Epoch: 653\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.2573e-04\n",
      "Epoch: 654\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.7993e-04\n",
      "Epoch: 655\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.4841e-04\n",
      "Epoch: 656\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.5455e-04\n",
      "Epoch: 657\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.5607e-04\n",
      "Epoch: 658\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.6946e-04\n",
      "Epoch: 659\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.0563e-04\n",
      "Epoch: 660\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0025\n",
      "Epoch: 661\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 7.5538e-04\n",
      "Epoch: 662\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.0522e-04\n",
      "Epoch: 663\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.3186e-04\n",
      "Epoch: 664\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.0314e-04\n",
      "Epoch: 665\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.8216e-05\n",
      "Epoch: 666\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 8.3642e-05\n",
      "Epoch: 667\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.2172e-04\n",
      "Epoch: 668\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.5682e-04\n",
      "Epoch: 669\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.6514e-04\n",
      "Epoch: 670\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.7517e-04\n",
      "Epoch: 671\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 79ms/sample - loss: 2.5221e-04\n",
      "Epoch: 672\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 78ms/sample - loss: 3.2241e-04\n",
      "Epoch: 673\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 19s 107ms/sample - loss: 5.5437e-04\n",
      "Epoch: 674\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 18s 100ms/sample - loss: 8.4451e-04\n",
      "Epoch: 675\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 90ms/sample - loss: 0.0026\n",
      "Epoch: 676\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 87ms/sample - loss: 0.0020\n",
      "Epoch: 677\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 85ms/sample - loss: 7.6888e-04\n",
      "Epoch: 678\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 88ms/sample - loss: 2.2604e-04\n",
      "Epoch: 679\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 77ms/sample - loss: 1.7443e-04\n",
      "Epoch: 680\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 74ms/sample - loss: 1.5263e-04\n",
      "Epoch: 681\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.6429e-04\n",
      "Epoch: 682\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.3073e-04\n",
      "Epoch: 683\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.1264e-04\n",
      "Epoch: 684\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 7.9496e-05\n",
      "Epoch: 685\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 8.8099e-05\n",
      "Epoch: 686\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 8.1457e-05\n",
      "Epoch: 687\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.1233e-04\n",
      "Epoch: 688\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.3839e-04\n",
      "Epoch: 689\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.5819e-04\n",
      "Epoch: 690\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.4605e-04\n",
      "Epoch: 691\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 4.8506e-04\n",
      "Epoch: 692\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.1080e-04\n",
      "Epoch: 693\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.0506e-04\n",
      "Epoch: 694\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.3875e-04\n",
      "Epoch: 695\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.2627e-04\n",
      "Epoch: 696\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.7540e-04\n",
      "Epoch: 697\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.0509e-04\n",
      "Epoch: 698\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.1906e-04\n",
      "Epoch: 699\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 6.8378e-04\n",
      "Epoch: 700\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0031\n",
      "Epoch: 701\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0040\n",
      "Epoch: 702\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 8.4401e-04\n",
      "Epoch: 703\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.3717e-04\n",
      "Epoch: 704\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 7.8023e-05\n",
      "Epoch: 705\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.8529e-05\n",
      "Epoch: 706\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.8489e-05\n",
      "Epoch: 707\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.0952e-05\n",
      "Epoch: 708\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.8262e-05\n",
      "Epoch: 709\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 5.7857e-05\n",
      "Epoch: 710\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 9.9932e-05\n",
      "Epoch: 711\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.7388e-04\n",
      "Epoch: 712\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.9048e-04\n",
      "Epoch: 713\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.1221e-04\n",
      "Epoch: 714\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.8471e-04\n",
      "Epoch: 715\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.7256e-04\n",
      "Epoch: 716\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.4899e-04\n",
      "Epoch: 717\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.6989e-04\n",
      "Epoch: 718\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.3508e-04\n",
      "Epoch: 719\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.0499e-04\n",
      "Epoch: 720\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.7774e-04\n",
      "Epoch: 721\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.7577e-04\n",
      "Epoch: 722\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.0207e-04\n",
      "Epoch: 723\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.2183e-04\n",
      "Epoch: 724\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.5403e-04\n",
      "Epoch: 725\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.7198e-04\n",
      "Epoch: 726\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.0629e-04\n",
      "Epoch: 727\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.7669e-04\n",
      "Epoch: 728\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.5487e-04\n",
      "Epoch: 729\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.8711e-04\n",
      "Epoch: 730\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0015\n",
      "Epoch: 731\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0018\n",
      "Epoch: 732\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 7.8311e-04\n",
      "Epoch: 733\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.4921e-04\n",
      "Epoch: 734\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.8595e-04\n",
      "Epoch: 735\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.6006e-04\n",
      "Epoch: 736\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.3237e-04\n",
      "Epoch: 737\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.2148e-04\n",
      "Epoch: 738\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.8282e-05\n",
      "Epoch: 739\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 8.1710e-05\n",
      "Epoch: 740\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.0121e-05\n",
      "Epoch: 741\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 8.7787e-05\n",
      "Epoch: 742\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.5611e-04\n",
      "Epoch: 743\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.2606e-04\n",
      "Epoch: 744\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.7291e-04\n",
      "Epoch: 745\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.4864e-04\n",
      "Epoch: 746\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.3336e-04\n",
      "Epoch: 747\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.4335e-04\n",
      "Epoch: 748\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.5345e-04\n",
      "Epoch: 749\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.0857e-04\n",
      "Epoch: 750\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.4361e-04\n",
      "Epoch: 751\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.9309e-04\n",
      "Epoch: 752\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.8615e-04\n",
      "Epoch: 753\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.3740e-04\n",
      "Epoch: 754\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.2780e-04\n",
      "Epoch: 755\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.5798e-04\n",
      "Epoch: 756\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.0076e-04\n",
      "Epoch: 757\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.5869e-04\n",
      "Epoch: 758\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 9.0659e-04\n",
      "Epoch: 759\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0010\n",
      "Epoch: 760\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 0.0043\n",
      "Epoch: 761\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0056\n",
      "Epoch: 762\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0017\n",
      "Epoch: 763\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.4939e-04\n",
      "Epoch: 764\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.0530e-04\n",
      "Epoch: 765\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.2815e-05\n",
      "Epoch: 766\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.2032e-05\n",
      "Epoch: 767\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.9114e-05\n",
      "Epoch: 768\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.3182e-05\n",
      "Epoch: 769\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 8.8158e-06\n",
      "Epoch: 770\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 6.4047e-06\n",
      "Epoch: 771\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 9.3185e-06\n",
      "Epoch: 772\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 1.6782e-05\n",
      "Epoch: 773\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 5.7567e-05\n",
      "Epoch: 774\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.2265e-04\n",
      "Epoch: 775\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.9921e-04\n",
      "Epoch: 776\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.1210e-04\n",
      "Epoch: 777\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.9740e-04\n",
      "Epoch: 778\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.5453e-04\n",
      "Epoch: 779\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 4.3747e-04\n",
      "Epoch: 780\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 3.4311e-04\n",
      "Epoch: 781\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.9441e-04\n",
      "Epoch: 782\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.3090e-04\n",
      "Epoch: 783\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.3544e-04\n",
      "Epoch: 784\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.5667e-04\n",
      "Epoch: 785\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.4083e-04\n",
      "Epoch: 786\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.9672e-04\n",
      "Epoch: 787\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.8929e-04\n",
      "Epoch: 788\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.8956e-04\n",
      "Epoch: 789\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.4180e-04\n",
      "Epoch: 790\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 1.9339e-04\n",
      "Epoch: 791\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.5535e-04\n",
      "Epoch: 792\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.7687e-04\n",
      "Epoch: 793\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.2131e-04\n",
      "Epoch: 794\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.9828e-04\n",
      "Epoch: 795\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 2.4767e-04\n",
      "Epoch: 796\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.1546e-04\n",
      "Epoch: 797\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.0755e-04\n",
      "Epoch: 798\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 70ms/sample - loss: 2.3586e-04\n",
      "Epoch: 799\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 3.1323e-04\n",
      "Forecasting Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-04-21 12:06:45.268802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=1, Predicted=9.598587, Expected=9.510000\n",
      "Month=2, Predicted=9.833865, Expected=9.796000\n",
      "Month=3, Predicted=9.527087, Expected=9.468500\n",
      "Month=4, Predicted=9.698331, Expected=9.672000\n",
      "Month=5, Predicted=9.664134, Expected=9.610000\n",
      "Month=6, Predicted=9.348174, Expected=9.240000\n",
      "Month=7, Predicted=10.433346, Expected=10.318300\n",
      "Month=8, Predicted=9.110533, Expected=8.974800\n",
      "Month=9, Predicted=9.164914, Expected=9.114000\n",
      "Month=10, Predicted=9.324727, Expected=9.300000\n",
      "Month=11, Predicted=8.546546, Expected=8.400000\n",
      "Month=12, Predicted=9.422881, Expected=9.300000\n",
      "Month=13, Predicted=9.057665, Expected=9.000000\n",
      "Month=14, Predicted=9.339553, Expected=9.300000\n",
      "Month=15, Predicted=9.527245, Expected=9.460000\n",
      "Month=16, Predicted=9.186434, Expected=9.145000\n",
      "Month=17, Predicted=9.092582, Expected=9.021000\n",
      "Month=18, Predicted=8.833046, Expected=8.750000\n",
      "Month=19, Predicted=8.775664, Expected=8.710000\n",
      "Month=20, Predicted=8.439987, Expected=8.370000\n",
      "Month=21, Predicted=8.549161, Expected=8.504000\n",
      "Month=22, Predicted=9.885967, Expected=9.819700\n",
      "Month=23, Predicted=9.837187, Expected=9.827300\n",
      "Month=24, Predicted=9.925847, Expected=9.929800\n",
      "Month=25, Predicted=9.295987, Expected=9.288000\n",
      "Month=26, Predicted=9.303665, Expected=9.300000\n",
      "Month=27, Predicted=9.111954, Expected=9.060000\n",
      "Month=28, Predicted=8.956744, Expected=8.835000\n",
      "Month=29, Predicted=8.493973, Expected=8.388600\n",
      "Month=30, Predicted=8.488623, Expected=8.400000\n",
      "Month=31, Predicted=8.550138, Expected=8.525000\n",
      "Month=32, Predicted=8.339004, Expected=8.250000\n",
      "Month=33, Predicted=8.494326, Expected=8.419000\n",
      "Month=34, Predicted=9.423766, Expected=9.455000\n",
      "Month=35, Predicted=8.603107, Expected=8.540000\n",
      "Month=36, Predicted=9.521549, Expected=9.455000\n",
      "Month=37, Predicted=9.119458, Expected=9.000000\n",
      "Month=38, Predicted=9.632158, Expected=9.599000\n",
      "Month=39, Predicted=9.454926, Expected=9.436000\n",
      "Month=40, Predicted=9.485965, Expected=9.539800\n",
      "Month=41, Predicted=9.036211, Expected=9.028600\n",
      "Month=42, Predicted=8.997333, Expected=8.932000\n",
      "Month=43, Predicted=9.036624, Expected=8.993000\n",
      "Month=44, Predicted=8.714346, Expected=8.678400\n",
      "Month=45, Predicted=9.046262, Expected=9.011100\n",
      "Month=46, Predicted=9.621922, Expected=9.630000\n",
      "Month=47, Predicted=8.683093, Expected=8.590400\n",
      "Month=48, Predicted=9.929916, Expected=9.736300\n",
      "Month=49, Predicted=9.451689, Expected=9.384500\n",
      "Month=50, Predicted=9.975100, Expected=9.947200\n",
      "Month=51, Predicted=9.620961, Expected=9.577100\n",
      "Month=52, Predicted=9.136323, Expected=9.117200\n",
      "Month=53, Predicted=9.140909, Expected=9.122500\n",
      "Month=54, Predicted=8.905190, Expected=8.880000\n",
      "Month=55, Predicted=8.815727, Expected=8.709200\n",
      "Month=56, Predicted=8.591315, Expected=8.428200\n",
      "Month=57, Predicted=10.003995, Expected=9.907600\n",
      "Month=58, Predicted=9.178562, Expected=9.145000\n",
      "Month=59, Predicted=8.681072, Expected=8.498000\n",
      "Month=60, Predicted=9.459811, Expected=9.362000\n",
      "Month=61, Predicted=9.057396, Expected=9.000000\n",
      "Month=62, Predicted=9.494755, Expected=9.455000\n",
      "Month=63, Predicted=9.374477, Expected=9.300000\n",
      "Month=64, Predicted=9.043245, Expected=8.990000\n",
      "Month=65, Predicted=9.039005, Expected=8.990000\n",
      "Month=66, Predicted=8.816653, Expected=8.790000\n",
      "Month=67, Predicted=8.896545, Expected=8.835000\n",
      "Month=68, Predicted=8.655275, Expected=8.700000\n",
      "Month=69, Predicted=8.924496, Expected=8.935000\n",
      "Month=70, Predicted=8.897086, Expected=8.835000\n",
      "Month=71, Predicted=8.355752, Expected=8.265000\n",
      "Month=72, Predicted=8.877816, Expected=8.835000\n",
      "Month=73, Predicted=8.610350, Expected=8.550000\n",
      "Month=74, Predicted=8.707748, Expected=8.680000\n",
      "Month=75, Predicted=8.459247, Expected=8.400000\n",
      "Month=76, Predicted=8.572805, Expected=8.525000\n",
      "Month=77, Predicted=8.473354, Expected=8.370000\n",
      "Month=78, Predicted=7.985432, Expected=7.890000\n",
      "Month=79, Predicted=7.870631, Expected=7.812000\n",
      "Month=80, Predicted=7.687895, Expected=7.620000\n",
      "Month=81, Predicted=7.750792, Expected=7.718000\n",
      "Month=82, Predicted=8.236181, Expected=8.323500\n",
      "Month=83, Predicted=7.054479, Expected=6.860000\n",
      "Month=84, Predicted=8.475560, Expected=8.308000\n",
      "Month=85, Predicted=8.213851, Expected=8.100000\n",
      "Month=86, Predicted=8.545940, Expected=8.525000\n",
      "Month=87, Predicted=8.297472, Expected=8.250000\n",
      "Month=88, Predicted=8.234003, Expected=8.215000\n",
      "Month=89, Predicted=8.177801, Expected=8.122600\n",
      "Month=90, Predicted=7.825545, Expected=7.778100\n",
      "Month=91, Predicted=7.965217, Expected=7.954600\n",
      "Month=92, Predicted=7.450943, Expected=7.420000\n",
      "Month=93, Predicted=7.559428, Expected=7.538300\n",
      "Month=94, Predicted=7.892865, Expected=7.905000\n",
      "Month=95, Predicted=7.172815, Expected=7.140000\n",
      "Month=96, Predicted=8.550360, Expected=8.432000\n",
      "Month=97, Predicted=7.688187, Expected=7.710000\n",
      "Month=98, Predicted=8.022809, Expected=7.967000\n",
      "Month=99, Predicted=7.337431, Expected=7.320000\n",
      "Month=100, Predicted=7.526462, Expected=7.502000\n",
      "Month=101, Predicted=7.444002, Expected=7.409000\n",
      "Month=102, Predicted=7.282031, Expected=7.200600\n",
      "Month=103, Predicted=7.923695, Expected=7.865000\n",
      "Month=104, Predicted=6.741013, Expected=6.690000\n",
      "Month=105, Predicted=6.914418, Expected=6.879400\n",
      "Month=106, Predicted=7.419989, Expected=7.440000\n",
      "Month=107, Predicted=6.925018, Expected=6.860000\n",
      "Month=108, Predicted=7.653050, Expected=7.595000\n",
      "Month=109, Predicted=7.257031, Expected=7.200000\n",
      "Month=110, Predicted=7.220617, Expected=7.130000\n",
      "Month=111, Predicted=6.995537, Expected=6.900000\n",
      "Month=112, Predicted=7.145938, Expected=7.130000\n",
      "Month=113, Predicted=7.179991, Expected=7.130000\n",
      "Month=114, Predicted=6.934581, Expected=6.840000\n",
      "Month=115, Predicted=7.190763, Expected=7.006000\n",
      "Month=116, Predicted=6.859747, Expected=6.780000\n",
      "Month=117, Predicted=7.113915, Expected=7.089600\n",
      "Month=118, Predicted=6.945869, Expected=6.882000\n",
      "Month=119, Predicted=6.530003, Expected=6.446700\n",
      "Month=120, Predicted=6.938356, Expected=6.882000\n",
      "Month=121, Predicted=6.690392, Expected=6.600000\n",
      "Month=122, Predicted=6.841446, Expected=6.820000\n",
      "Month=123, Predicted=6.681175, Expected=6.600000\n",
      "Month=124, Predicted=6.827154, Expected=6.820000\n",
      "Month=125, Predicted=6.733663, Expected=6.665000\n",
      "Month=126, Predicted=6.465667, Expected=6.450000\n",
      "Month=127, Predicted=6.771557, Expected=6.665000\n",
      "Month=128, Predicted=6.528024, Expected=6.450000\n",
      "Month=129, Predicted=6.759319, Expected=6.722100\n",
      "Month=130, Predicted=6.871941, Expected=6.820000\n",
      "Month=131, Predicted=6.235118, Expected=6.160000\n",
      "Month=132, Predicted=6.879655, Expected=6.820000\n",
      "Month=133, Predicted=6.534358, Expected=6.480000\n",
      "Month=134, Predicted=6.628441, Expected=6.596900\n",
      "Month=135, Predicted=6.535937, Expected=6.492000\n",
      "Month=136, Predicted=6.560909, Expected=6.510000\n",
      "Month=137, Predicted=6.429469, Expected=6.339500\n",
      "Month=138, Predicted=6.084243, Expected=6.001600\n",
      "Month=139, Predicted=6.138986, Expected=6.107000\n",
      "Month=140, Predicted=5.845042, Expected=5.790000\n",
      "Month=141, Predicted=5.909473, Expected=5.885000\n",
      "Month=142, Predicted=7.228554, Expected=7.280000\n",
      "Month=143, Predicted=6.088757, Expected=5.941600\n",
      "Month=144, Predicted=6.887211, Expected=6.810000\n",
      "Month=145, Predicted=6.327482, Expected=6.182000\n",
      "Month=146, Predicted=6.308537, Expected=6.293000\n",
      "Month=147, Predicted=6.175526, Expected=6.118600\n",
      "Month=148, Predicted=6.169856, Expected=6.138000\n",
      "Month=149, Predicted=6.141951, Expected=6.107000\n",
      "Month=150, Predicted=5.984706, Expected=5.913000\n",
      "Month=151, Predicted=6.154669, Expected=6.141100\n",
      "Month=152, Predicted=6.234573, Expected=6.248000\n",
      "Month=153, Predicted=5.850434, Expected=5.829700\n",
      "Month=154, Predicted=6.952264, Expected=6.829300\n",
      "Month=155, Predicted=6.712960, Expected=6.694400\n",
      "Month=156, Predicted=7.689114, Expected=7.726200\n",
      "Month=157, Predicted=7.038599, Expected=7.054400\n",
      "Month=158, Predicted=7.265021, Expected=7.268900\n",
      "Month=159, Predicted=7.020066, Expected=7.020000\n",
      "Month=160, Predicted=6.515260, Expected=6.510000\n",
      "Month=161, Predicted=6.375460, Expected=6.370500\n",
      "Month=162, Predicted=5.865412, Expected=5.730000\n",
      "Month=163, Predicted=5.823498, Expected=5.828000\n",
      "Month=164, Predicted=5.676132, Expected=5.580000\n",
      "Month=165, Predicted=5.723173, Expected=5.709900\n",
      "Month=166, Predicted=6.733753, Expected=6.696000\n",
      "Month=167, Predicted=6.235579, Expected=6.248000\n",
      "Month=168, Predicted=6.722875, Expected=6.711600\n",
      "Month=169, Predicted=6.599830, Expected=6.600100\n",
      "Month=170, Predicted=7.508840, Expected=7.508200\n",
      "Month=171, Predicted=7.763853, Expected=7.765000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=172, Predicted=7.284461, Expected=7.285000\n",
      "Month=173, Predicted=6.939872, Expected=6.959500\n",
      "Month=174, Predicted=6.439871, Expected=6.450000\n",
      "Month=175, Predicted=6.587237, Expected=6.572000\n",
      "Month=176, Predicted=6.604878, Expected=6.600000\n",
      "Month=177, Predicted=4.216597, Expected=4.265300\n",
      "Month=178, Predicted=7.362952, Expected=7.367000\n",
      "Month=179, Predicted=6.571731, Expected=6.544000\n",
      "Month=180, Predicted=6.955649, Expected=6.940800\n",
      "Train RMSE: 0.06940\n",
      "Train RMSPE: 0.91089\n",
      "Train MAE: 0.05545\n",
      "Train MAPE: 0.71946\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=6.960433, Expected=6.786000\n",
      "Month=2, Predicted=6.675420, Expected=6.981200\n",
      "Month=3, Predicted=6.738242, Expected=6.756000\n",
      "Month=4, Predicted=6.678925, Expected=6.733200\n",
      "Month=5, Predicted=6.791986, Expected=6.671200\n",
      "Month=6, Predicted=6.389579, Expected=6.295600\n",
      "Month=7, Predicted=6.373254, Expected=6.432500\n",
      "Month=8, Predicted=6.018227, Expected=6.153000\n",
      "Month=9, Predicted=6.281698, Expected=6.389500\n",
      "Month=10, Predicted=6.671983, Expected=7.192000\n",
      "Month=11, Predicted=6.198960, Expected=6.524000\n",
      "Month=12, Predicted=7.490412, Expected=7.238500\n",
      "Month=13, Predicted=6.941870, Expected=6.990000\n",
      "Month=14, Predicted=7.284278, Expected=7.254000\n",
      "Month=15, Predicted=6.928528, Expected=6.720000\n",
      "Month=16, Predicted=6.802461, Expected=6.944000\n",
      "Month=17, Predicted=6.842309, Expected=7.052500\n",
      "Month=18, Predicted=6.499641, Expected=6.690000\n",
      "Month=19, Predicted=7.709372, Expected=6.909900\n",
      "Month=20, Predicted=6.540519, Expected=6.819000\n",
      "Month=21, Predicted=7.227511, Expected=7.167200\n",
      "Month=22, Predicted=7.022340, Expected=7.254000\n",
      "Month=23, Predicted=6.568697, Expected=6.664000\n",
      "Month=24, Predicted=7.372324, Expected=7.393500\n",
      "Month=25, Predicted=7.179624, Expected=7.125000\n",
      "Month=26, Predicted=7.311869, Expected=7.347000\n",
      "Month=27, Predicted=7.310907, Expected=7.216500\n",
      "Month=28, Predicted=7.301329, Expected=7.254000\n",
      "Month=29, Predicted=7.162340, Expected=7.238500\n",
      "Month=30, Predicted=7.055940, Expected=6.990000\n",
      "Month=31, Predicted=7.276888, Expected=7.192000\n",
      "Month=32, Predicted=7.206825, Expected=6.900000\n",
      "Month=33, Predicted=7.093112, Expected=7.427300\n",
      "Month=34, Predicted=7.171322, Expected=7.300500\n",
      "Month=35, Predicted=7.037589, Expected=6.902000\n",
      "Month=36, Predicted=7.400017, Expected=7.409000\n",
      "Month=37, Predicted=7.078804, Expected=7.179000\n",
      "Month=38, Predicted=7.363382, Expected=7.424500\n",
      "Month=39, Predicted=7.269870, Expected=7.275000\n",
      "Month=40, Predicted=7.539045, Expected=7.316000\n",
      "Month=41, Predicted=7.256486, Expected=7.086300\n",
      "Month=42, Predicted=6.805760, Expected=7.020000\n",
      "Month=43, Predicted=7.114282, Expected=7.270500\n",
      "Month=44, Predicted=7.196948, Expected=7.168800\n",
      "Month=45, Predicted=7.499437, Expected=7.448600\n",
      "Month=46, Predicted=7.483174, Expected=7.440200\n",
      "Test RMSE: 0.20830\n",
      "Test RMSPE: 2.98786\n",
      "Test MAE: 0.15014\n",
      "Test MAPE: 2.15366\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stacked bilstm static \n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(64,activation='relu')))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')   \n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size , verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=5\n",
    "\tneurons=[6,5,4,2] \n",
    "\tn_epochs=800\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56438ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 09:07:58.030279: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-22 09:07:58.031488: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_19346/4263786388.py:24: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_19346/4263786388.py:241: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_19346/4263786388.py:145: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 09:08:00.566236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-22 09:08:00.864018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-22 09:08:01.217101: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 20s 94ms/sample - loss: 0.0499\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 97ms/sample - loss: 0.0435\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 20s 111ms/sample - loss: 0.0426\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 25s 138ms/sample - loss: 0.0416\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 115ms/sample - loss: 0.0416\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 21s 117ms/sample - loss: 0.0405\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 20s 110ms/sample - loss: 0.0400\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 19s 106ms/sample - loss: 0.0393\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 18s 98ms/sample - loss: 0.0380\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 97ms/sample - loss: 0.0367\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0350\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0332\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 97ms/sample - loss: 0.0349\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 18s 99ms/sample - loss: 0.0309\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0297\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0287\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0287\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0298\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0285\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 96ms/sample - loss: 0.0277\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 97ms/sample - loss: 0.0274\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0274\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0271\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0294\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0278\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 97ms/sample - loss: 0.0277\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0272\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0268\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0262\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 96ms/sample - loss: 0.0251\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 18s 97ms/sample - loss: 0.0256\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 18s 99ms/sample - loss: 0.0237\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 94ms/sample - loss: 0.0251\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 94ms/sample - loss: 0.0243\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 91ms/sample - loss: 0.0229\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 18s 97ms/sample - loss: 0.0229\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0263\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0253\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0222\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0217\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0209\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 92ms/sample - loss: 0.0216\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 94ms/sample - loss: 0.0202\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0230\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0205\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 97ms/sample - loss: 0.0188\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 92ms/sample - loss: 0.0216\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 94ms/sample - loss: 0.0208\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0199\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 92ms/sample - loss: 0.0208\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 92ms/sample - loss: 0.0206\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0177\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0166\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0185\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 92ms/sample - loss: 0.0172\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 92ms/sample - loss: 0.0161\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 92ms/sample - loss: 0.0192\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 92ms/sample - loss: 0.0156\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0140\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0155\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0157\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 94ms/sample - loss: 0.0144\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0140\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 92ms/sample - loss: 0.0127\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 92ms/sample - loss: 0.0112\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 95ms/sample - loss: 0.0112\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 94ms/sample - loss: 0.0103\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0110\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 94ms/sample - loss: 0.0090\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 18s 99ms/sample - loss: 0.0192\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 97ms/sample - loss: 0.0267\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 96ms/sample - loss: 0.0227\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 94ms/sample - loss: 0.0316\n",
      "Epoch: 73\n",
      "Train on 180 samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(64,return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(32,activation='relu')))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')   \n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size , verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=5\n",
    "\tneurons=[5,4,2] \n",
    "\tn_epochs=800    \n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n",
    "# 0.192 rmse \n",
    "#2.767\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d786c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
