{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e90653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow has access to the following devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "\n",
    "# See TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8432a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 11:29:02.601743: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-18 11:29:02.601783: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_79316/3430678449.py:26: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_79316/3430678449.py:240: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_79316/3430678449.py:144: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "2022-04-18 11:29:02.821456: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-18 11:29:02.821478: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 11:29:03.141914: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-18 11:29:03.142549: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-18 11:29:03.174158: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-18 11:29:03.245863: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0488\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0428\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0385\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0355\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0340\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0330\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0323\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0318\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0313\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0309\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0306\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0302\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0297\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0293\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0289\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0285\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0281\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0277\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0274\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0272\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0270\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0268\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0267\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0265\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0263\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0262\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0260\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0258\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0256\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0254\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0253\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0251\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0249\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0248\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0246\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0245\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0243\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0242\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0241\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0239\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0237\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0236\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0234\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0232\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0231\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0230\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0228\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0227\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0225\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0224\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0223\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0221\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0221\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0219\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0218\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0217\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0215\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0213\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 33ms/sample - loss: 0.0211\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 32ms/sample - loss: 0.0210\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0208\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 32ms/sample - loss: 0.0207\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 32ms/sample - loss: 0.0205\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0204\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0201\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0201\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0196\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0194\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0192\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0193\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0190\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0191\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0187\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0186\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0181\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0178\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0176\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0174\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0173\n",
      "Epoch: 79\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 5s 25ms/sample - loss: 0.0171\n",
      "Epoch: 80\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 25ms/sample - loss: 0.0172\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 25ms/sample - loss: 0.0167\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0168\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0165\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0168\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0165\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0164\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0156\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0158\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0152\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0152\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0151\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0149\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0144\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0151\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0142\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0145\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0142\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0140\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0140\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0136\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0135\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0139\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0133\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 0.0133\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0130\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0132\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0132\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0134\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0123\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0122\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0121\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0126\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0119\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0117\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0126\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0119\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0114\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0135\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 0.0119\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0111\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0113\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0120\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0110\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0105\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0121\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0110\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0106\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0106\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0126\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0100\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0092\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0099\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0096\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0090\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0089\n",
      "Epoch: 136\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0105\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0091\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0087\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0100\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0088\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0087\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 25ms/sample - loss: 0.0085\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0084\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 25ms/sample - loss: 0.0081\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 25ms/sample - loss: 0.0076\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0078\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0078\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0074\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0071\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0069\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0083\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0077\n",
      "Epoch: 153\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0081\n",
      "Epoch: 154\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0076\n",
      "Epoch: 155\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 44ms/sample - loss: 0.0063\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0067\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0063\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0064\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0063\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0059\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0068\n",
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0061\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0068\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0080\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0084\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0087\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0051\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0053\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0050\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0048\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0049\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0054\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0053\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0060\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0061\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0058\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 0.0086\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 0.0057\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0051\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0051\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 0.0046\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 32ms/sample - loss: 0.0045\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0057\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 34ms/sample - loss: 0.0048\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 32ms/sample - loss: 0.0049\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 33ms/sample - loss: 0.0053\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0058\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 33ms/sample - loss: 0.0068\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 33ms/sample - loss: 0.0065\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0046\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 34ms/sample - loss: 0.0046\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 0.0044\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0044\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0043\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0048\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0081\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0067\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0047\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0041\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0038\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0041\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0044\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0036\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0039\n",
      "Epoch: 205\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0047\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0043\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0043\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 35ms/sample - loss: 0.0053\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0059\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0061\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 0.0039\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0040\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0042\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0044\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0041\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0038\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0036\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0036\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 34ms/sample - loss: 0.0040\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 33ms/sample - loss: 0.0056\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0052\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0036\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0031\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0032\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0032\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0034\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0035\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0028\n",
      "Epoch: 229\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0035\n",
      "Epoch: 230\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0090\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0059\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0033\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0034\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 0.0028\n",
      "Epoch: 235\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0034\n",
      "Epoch: 236\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0028\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0032\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0045\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0039\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0044\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0042\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0031\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0027\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0032\n",
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0032\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0026\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0031\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0034\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0035\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0037\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0036\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0030\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0038\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0031\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0027\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0038\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0027\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0021\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 0.0021\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0038\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0044\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0038\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0022\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 0.0032\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0031\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0028\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0045\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0035\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0019\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0016\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0020\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0024\n",
      "Epoch: 273\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0030\n",
      "Epoch: 274\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0019\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0035\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0036\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0046\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0033\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0024\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0020\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0019\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0019\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0019\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0019\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0019\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0026\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0024\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0027\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0026\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0034\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0021\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0018\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0020\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0016\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0028\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0053\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0024\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0025\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0018\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0026\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0020\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0029\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0021\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0013\n",
      "Epoch: 305\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0015\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0024\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0023\n",
      "Epoch: 308\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0032\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0023\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0024\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0019\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0012\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 67s 372ms/sample - loss: 0.0014\n",
      "Epoch: 314\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 25ms/sample - loss: 0.0015\n",
      "Epoch: 315\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 919s 5s/sample - loss: 0.0013\n",
      "Epoch: 316\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 25ms/sample - loss: 0.0018\n",
      "Epoch: 317\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 312s 2s/sample - loss: 0.0025\n",
      "Epoch: 318\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0034\n",
      "Epoch: 319\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0018\n",
      "Epoch: 320\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0015\n",
      "Epoch: 321\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0011\n",
      "Epoch: 322\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0011\n",
      "Epoch: 323\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0019\n",
      "Epoch: 324\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0028\n",
      "Epoch: 325\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0021\n",
      "Epoch: 326\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0022\n",
      "Epoch: 327\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0015\n",
      "Epoch: 328\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0018\n",
      "Epoch: 329\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0020\n",
      "Epoch: 330\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0020\n",
      "Epoch: 331\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0012\n",
      "Epoch: 332\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0011\n",
      "Epoch: 333\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0014\n",
      "Epoch: 334\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0014\n",
      "Epoch: 335\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0020\n",
      "Epoch: 336\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0041\n",
      "Epoch: 337\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0030\n",
      "Epoch: 338\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0014\n",
      "Epoch: 339\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0010\n",
      "Epoch: 340\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 9.3575e-04\n",
      "Epoch: 341\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 9.1775e-04\n",
      "Epoch: 342\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.1836e-04\n",
      "Epoch: 343\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 9.7207e-04\n",
      "Epoch: 344\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0012\n",
      "Epoch: 345\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0032\n",
      "Epoch: 346\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0021\n",
      "Epoch: 347\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0017\n",
      "Epoch: 348\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0024\n",
      "Epoch: 349\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0022\n",
      "Epoch: 350\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0024\n",
      "Epoch: 351\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0014\n",
      "Epoch: 352\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0012\n",
      "Epoch: 353\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0013\n",
      "Epoch: 354\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0011\n",
      "Epoch: 355\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.6400e-04\n",
      "Epoch: 356\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0012\n",
      "Epoch: 357\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0016\n",
      "Epoch: 358\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0017\n",
      "Epoch: 359\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0019\n",
      "Epoch: 360\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0019\n",
      "Epoch: 361\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 9.4176e-04\n",
      "Epoch: 362\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 7.3573e-04\n",
      "Epoch: 363\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0011\n",
      "Epoch: 364\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0018\n",
      "Epoch: 365\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0023\n",
      "Epoch: 366\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0019\n",
      "Epoch: 367\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0025\n",
      "Epoch: 368\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0030\n",
      "Epoch: 369\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0013\n",
      "Epoch: 370\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 9.9561e-04\n",
      "Epoch: 371\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 5.5147e-04\n",
      "Epoch: 372\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0010\n",
      "Epoch: 373\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0032\n",
      "Epoch: 374\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0025\n",
      "Epoch: 375\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0016\n",
      "Epoch: 376\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0013\n",
      "Epoch: 377\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0013\n",
      "Epoch: 378\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0011\n",
      "Epoch: 379\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 9.4461e-04\n",
      "Epoch: 380\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0012\n",
      "Epoch: 381\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.7572e-04\n",
      "Epoch: 382\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.8576e-04\n",
      "Epoch: 383\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0016\n",
      "Epoch: 384\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0013\n",
      "Epoch: 385\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.0233e-04\n",
      "Epoch: 386\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0012\n",
      "Epoch: 387\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0013\n",
      "Epoch: 388\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0013\n",
      "Epoch: 389\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0012\n",
      "Epoch: 390\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0027\n",
      "Epoch: 391\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0017\n",
      "Epoch: 392\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0012\n",
      "Epoch: 393\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0013\n",
      "Epoch: 394\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 8.9215e-04\n",
      "Epoch: 395\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 9.6424e-04\n",
      "Epoch: 396\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 6.7548e-04\n",
      "Epoch: 397\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 7.3725e-04\n",
      "Epoch: 398\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0013\n",
      "Epoch: 399\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 8.3678e-04\n",
      "Epoch: 400\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0012\n",
      "Epoch: 401\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0017\n",
      "Epoch: 402\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0037\n",
      "Epoch: 403\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0046\n",
      "Epoch: 404\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0016\n",
      "Epoch: 405\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0015\n",
      "Epoch: 406\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0010\n",
      "Epoch: 407\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 7.0116e-04\n",
      "Epoch: 408\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 4.2559e-04\n",
      "Epoch: 409\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 5.0388e-04\n",
      "Epoch: 410\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 3.8137e-04\n",
      "Epoch: 411\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.8743e-04\n",
      "Epoch: 412\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 6.1920e-04\n",
      "Epoch: 413\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 4.7829e-04\n",
      "Epoch: 414\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.3416e-04\n",
      "Epoch: 415\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0011\n",
      "Epoch: 416\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0016\n",
      "Epoch: 417\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0021\n",
      "Epoch: 418\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0017\n",
      "Epoch: 419\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0013\n",
      "Epoch: 420\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 9.9730e-04\n",
      "Epoch: 421\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0011\n",
      "Epoch: 422\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0011\n",
      "Epoch: 423\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.9630e-04\n",
      "Epoch: 424\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 9.3523e-04\n",
      "Epoch: 425\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0014\n",
      "Epoch: 426\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 9.1292e-04\n",
      "Epoch: 427\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0017\n",
      "Epoch: 428\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0015\n",
      "Epoch: 429\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0030\n",
      "Epoch: 430\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0016\n",
      "Epoch: 431\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0011\n",
      "Epoch: 432\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 7.4630e-04\n",
      "Epoch: 433\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 4.9937e-04\n",
      "Epoch: 434\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 5.3951e-04\n",
      "Epoch: 435\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 5.0092e-04\n",
      "Epoch: 436\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 7.3350e-04\n",
      "Epoch: 437\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 9.4367e-04\n",
      "Epoch: 438\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0035\n",
      "Epoch: 439\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0018\n",
      "Epoch: 440\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0012\n",
      "Epoch: 441\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0011\n",
      "Epoch: 442\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.7390e-04\n",
      "Epoch: 443\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.9931e-04\n",
      "Epoch: 444\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 6.6408e-04\n",
      "Epoch: 445\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 6.1695e-04\n",
      "Epoch: 446\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 7.0921e-04\n",
      "Epoch: 447\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.3202e-04\n",
      "Epoch: 448\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0013\n",
      "Epoch: 449\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0019\n",
      "Epoch: 450\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0024\n",
      "Epoch: 451\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0013\n",
      "Epoch: 452\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0011\n",
      "Epoch: 453\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 6.4438e-04\n",
      "Epoch: 454\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 5.2338e-04\n",
      "Epoch: 455\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 4.0795e-04\n",
      "Epoch: 456\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.0344e-04\n",
      "Epoch: 457\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0012\n",
      "Epoch: 458\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 9.0522e-04\n",
      "Epoch: 459\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0015\n",
      "Epoch: 460\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0012\n",
      "Epoch: 461\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 9.8949e-04\n",
      "Epoch: 462\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 7.7154e-04\n",
      "Epoch: 463\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 7.7589e-04\n",
      "Epoch: 464\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0011\n",
      "Epoch: 465\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 6.5121e-04\n",
      "Epoch: 466\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0010\n",
      "Epoch: 467\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0043\n",
      "Epoch: 468\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0018\n",
      "Epoch: 469\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0010\n",
      "Epoch: 470\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 8.2883e-04\n",
      "Epoch: 471\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 6.0977e-04\n",
      "Epoch: 472\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 6.0195e-04\n",
      "Epoch: 473\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 5.2458e-04\n",
      "Epoch: 474\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 3.6241e-04\n",
      "Epoch: 475\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 9.3630e-04\n",
      "Epoch: 476\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.9876e-04\n",
      "Epoch: 477\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 9.7584e-04\n",
      "Epoch: 478\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 7.5995e-04\n",
      "Epoch: 479\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 4.4030e-04\n",
      "Epoch: 480\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 7.3559e-04\n",
      "Epoch: 481\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.6237e-04\n",
      "Epoch: 482\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0011\n",
      "Epoch: 483\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 6.9736e-04\n",
      "Epoch: 484\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 5.8533e-04\n",
      "Epoch: 485\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 6.9686e-04\n",
      "Epoch: 486\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 7.1473e-04\n",
      "Epoch: 487\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 6.3882e-04\n",
      "Epoch: 488\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0012\n",
      "Epoch: 489\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0014\n",
      "Epoch: 490\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0040\n",
      "Epoch: 491\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0018\n",
      "Epoch: 492\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0014\n",
      "Epoch: 493\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 6.9440e-04\n",
      "Epoch: 494\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 5.7547e-04\n",
      "Epoch: 495\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.3892e-04\n",
      "Epoch: 496\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.5146e-04\n",
      "Epoch: 497\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.1377e-04\n",
      "Epoch: 498\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 2.4883e-04\n",
      "Epoch: 499\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 2.7470e-04\n",
      "Epoch: 500\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.6299e-04\n",
      "Epoch: 501\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 5.9620e-04\n",
      "Epoch: 502\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0010\n",
      "Epoch: 503\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0042\n",
      "Epoch: 504\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0020\n",
      "Epoch: 505\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0019\n",
      "Epoch: 506\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 9.5452e-04\n",
      "Epoch: 507\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 4.6814e-04\n",
      "Epoch: 508\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 4.1780e-04\n",
      "Epoch: 509\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.8057e-04\n",
      "Epoch: 510\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 2.6660e-04\n",
      "Epoch: 511\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 3.1717e-04\n",
      "Epoch: 512\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.5308e-04\n",
      "Epoch: 513\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 6.6785e-04\n",
      "Epoch: 514\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0022\n",
      "Epoch: 515\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0017\n",
      "Epoch: 516\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0013\n",
      "Epoch: 517\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.8029e-04\n",
      "Epoch: 518\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 4.0300e-04\n",
      "Epoch: 519\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.9549e-04\n",
      "Epoch: 520\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.3150e-04\n",
      "Epoch: 521\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.0555e-04\n",
      "Epoch: 522\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 4.3947e-04\n",
      "Epoch: 523\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 4.7392e-04\n",
      "Epoch: 524\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 9.7381e-04\n",
      "Epoch: 525\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0015\n",
      "Epoch: 526\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0013\n",
      "Epoch: 527\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0011\n",
      "Epoch: 528\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0019\n",
      "Epoch: 529\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0019\n",
      "Epoch: 530\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0013\n",
      "Epoch: 531\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0014\n",
      "Epoch: 532\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.6144e-04\n",
      "Epoch: 533\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.2256e-04\n",
      "Epoch: 534\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 7.1848e-04\n",
      "Epoch: 535\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 9.3666e-04\n",
      "Epoch: 536\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 6.1649e-04\n",
      "Epoch: 537\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.8816e-04\n",
      "Epoch: 538\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 5.1535e-04\n",
      "Epoch: 539\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 43ms/sample - loss: 4.6788e-04\n",
      "Epoch: 540\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.7691e-04\n",
      "Epoch: 541\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 4.2747e-04\n",
      "Epoch: 542\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 5s 28ms/sample - loss: 3.5770e-04\n",
      "Epoch: 543\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.5589e-04\n",
      "Epoch: 544\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 32ms/sample - loss: 0.0013\n",
      "Epoch: 545\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 34ms/sample - loss: 0.0014\n",
      "Epoch: 546\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 7.1410e-04\n",
      "Epoch: 547\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 32ms/sample - loss: 5.7367e-04\n",
      "Epoch: 548\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 32ms/sample - loss: 3.9748e-04\n",
      "Epoch: 549\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 5.7588e-04\n",
      "Epoch: 550\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 6.9566e-04\n",
      "Epoch: 551\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 9.0901e-04\n",
      "Epoch: 552\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 7.5945e-04\n",
      "Epoch: 553\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 34ms/sample - loss: 8.4618e-04\n",
      "Epoch: 554\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 5.3058e-04\n",
      "Epoch: 555\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 8.0258e-04\n",
      "Epoch: 556\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 8.2578e-04\n",
      "Epoch: 557\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 9.2798e-04\n",
      "Epoch: 558\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 9.4790e-04\n",
      "Epoch: 559\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0015\n",
      "Epoch: 560\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.4061e-04\n",
      "Epoch: 561\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.2908e-04\n",
      "Epoch: 562\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.3780e-04\n",
      "Epoch: 563\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.2865e-04\n",
      "Epoch: 564\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 8.2792e-04\n",
      "Epoch: 565\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 7.4041e-04\n",
      "Epoch: 566\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.8432e-04\n",
      "Epoch: 567\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0014\n",
      "Epoch: 568\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0013\n",
      "Epoch: 569\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 8.4238e-04\n",
      "Epoch: 570\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.9139e-04\n",
      "Epoch: 571\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 4.4857e-04\n",
      "Epoch: 572\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.2671e-04\n",
      "Epoch: 573\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 5.9318e-04\n",
      "Epoch: 574\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0012\n",
      "Epoch: 575\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0016\n",
      "Epoch: 576\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 7.5834e-04\n",
      "Epoch: 577\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 7.5830e-04\n",
      "Epoch: 578\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 8.2972e-04\n",
      "Epoch: 579\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.4500e-04\n",
      "Epoch: 580\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 5.4145e-04\n",
      "Epoch: 581\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.3380e-04\n",
      "Epoch: 582\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 6.8515e-04\n",
      "Epoch: 583\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.8475e-04\n",
      "Epoch: 584\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 5.7153e-04\n",
      "Epoch: 585\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.9347e-04\n",
      "Epoch: 586\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 8.1833e-04\n",
      "Epoch: 587\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 7.1069e-04\n",
      "Epoch: 588\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 7.6614e-04\n",
      "Epoch: 589\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0011\n",
      "Epoch: 590\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 8.0196e-04\n",
      "Epoch: 591\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0011\n",
      "Epoch: 592\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.4151e-04\n",
      "Epoch: 593\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 6.1493e-04\n",
      "Epoch: 594\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.7216e-04\n",
      "Epoch: 595\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 4.4671e-04\n",
      "Epoch: 596\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 5.8215e-04\n",
      "Epoch: 597\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0014\n",
      "Epoch: 598\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 5.9044e-04\n",
      "Epoch: 599\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0010\n",
      "Epoch: 600\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 5.7933e-04\n",
      "Epoch: 601\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 6.4352e-04\n",
      "Epoch: 602\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 4.9024e-04\n",
      "Epoch: 603\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 8.3509e-04\n",
      "Epoch: 604\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 8.2097e-04\n",
      "Epoch: 605\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 5.3705e-04\n",
      "Epoch: 606\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 2.9091e-04\n",
      "Epoch: 607\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 3.6574e-04\n",
      "Epoch: 608\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 2.8060e-04\n",
      "Epoch: 609\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0024\n",
      "Epoch: 610\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0013\n",
      "Epoch: 611\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 8.9340e-04\n",
      "Epoch: 612\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 3.5289e-04\n",
      "Epoch: 613\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 3.8773e-04\n",
      "Epoch: 614\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 1.9628e-04\n",
      "Epoch: 615\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 2.6540e-04\n",
      "Epoch: 616\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 3.1739e-04\n",
      "Epoch: 617\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 4.0623e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 618\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.4895e-04\n",
      "Epoch: 619\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.4257e-04\n",
      "Epoch: 620\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 7.2073e-04\n",
      "Epoch: 621\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 9.2247e-04\n",
      "Epoch: 622\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0011\n",
      "Epoch: 623\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 8.9713e-04\n",
      "Epoch: 624\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.0664e-04\n",
      "Epoch: 625\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 2.9557e-04\n",
      "Epoch: 626\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 2.3069e-04\n",
      "Epoch: 627\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 3.5068e-04\n",
      "Epoch: 628\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.9024e-04\n",
      "Epoch: 629\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0011\n",
      "Epoch: 630\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 8.2705e-04\n",
      "Epoch: 631\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 4.0848e-04\n",
      "Epoch: 632\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.0397e-04\n",
      "Epoch: 633\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.2347e-04\n",
      "Epoch: 634\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.6528e-04\n",
      "Epoch: 635\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 8.0012e-04\n",
      "Epoch: 636\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 8.8368e-04\n",
      "Epoch: 637\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.6734e-04\n",
      "Epoch: 638\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 7.4284e-04\n",
      "Epoch: 639\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 7.2909e-04\n",
      "Epoch: 640\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 9.5061e-04\n",
      "Epoch: 641\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 4.8262e-04\n",
      "Epoch: 642\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 4.5617e-04\n",
      "Epoch: 643\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 3.2508e-04\n",
      "Epoch: 644\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 3.1818e-04\n",
      "Epoch: 645\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.2882e-04\n",
      "Epoch: 646\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.4788e-04\n",
      "Epoch: 647\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.3982e-04\n",
      "Epoch: 648\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 8.7910e-04\n",
      "Epoch: 649\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 9.7402e-04\n",
      "Epoch: 650\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0010\n",
      "Epoch: 651\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.2703e-04\n",
      "Epoch: 652\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 5.8574e-04\n",
      "Epoch: 653\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 4.9992e-04\n",
      "Epoch: 654\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 7.7583e-04\n",
      "Epoch: 655\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 6.4824e-04\n",
      "Epoch: 656\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 4.7947e-04\n",
      "Epoch: 657\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 2.5043e-04\n",
      "Epoch: 658\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 2.4619e-04\n",
      "Epoch: 659\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 2.4558e-04\n",
      "Epoch: 660\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 3.3345e-04\n",
      "Epoch: 661\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 8.7328e-04\n",
      "Epoch: 662\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0011\n",
      "Epoch: 663\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0019\n",
      "Epoch: 664\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 32ms/sample - loss: 6.8683e-04\n",
      "Epoch: 665\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.5446e-04\n",
      "Epoch: 666\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 3.9469e-04\n",
      "Epoch: 667\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 4.7195e-04\n",
      "Epoch: 668\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.0688e-04\n",
      "Epoch: 669\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 31ms/sample - loss: 3.4887e-04\n",
      "Epoch: 670\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 2.7502e-04\n",
      "Epoch: 671\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 2.5295e-04\n",
      "Epoch: 672\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 3.9433e-04\n",
      "Epoch: 673\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 5.6099e-04\n",
      "Epoch: 674\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 5.1342e-04\n",
      "Epoch: 675\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 8.7129e-04\n",
      "Epoch: 676\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 6.2863e-04\n",
      "Epoch: 677\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 8.6249e-04\n",
      "Epoch: 678\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0015\n",
      "Epoch: 679\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0015\n",
      "Epoch: 680\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0010\n",
      "Epoch: 681\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 7.4040e-04\n",
      "Epoch: 682\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 4.3841e-04\n",
      "Epoch: 683\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 2.4704e-04\n",
      "Epoch: 684\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 1.2827e-04\n",
      "Epoch: 685\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 1.5120e-04\n",
      "Epoch: 686\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 1.3556e-04\n",
      "Epoch: 687\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 2.2385e-04\n",
      "Epoch: 688\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 4.1372e-04\n",
      "Epoch: 689\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0012\n",
      "Epoch: 690\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 32ms/sample - loss: 0.0021\n",
      "Epoch: 691\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 0.0014\n",
      "Epoch: 692\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 7.8435e-04\n",
      "Epoch: 693\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 4.2302e-04\n",
      "Epoch: 694\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 2.3312e-04\n",
      "Epoch: 695\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 2.8623e-04\n",
      "Epoch: 696\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 2.1494e-04\n",
      "Epoch: 697\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 2.4464e-04\n",
      "Epoch: 698\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 2.4440e-04\n",
      "Epoch: 699\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 3.6862e-04\n",
      "Epoch: 700\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 8.1592e-04\n",
      "Epoch: 701\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 0.0012\n",
      "Epoch: 702\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0015\n",
      "Epoch: 703\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.2008e-04\n",
      "Epoch: 704\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 5.1794e-04\n",
      "Epoch: 705\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 29ms/sample - loss: 4.5054e-04\n",
      "Epoch: 706\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 4.3126e-04\n",
      "Epoch: 707\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 4.0074e-04\n",
      "Epoch: 708\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 2.5653e-04\n",
      "Epoch: 709\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 3.2769e-04\n",
      "Epoch: 710\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 5.1151e-04\n",
      "Epoch: 711\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 5.3334e-04\n",
      "Epoch: 712\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 6.4011e-04\n",
      "Epoch: 713\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 25ms/sample - loss: 4.7383e-04\n",
      "Epoch: 714\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 7.3645e-04\n",
      "Epoch: 715\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 6.0401e-04\n",
      "Epoch: 716\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 4.3723e-04\n",
      "Epoch: 717\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 4.6830e-04\n",
      "Epoch: 718\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 4.7697e-04\n",
      "Epoch: 719\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 6.7809e-04\n",
      "Epoch: 720\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 24ms/sample - loss: 5.8800e-04\n",
      "Epoch: 721\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 3.4436e-04\n",
      "Epoch: 722\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 25ms/sample - loss: 3.6220e-04\n",
      "Epoch: 723\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 5.8476e-04\n",
      "Epoch: 724\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0012\n",
      "Epoch: 725\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 6.7176e-04\n",
      "Epoch: 726\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 25ms/sample - loss: 6.4823e-04\n",
      "Epoch: 727\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 25ms/sample - loss: 6.5069e-04\n",
      "Epoch: 728\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 24ms/sample - loss: 6.3759e-04\n",
      "Epoch: 729\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.2864e-04\n",
      "Epoch: 730\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 2.3612e-04\n",
      "Epoch: 731\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.3417e-04\n",
      "Epoch: 732\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.8448e-04\n",
      "Epoch: 733\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.4347e-04\n",
      "Epoch: 734\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.7879e-04\n",
      "Epoch: 735\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.9191e-04\n",
      "Epoch: 736\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.4727e-04\n",
      "Epoch: 737\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.5972e-04\n",
      "Epoch: 738\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 739\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.9688e-04\n",
      "Epoch: 740\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 6.4518e-04\n",
      "Epoch: 741\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.5806e-04\n",
      "Epoch: 742\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 8.2456e-04\n",
      "Epoch: 743\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 5.9996e-04\n",
      "Epoch: 744\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.9615e-04\n",
      "Epoch: 745\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 2.9397e-04\n",
      "Epoch: 746\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 1.9947e-04\n",
      "Epoch: 747\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.1901e-04\n",
      "Epoch: 748\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.4278e-04\n",
      "Epoch: 749\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.5607e-04\n",
      "Epoch: 750\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 5.6891e-04\n",
      "Epoch: 751\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.6801e-04\n",
      "Epoch: 752\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.9066e-04\n",
      "Epoch: 753\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.3742e-04\n",
      "Epoch: 754\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.2674e-04\n",
      "Epoch: 755\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 8.0849e-04\n",
      "Epoch: 756\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.0328e-04\n",
      "Epoch: 757\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.5703e-04\n",
      "Epoch: 758\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.5555e-04\n",
      "Epoch: 759\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 2.6929e-04\n",
      "Epoch: 760\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 2.5136e-04\n",
      "Epoch: 761\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 1.7566e-04\n",
      "Epoch: 762\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.6329e-04\n",
      "Epoch: 763\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.1459e-04\n",
      "Epoch: 764\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.0826e-04\n",
      "Epoch: 765\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 5.9255e-04\n",
      "Epoch: 766\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.4838e-04\n",
      "Epoch: 767\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.1775e-04\n",
      "Epoch: 768\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.4539e-04\n",
      "Epoch: 769\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0018\n",
      "Epoch: 770\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 771\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.9079e-04\n",
      "Epoch: 772\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.0736e-04\n",
      "Epoch: 773\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.0093e-04\n",
      "Epoch: 774\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.6277e-04\n",
      "Epoch: 775\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.3217e-04\n",
      "Epoch: 776\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.1755e-04\n",
      "Epoch: 777\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.1829e-04\n",
      "Epoch: 778\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.4563e-04\n",
      "Epoch: 779\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.9900e-04\n",
      "Epoch: 780\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0015\n",
      "Epoch: 781\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 782\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.1721e-04\n",
      "Epoch: 783\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.4434e-04\n",
      "Epoch: 784\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.0125e-04\n",
      "Epoch: 785\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 1.8222e-04\n",
      "Epoch: 786\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.2272e-04\n",
      "Epoch: 787\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.2102e-04\n",
      "Epoch: 788\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.2028e-04\n",
      "Epoch: 789\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.9615e-04\n",
      "Epoch: 790\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.1800e-04\n",
      "Epoch: 791\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.7977e-04\n",
      "Epoch: 792\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.3711e-04\n",
      "Epoch: 793\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.6522e-04\n",
      "Epoch: 794\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.4868e-04\n",
      "Epoch: 795\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.5986e-04\n",
      "Epoch: 796\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.7650e-04\n",
      "Epoch: 797\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0016\n",
      "Epoch: 798\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 799\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.4884e-04\n",
      "Forecasting Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-04-18 12:56:03.531004: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=1, Predicted=9.509751, Expected=9.510000\n",
      "Month=2, Predicted=9.841917, Expected=9.796000\n",
      "Month=3, Predicted=9.499683, Expected=9.468500\n",
      "Month=4, Predicted=9.693735, Expected=9.672000\n",
      "Month=5, Predicted=9.703690, Expected=9.610000\n",
      "Month=6, Predicted=9.233274, Expected=9.240000\n",
      "Month=7, Predicted=10.336190, Expected=10.318300\n",
      "Month=8, Predicted=9.050406, Expected=8.974800\n",
      "Month=9, Predicted=9.263460, Expected=9.114000\n",
      "Month=10, Predicted=9.381236, Expected=9.300000\n",
      "Month=11, Predicted=8.620665, Expected=8.400000\n",
      "Month=12, Predicted=9.317475, Expected=9.300000\n",
      "Month=13, Predicted=9.037047, Expected=9.000000\n",
      "Month=14, Predicted=9.270672, Expected=9.300000\n",
      "Month=15, Predicted=9.442141, Expected=9.460000\n",
      "Month=16, Predicted=9.135697, Expected=9.145000\n",
      "Month=17, Predicted=9.004726, Expected=9.021000\n",
      "Month=18, Predicted=8.744082, Expected=8.750000\n",
      "Month=19, Predicted=8.747841, Expected=8.710000\n",
      "Month=20, Predicted=8.410953, Expected=8.370000\n",
      "Month=21, Predicted=8.574489, Expected=8.504000\n",
      "Month=22, Predicted=9.836875, Expected=9.819700\n",
      "Month=23, Predicted=9.938969, Expected=9.827300\n",
      "Month=24, Predicted=9.930103, Expected=9.929800\n",
      "Month=25, Predicted=9.285633, Expected=9.288000\n",
      "Month=26, Predicted=9.247504, Expected=9.300000\n",
      "Month=27, Predicted=9.078041, Expected=9.060000\n",
      "Month=28, Predicted=8.832986, Expected=8.835000\n",
      "Month=29, Predicted=8.529970, Expected=8.388600\n",
      "Month=30, Predicted=8.407311, Expected=8.400000\n",
      "Month=31, Predicted=8.489956, Expected=8.525000\n",
      "Month=32, Predicted=8.309826, Expected=8.250000\n",
      "Month=33, Predicted=8.480286, Expected=8.419000\n",
      "Month=34, Predicted=9.508925, Expected=9.455000\n",
      "Month=35, Predicted=8.645628, Expected=8.540000\n",
      "Month=36, Predicted=9.481646, Expected=9.455000\n",
      "Month=37, Predicted=9.021957, Expected=9.000000\n",
      "Month=38, Predicted=9.552543, Expected=9.599000\n",
      "Month=39, Predicted=9.477613, Expected=9.436000\n",
      "Month=40, Predicted=9.553862, Expected=9.539800\n",
      "Month=41, Predicted=9.084743, Expected=9.028600\n",
      "Month=42, Predicted=8.966384, Expected=8.932000\n",
      "Month=43, Predicted=8.973532, Expected=8.993000\n",
      "Month=44, Predicted=8.666585, Expected=8.678400\n",
      "Month=45, Predicted=9.066247, Expected=9.011100\n",
      "Month=46, Predicted=9.683741, Expected=9.630000\n",
      "Month=47, Predicted=8.659026, Expected=8.590400\n",
      "Month=48, Predicted=9.758589, Expected=9.736300\n",
      "Month=49, Predicted=9.423381, Expected=9.384500\n",
      "Month=50, Predicted=9.942736, Expected=9.947200\n",
      "Month=51, Predicted=9.623001, Expected=9.577100\n",
      "Month=52, Predicted=9.144974, Expected=9.117200\n",
      "Month=53, Predicted=9.172834, Expected=9.122500\n",
      "Month=54, Predicted=8.893519, Expected=8.880000\n",
      "Month=55, Predicted=8.739412, Expected=8.709200\n",
      "Month=56, Predicted=8.597780, Expected=8.428200\n",
      "Month=57, Predicted=10.126693, Expected=9.907600\n",
      "Month=58, Predicted=9.103429, Expected=9.145000\n",
      "Month=59, Predicted=8.602616, Expected=8.498000\n",
      "Month=60, Predicted=9.408208, Expected=9.362000\n",
      "Month=61, Predicted=9.055604, Expected=9.000000\n",
      "Month=62, Predicted=9.476236, Expected=9.455000\n",
      "Month=63, Predicted=9.289750, Expected=9.300000\n",
      "Month=64, Predicted=9.006346, Expected=8.990000\n",
      "Month=65, Predicted=8.990864, Expected=8.990000\n",
      "Month=66, Predicted=8.808503, Expected=8.790000\n",
      "Month=67, Predicted=8.872210, Expected=8.835000\n",
      "Month=68, Predicted=8.630598, Expected=8.700000\n",
      "Month=69, Predicted=8.863700, Expected=8.935000\n",
      "Month=70, Predicted=8.799082, Expected=8.835000\n",
      "Month=71, Predicted=8.281143, Expected=8.265000\n",
      "Month=72, Predicted=8.866383, Expected=8.835000\n",
      "Month=73, Predicted=8.513574, Expected=8.550000\n",
      "Month=74, Predicted=8.720214, Expected=8.680000\n",
      "Month=75, Predicted=8.425222, Expected=8.400000\n",
      "Month=76, Predicted=8.528173, Expected=8.525000\n",
      "Month=77, Predicted=8.405389, Expected=8.370000\n",
      "Month=78, Predicted=7.902518, Expected=7.890000\n",
      "Month=79, Predicted=7.847435, Expected=7.812000\n",
      "Month=80, Predicted=7.631998, Expected=7.620000\n",
      "Month=81, Predicted=7.722090, Expected=7.718000\n",
      "Month=82, Predicted=8.460775, Expected=8.323500\n",
      "Month=83, Predicted=6.906203, Expected=6.860000\n",
      "Month=84, Predicted=8.348177, Expected=8.308000\n",
      "Month=85, Predicted=8.074434, Expected=8.100000\n",
      "Month=86, Predicted=8.476991, Expected=8.525000\n",
      "Month=87, Predicted=8.220319, Expected=8.250000\n",
      "Month=88, Predicted=8.198903, Expected=8.215000\n",
      "Month=89, Predicted=8.162516, Expected=8.122600\n",
      "Month=90, Predicted=7.842316, Expected=7.778100\n",
      "Month=91, Predicted=7.984787, Expected=7.954600\n",
      "Month=92, Predicted=7.404864, Expected=7.420000\n",
      "Month=93, Predicted=7.532427, Expected=7.538300\n",
      "Month=94, Predicted=7.964838, Expected=7.905000\n",
      "Month=95, Predicted=7.191605, Expected=7.140000\n",
      "Month=96, Predicted=8.391520, Expected=8.432000\n",
      "Month=97, Predicted=7.696934, Expected=7.710000\n",
      "Month=98, Predicted=7.975841, Expected=7.967000\n",
      "Month=99, Predicted=7.354847, Expected=7.320000\n",
      "Month=100, Predicted=7.547956, Expected=7.502000\n",
      "Month=101, Predicted=7.436102, Expected=7.409000\n",
      "Month=102, Predicted=7.207453, Expected=7.200600\n",
      "Month=103, Predicted=7.869311, Expected=7.865000\n",
      "Month=104, Predicted=6.687481, Expected=6.690000\n",
      "Month=105, Predicted=6.952326, Expected=6.879400\n",
      "Month=106, Predicted=7.466505, Expected=7.440000\n",
      "Month=107, Predicted=6.921301, Expected=6.860000\n",
      "Month=108, Predicted=7.598814, Expected=7.595000\n",
      "Month=109, Predicted=7.249045, Expected=7.200000\n",
      "Month=110, Predicted=7.203819, Expected=7.130000\n",
      "Month=111, Predicted=6.898102, Expected=6.900000\n",
      "Month=112, Predicted=7.159155, Expected=7.130000\n",
      "Month=113, Predicted=7.155475, Expected=7.130000\n",
      "Month=114, Predicted=6.911345, Expected=6.840000\n",
      "Month=115, Predicted=7.095166, Expected=7.006000\n",
      "Month=116, Predicted=6.837637, Expected=6.780000\n",
      "Month=117, Predicted=7.135410, Expected=7.089600\n",
      "Month=118, Predicted=6.943231, Expected=6.882000\n",
      "Month=119, Predicted=6.540797, Expected=6.446700\n",
      "Month=120, Predicted=6.977416, Expected=6.882000\n",
      "Month=121, Predicted=6.638194, Expected=6.600000\n",
      "Month=122, Predicted=6.858867, Expected=6.820000\n",
      "Month=123, Predicted=6.618417, Expected=6.600000\n",
      "Month=124, Predicted=6.886703, Expected=6.820000\n",
      "Month=125, Predicted=6.721208, Expected=6.665000\n",
      "Month=126, Predicted=6.531060, Expected=6.450000\n",
      "Month=127, Predicted=6.705995, Expected=6.665000\n",
      "Month=128, Predicted=6.483493, Expected=6.450000\n",
      "Month=129, Predicted=6.732081, Expected=6.722100\n",
      "Month=130, Predicted=6.834179, Expected=6.820000\n",
      "Month=131, Predicted=6.190050, Expected=6.160000\n",
      "Month=132, Predicted=6.845146, Expected=6.820000\n",
      "Month=133, Predicted=6.524145, Expected=6.480000\n",
      "Month=134, Predicted=6.623018, Expected=6.596900\n",
      "Month=135, Predicted=6.505353, Expected=6.492000\n",
      "Month=136, Predicted=6.531668, Expected=6.510000\n",
      "Month=137, Predicted=6.336542, Expected=6.339500\n",
      "Month=138, Predicted=5.984311, Expected=6.001600\n",
      "Month=139, Predicted=6.116328, Expected=6.107000\n",
      "Month=140, Predicted=5.769356, Expected=5.790000\n",
      "Month=141, Predicted=5.900334, Expected=5.885000\n",
      "Month=142, Predicted=7.445708, Expected=7.280000\n",
      "Month=143, Predicted=6.101318, Expected=5.941600\n",
      "Month=144, Predicted=6.839323, Expected=6.810000\n",
      "Month=145, Predicted=6.249371, Expected=6.182000\n",
      "Month=146, Predicted=6.317578, Expected=6.293000\n",
      "Month=147, Predicted=6.156229, Expected=6.118600\n",
      "Month=148, Predicted=6.181654, Expected=6.138000\n",
      "Month=149, Predicted=6.106460, Expected=6.107000\n",
      "Month=150, Predicted=5.928485, Expected=5.913000\n",
      "Month=151, Predicted=6.178129, Expected=6.141100\n",
      "Month=152, Predicted=6.272482, Expected=6.248000\n",
      "Month=153, Predicted=5.853321, Expected=5.829700\n",
      "Month=154, Predicted=6.890989, Expected=6.829300\n",
      "Month=155, Predicted=6.734679, Expected=6.694400\n",
      "Month=156, Predicted=7.825685, Expected=7.726200\n",
      "Month=157, Predicted=7.099258, Expected=7.054400\n",
      "Month=158, Predicted=7.371502, Expected=7.268900\n",
      "Month=159, Predicted=7.072616, Expected=7.020000\n",
      "Month=160, Predicted=6.572679, Expected=6.510000\n",
      "Month=161, Predicted=6.409275, Expected=6.370500\n",
      "Month=162, Predicted=5.777739, Expected=5.730000\n",
      "Month=163, Predicted=5.854075, Expected=5.828000\n",
      "Month=164, Predicted=5.668569, Expected=5.580000\n",
      "Month=165, Predicted=5.676843, Expected=5.709900\n",
      "Month=166, Predicted=6.844846, Expected=6.696000\n",
      "Month=167, Predicted=6.317284, Expected=6.248000\n",
      "Month=168, Predicted=6.749764, Expected=6.711600\n",
      "Month=169, Predicted=6.641729, Expected=6.600100\n",
      "Month=170, Predicted=7.600426, Expected=7.508200\n",
      "Month=171, Predicted=7.812181, Expected=7.765000\n",
      "Month=172, Predicted=7.323382, Expected=7.285000\n",
      "Month=173, Predicted=6.994882, Expected=6.959500\n",
      "Month=174, Predicted=6.477150, Expected=6.450000\n",
      "Month=175, Predicted=6.581009, Expected=6.572000\n",
      "Month=176, Predicted=6.620505, Expected=6.600000\n",
      "Month=177, Predicted=4.273965, Expected=4.265300\n",
      "Month=178, Predicted=7.371534, Expected=7.367000\n",
      "Month=179, Predicted=6.515599, Expected=6.544000\n",
      "Month=180, Predicted=6.932532, Expected=6.940800\n",
      "Train RMSE: 0.05782\n",
      "Train RMSPE: 0.75049\n",
      "Train MAE: 0.04317\n",
      "Train MAPE: 0.56289\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=6.410505, Expected=6.786000\n",
      "Month=2, Predicted=7.409989, Expected=6.981200\n",
      "Month=3, Predicted=7.972760, Expected=6.756000\n",
      "Month=4, Predicted=6.529756, Expected=6.733200\n",
      "Month=5, Predicted=6.444477, Expected=6.671200\n",
      "Month=6, Predicted=6.315458, Expected=6.295600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=7, Predicted=6.392668, Expected=6.432500\n",
      "Month=8, Predicted=5.952260, Expected=6.153000\n",
      "Month=9, Predicted=6.109158, Expected=6.389500\n",
      "Month=10, Predicted=6.642535, Expected=7.192000\n",
      "Month=11, Predicted=6.236628, Expected=6.524000\n",
      "Month=12, Predicted=7.393898, Expected=7.238500\n",
      "Month=13, Predicted=7.093878, Expected=6.990000\n",
      "Month=14, Predicted=7.549581, Expected=7.254000\n",
      "Month=15, Predicted=6.962036, Expected=6.720000\n",
      "Month=16, Predicted=6.625472, Expected=6.944000\n",
      "Month=17, Predicted=6.733350, Expected=7.052500\n",
      "Month=18, Predicted=6.533096, Expected=6.690000\n",
      "Month=19, Predicted=7.795594, Expected=6.909900\n",
      "Month=20, Predicted=6.843902, Expected=6.819000\n",
      "Month=21, Predicted=7.042759, Expected=7.167200\n",
      "Month=22, Predicted=6.905890, Expected=7.254000\n",
      "Month=23, Predicted=6.607202, Expected=6.664000\n",
      "Month=24, Predicted=7.117190, Expected=7.393500\n",
      "Month=25, Predicted=7.381160, Expected=7.125000\n",
      "Month=26, Predicted=7.429860, Expected=7.347000\n",
      "Month=27, Predicted=7.107555, Expected=7.216500\n",
      "Month=28, Predicted=7.118636, Expected=7.254000\n",
      "Month=29, Predicted=6.900137, Expected=7.238500\n",
      "Month=30, Predicted=6.730969, Expected=6.990000\n",
      "Month=31, Predicted=7.110259, Expected=7.192000\n",
      "Month=32, Predicted=7.197370, Expected=6.900000\n",
      "Month=33, Predicted=6.842277, Expected=7.427300\n",
      "Month=34, Predicted=7.148635, Expected=7.300500\n",
      "Month=35, Predicted=6.970986, Expected=6.902000\n",
      "Month=36, Predicted=7.545828, Expected=7.409000\n",
      "Month=37, Predicted=7.094447, Expected=7.179000\n",
      "Month=38, Predicted=7.632361, Expected=7.424500\n",
      "Month=39, Predicted=7.161731, Expected=7.275000\n",
      "Month=40, Predicted=7.391523, Expected=7.316000\n",
      "Month=41, Predicted=6.964117, Expected=7.086300\n",
      "Month=42, Predicted=6.772169, Expected=7.020000\n",
      "Month=43, Predicted=6.806222, Expected=7.270500\n",
      "Month=44, Predicted=6.965484, Expected=7.168800\n",
      "Month=45, Predicted=7.258775, Expected=7.448600\n",
      "Month=46, Predicted=7.460520, Expected=7.440200\n",
      "Test RMSE: 0.33036\n",
      "Test RMSPE: 4.75450\n",
      "Test MAE: 0.24713\n",
      "Test MAPE: 3.53050\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# oil static.py d-lstm \n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='relu', batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')   \n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=5\n",
    "\tneurons=[5,4,2] \n",
    "\tn_epochs=800\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acded694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 13:05:14.907127: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-18 13:05:14.908798: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_79316/3380753055.py:26: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_79316/3380753055.py:240: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_79316/3380753055.py:144: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 13:05:16.077663: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-18 13:05:16.110922: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-18 13:05:16.181164: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 5s 23ms/sample - loss: 0.0492\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0439\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0398\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0368\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0350\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 25ms/sample - loss: 0.0336\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0325\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0317\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0312\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0306\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0301\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0296\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0292\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0287\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0284\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0280\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0277\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0275\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0272\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0270\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0268\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0266\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0263\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0262\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0259\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0257\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0254\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0252\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0250\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0247\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0245\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0243\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0241\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0239\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0237\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0236\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0234\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0232\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0231\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0230\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0229\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0227\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0225\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0225\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0223\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0222\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0221\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0220\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0218\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0217\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0216\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0216\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0214\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0212\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0212\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0210\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0208\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0206\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0204\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0203\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0202\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0201\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0200\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0197\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0198\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0197\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0195\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0197\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0193\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0191\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0189\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0183\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0182\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0180\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0178\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0173\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0174\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0172\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0171\n",
      "Epoch: 79\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0168\n",
      "Epoch: 80\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0166\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0163\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0163\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0160\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0158\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0153\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0155\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0151\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0151\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0145\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0145\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0142\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0141\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0140\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0138\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0139\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0136\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0138\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0135\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0133\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0130\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0133\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0129\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0128\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0122\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0123\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0118\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0117\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0114\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0114\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0112\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0110\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0107\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0109\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0107\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0106\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0106\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0106\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0105\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0102\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0101\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0102\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0098\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0097\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0095\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0092\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0092\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0094\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0097\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0096\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0100\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0099\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0095\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0087\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0088\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0089\n",
      "Epoch: 136\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0088\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0088\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0083\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0084\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0083\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0083\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0083\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0090\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0086\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0085\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0088\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0080\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0084\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0079\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0075\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0078\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0074\n",
      "Epoch: 153\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0073\n",
      "Epoch: 154\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0081\n",
      "Epoch: 155\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0079\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0073\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0071\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0076\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0070\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0079\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0088\n",
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0087\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0077\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0071\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0064\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0067\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0064\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0065\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0063\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0065\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0072\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0074\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0076\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0062\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0063\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0056\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0063\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0068\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0057\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0065\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0061\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0066\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0078\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0056\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0054\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0057\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0054\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0059\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0060\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0061\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0061\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0065\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0071\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0054\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0052\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0057\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0051\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0049\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0047\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0051\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0051\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0052\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0051\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0052\n",
      "Epoch: 205\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0060\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0067\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0053\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0050\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0066\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0047\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0043\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0041\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0039\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0043\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0043\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0059\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0058\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0045\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0049\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0047\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0071\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0048\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0042\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0037\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0031\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0030\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0039\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0034\n",
      "Epoch: 229\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0036\n",
      "Epoch: 230\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0035\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0055\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0041\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0079\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0040\n",
      "Epoch: 235\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0041\n",
      "Epoch: 236\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0030\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0029\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0026\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0027\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0037\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0030\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0059\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0048\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0048\n",
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0032\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0034\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0027\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0034\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0028\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0045\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0030\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0028\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0024\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0024\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0028\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0038\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0049\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0033\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0029\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0035\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0024\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0021\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0019\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0019\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0021\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0025\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0047\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0055\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0038\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0022\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0025\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0027\n",
      "Epoch: 273\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0024\n",
      "Epoch: 274\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0034\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0023\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0047\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0028\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0034\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0027\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0017\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0017\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0022\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0023\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0022\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0025\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0029\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0019\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0070\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0035\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0023\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0021\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0026\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0028\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0025\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0040\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0032\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0027\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0045\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0020\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0017\n",
      "Epoch: 305\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 308\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0020\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0024\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0025\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0015\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0026\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0064\n",
      "Epoch: 314\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0030\n",
      "Epoch: 315\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0019\n",
      "Epoch: 316\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0016\n",
      "Epoch: 317\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 318\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 319\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.8425e-04\n",
      "Epoch: 320\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 321\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0047\n",
      "Epoch: 322\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0041\n",
      "Epoch: 323\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0025\n",
      "Epoch: 324\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0016\n",
      "Epoch: 325\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 326\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0013\n",
      "Epoch: 327\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0016\n",
      "Epoch: 328\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0015\n",
      "Epoch: 329\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0031\n",
      "Epoch: 330\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0029\n",
      "Epoch: 331\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0021\n",
      "Epoch: 332\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0015\n",
      "Epoch: 333\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 334\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0017\n",
      "Epoch: 335\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0016\n",
      "Epoch: 336\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0018\n",
      "Epoch: 337\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0025\n",
      "Epoch: 338\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0034\n",
      "Epoch: 339\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0029\n",
      "Epoch: 340\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0019\n",
      "Epoch: 341\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 342\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 343\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0013\n",
      "Epoch: 344\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 345\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 346\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0019\n",
      "Epoch: 347\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0019\n",
      "Epoch: 348\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0023\n",
      "Epoch: 349\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0027\n",
      "Epoch: 350\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0020\n",
      "Epoch: 351\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0016\n",
      "Epoch: 352\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 353\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 354\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.1182e-04\n",
      "Epoch: 355\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 356\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0017\n",
      "Epoch: 357\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0018\n",
      "Epoch: 358\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0037\n",
      "Epoch: 359\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0033\n",
      "Epoch: 360\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0017\n",
      "Epoch: 361\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 362\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 363\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 364\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 365\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 366\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 367\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 368\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0013\n",
      "Epoch: 369\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0025\n",
      "Epoch: 370\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0073\n",
      "Epoch: 371\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0030\n",
      "Epoch: 372\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 373\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 374\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.4788e-04\n",
      "Epoch: 375\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.3779e-04\n",
      "Epoch: 376\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.8279e-04\n",
      "Epoch: 377\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 378\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 379\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0016\n",
      "Epoch: 380\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0021\n",
      "Epoch: 381\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0019\n",
      "Epoch: 382\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 383\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 384\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 385\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0021\n",
      "Epoch: 386\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0025\n",
      "Epoch: 387\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0074\n",
      "Epoch: 388\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0031\n",
      "Epoch: 389\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 390\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.3910e-04\n",
      "Epoch: 391\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.4803e-04\n",
      "Epoch: 392\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.0800e-04\n",
      "Epoch: 393\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.9199e-04\n",
      "Epoch: 394\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.0935e-04\n",
      "Epoch: 395\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.1179e-04\n",
      "Epoch: 396\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 397\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0023\n",
      "Epoch: 398\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0037\n",
      "Epoch: 399\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0022\n",
      "Epoch: 400\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0016\n",
      "Epoch: 401\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0013\n",
      "Epoch: 402\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.7080e-04\n",
      "Epoch: 403\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.8103e-04\n",
      "Epoch: 404\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 405\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0017\n",
      "Epoch: 406\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0021\n",
      "Epoch: 407\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0026\n",
      "Epoch: 408\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0020\n",
      "Epoch: 409\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0015\n",
      "Epoch: 410\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 411\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.4400e-04\n",
      "Epoch: 412\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.1102e-04\n",
      "Epoch: 413\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.5125e-04\n",
      "Epoch: 414\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.8765e-04\n",
      "Epoch: 415\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0021\n",
      "Epoch: 416\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0020\n",
      "Epoch: 417\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0026\n",
      "Epoch: 418\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0015\n",
      "Epoch: 419\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0013\n",
      "Epoch: 420\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 421\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0026\n",
      "Epoch: 422\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0024\n",
      "Epoch: 423\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0019\n",
      "Epoch: 424\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 425\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.9121e-04\n",
      "Epoch: 426\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.0715e-04\n",
      "Epoch: 427\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.7166e-04\n",
      "Epoch: 428\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.5132e-04\n",
      "Epoch: 429\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 430\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0050\n",
      "Epoch: 431\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0085\n",
      "Epoch: 432\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0037\n",
      "Epoch: 433\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0017\n",
      "Epoch: 434\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 435\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.6536e-04\n",
      "Epoch: 436\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.6036e-04\n",
      "Epoch: 437\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.5273e-04\n",
      "Epoch: 438\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.9140e-04\n",
      "Epoch: 439\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.2751e-04\n",
      "Epoch: 440\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.0329e-04\n",
      "Epoch: 441\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.6939e-04\n",
      "Epoch: 442\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.0031e-04\n",
      "Epoch: 443\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.9396e-04\n",
      "Epoch: 444\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0021\n",
      "Epoch: 445\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0019\n",
      "Epoch: 446\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 447\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.6091e-04\n",
      "Epoch: 448\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0035\n",
      "Epoch: 449\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0056\n",
      "Epoch: 450\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 33ms/sample - loss: 0.0023\n",
      "Epoch: 451\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 452\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.1225e-04\n",
      "Epoch: 453\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.1901e-04\n",
      "Epoch: 454\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.8405e-04\n",
      "Epoch: 455\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 25ms/sample - loss: 4.7539e-04\n",
      "Epoch: 456\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 27ms/sample - loss: 5.3414e-04\n",
      "Epoch: 457\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 6s 33ms/sample - loss: 4.7132e-04\n",
      "Epoch: 458\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 8.6416e-04\n",
      "Epoch: 459\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 30ms/sample - loss: 0.0011\n",
      "Epoch: 460\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0018\n",
      "Epoch: 461\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0025\n",
      "Epoch: 462\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0018\n",
      "Epoch: 463\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0020\n",
      "Epoch: 464\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0029\n",
      "Epoch: 465\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0016\n",
      "Epoch: 466\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0010\n",
      "Epoch: 467\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 7.6215e-04\n",
      "Epoch: 468\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.4225e-04\n",
      "Epoch: 469\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.3641e-04\n",
      "Epoch: 470\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.7819e-04\n",
      "Epoch: 471\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.3634e-04\n",
      "Epoch: 472\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 473\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0020\n",
      "Epoch: 474\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0043\n",
      "Epoch: 475\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0047\n",
      "Epoch: 476\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0021\n",
      "Epoch: 477\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.8137e-04\n",
      "Epoch: 478\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.7233e-04\n",
      "Epoch: 479\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.2304e-04\n",
      "Epoch: 480\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.2670e-04\n",
      "Epoch: 481\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.9358e-04\n",
      "Epoch: 482\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.2300e-04\n",
      "Epoch: 483\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.3056e-04\n",
      "Epoch: 484\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.0860e-04\n",
      "Epoch: 485\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.5894e-04\n",
      "Epoch: 486\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 487\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0029\n",
      "Epoch: 488\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0026\n",
      "Epoch: 489\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0015\n",
      "Epoch: 490\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 491\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.7904e-04\n",
      "Epoch: 492\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.9262e-04\n",
      "Epoch: 493\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.1097e-04\n",
      "Epoch: 494\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.7827e-04\n",
      "Epoch: 495\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0015\n",
      "Epoch: 496\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 497\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.5273e-04\n",
      "Epoch: 498\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 499\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 500\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 501\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0013\n",
      "Epoch: 502\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0018\n",
      "Epoch: 503\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 504\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 505\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 506\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 507\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.1122e-04\n",
      "Epoch: 508\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.8949e-04\n",
      "Epoch: 509\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.0324e-04\n",
      "Epoch: 510\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.6029e-04\n",
      "Epoch: 511\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 512\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0013\n",
      "Epoch: 513\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.9067e-04\n",
      "Epoch: 514\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 515\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0024\n",
      "Epoch: 516\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0040\n",
      "Epoch: 517\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 518\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.1910e-04\n",
      "Epoch: 519\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.3964e-04\n",
      "Epoch: 520\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.1512e-04\n",
      "Epoch: 521\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.8182e-04\n",
      "Epoch: 522\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.6931e-04\n",
      "Epoch: 523\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.6224e-04\n",
      "Epoch: 524\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.0022e-04\n",
      "Epoch: 525\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.8139e-04\n",
      "Epoch: 526\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.4685e-04\n",
      "Epoch: 527\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.4323e-04\n",
      "Epoch: 528\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 529\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0018\n",
      "Epoch: 530\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0018\n",
      "Epoch: 531\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0018\n",
      "Epoch: 532\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0016\n",
      "Epoch: 533\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0024\n",
      "Epoch: 534\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0016\n",
      "Epoch: 535\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.4248e-04\n",
      "Epoch: 536\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.7396e-04\n",
      "Epoch: 537\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.8616e-04\n",
      "Epoch: 538\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.9274e-04\n",
      "Epoch: 539\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.8761e-04\n",
      "Epoch: 540\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.5956e-04\n",
      "Epoch: 541\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.1696e-04\n",
      "Epoch: 542\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 543\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 544\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.4990e-04\n",
      "Epoch: 545\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 546\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.5757e-04\n",
      "Epoch: 547\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.1168e-04\n",
      "Epoch: 548\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.1241e-04\n",
      "Epoch: 549\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.7179e-04\n",
      "Epoch: 550\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 551\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.0626e-04\n",
      "Epoch: 552\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 553\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 554\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 555\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.3134e-04\n",
      "Epoch: 556\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 557\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0022\n",
      "Epoch: 558\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.3586e-04\n",
      "Epoch: 559\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.2962e-04\n",
      "Epoch: 560\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.6519e-04\n",
      "Epoch: 561\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.6316e-04\n",
      "Epoch: 562\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.2647e-04\n",
      "Epoch: 563\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.7224e-04\n",
      "Epoch: 564\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.9810e-04\n",
      "Epoch: 565\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.6277e-04\n",
      "Epoch: 566\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 567\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.9573e-04\n",
      "Epoch: 568\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 569\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 570\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 571\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 572\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 573\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.2826e-04\n",
      "Epoch: 574\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.5142e-04\n",
      "Epoch: 575\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.6534e-04\n",
      "Epoch: 576\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 577\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.4032e-04\n",
      "Epoch: 578\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.2359e-04\n",
      "Epoch: 579\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.0857e-04\n",
      "Epoch: 580\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.5317e-04\n",
      "Epoch: 581\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 582\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.8676e-04\n",
      "Epoch: 583\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.4515e-04\n",
      "Epoch: 584\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.6432e-04\n",
      "Epoch: 585\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.4746e-04\n",
      "Epoch: 586\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 7.6732e-04\n",
      "Epoch: 587\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 588\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0012\n",
      "Epoch: 589\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0035\n",
      "Epoch: 590\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 591\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 5.5156e-04\n",
      "Epoch: 592\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.5674e-04\n",
      "Epoch: 593\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 3.8672e-04\n",
      "Epoch: 594\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.3732e-04\n",
      "Epoch: 595\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.9641e-04\n",
      "Epoch: 596\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 8.4624e-04\n",
      "Epoch: 597\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0026\n",
      "Epoch: 598\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 599\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.5562e-04\n",
      "Epoch: 600\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.0312e-04\n",
      "Epoch: 601\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 5.0933e-04\n",
      "Epoch: 602\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.2197e-04\n",
      "Epoch: 603\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 4.5498e-04\n",
      "Epoch: 604\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.4183e-04\n",
      "Epoch: 605\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.6251e-04\n",
      "Epoch: 606\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 607\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0010\n",
      "Epoch: 608\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 7.7348e-04\n",
      "Epoch: 609\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 7.0912e-04\n",
      "Epoch: 610\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 5.6263e-04\n",
      "Epoch: 611\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 5.6390e-04\n",
      "Epoch: 612\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 9.7780e-04\n",
      "Epoch: 613\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0011\n",
      "Epoch: 614\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.0023e-04\n",
      "Epoch: 615\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 8.3443e-04\n",
      "Epoch: 616\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 7.7705e-04\n",
      "Epoch: 617\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.8691e-04\n",
      "Epoch: 618\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 8.0959e-04\n",
      "Epoch: 619\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 8.6701e-04\n",
      "Epoch: 620\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.3354e-04\n",
      "Epoch: 621\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.1889e-04\n",
      "Epoch: 622\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.0205e-04\n",
      "Epoch: 623\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.6489e-04\n",
      "Epoch: 624\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0014\n",
      "Epoch: 625\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0013\n",
      "Epoch: 626\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 627\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.4388e-04\n",
      "Epoch: 628\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.3178e-04\n",
      "Epoch: 629\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.1831e-04\n",
      "Epoch: 630\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.2170e-04\n",
      "Epoch: 631\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.1518e-04\n",
      "Epoch: 632\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0016\n",
      "Epoch: 633\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0020\n",
      "Epoch: 634\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0027\n",
      "Epoch: 635\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0013\n",
      "Epoch: 636\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.8737e-04\n",
      "Epoch: 637\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.4854e-04\n",
      "Epoch: 638\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.1574e-04\n",
      "Epoch: 639\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 1.8896e-04\n",
      "Epoch: 640\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 1.8724e-04\n",
      "Epoch: 641\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.4182e-04\n",
      "Epoch: 642\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.8780e-04\n",
      "Epoch: 643\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.0124e-04\n",
      "Epoch: 644\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.6017e-04\n",
      "Epoch: 645\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.5290e-04\n",
      "Epoch: 646\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.1498e-04\n",
      "Epoch: 647\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0018\n",
      "Epoch: 648\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0022\n",
      "Epoch: 649\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0015\n",
      "Epoch: 650\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.7537e-04\n",
      "Epoch: 651\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.3666e-04\n",
      "Epoch: 652\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.2531e-04\n",
      "Epoch: 653\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 2.1132e-04\n",
      "Epoch: 654\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.0221e-04\n",
      "Epoch: 655\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.4391e-04\n",
      "Epoch: 656\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.2655e-04\n",
      "Epoch: 657\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.4635e-04\n",
      "Epoch: 658\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 659\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.4924e-04\n",
      "Epoch: 660\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.0791e-04\n",
      "Epoch: 661\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.0662e-04\n",
      "Epoch: 662\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.9205e-04\n",
      "Epoch: 663\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.6826e-04\n",
      "Epoch: 664\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.0610e-04\n",
      "Epoch: 665\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.1984e-04\n",
      "Epoch: 666\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.8672e-04\n",
      "Epoch: 667\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.2144e-04\n",
      "Epoch: 668\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.1827e-04\n",
      "Epoch: 669\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.9343e-04\n",
      "Epoch: 670\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 671\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.4580e-04\n",
      "Epoch: 672\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.4881e-04\n",
      "Epoch: 673\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.8006e-04\n",
      "Epoch: 674\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.9756e-04\n",
      "Epoch: 675\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.3113e-04\n",
      "Epoch: 676\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 677\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0033\n",
      "Epoch: 678\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.3561e-04\n",
      "Epoch: 679\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 5.1723e-04\n",
      "Epoch: 680\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.6857e-04\n",
      "Epoch: 681\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.2807e-04\n",
      "Epoch: 682\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.9805e-04\n",
      "Epoch: 683\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.2041e-04\n",
      "Epoch: 684\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.2094e-04\n",
      "Epoch: 685\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.2443e-04\n",
      "Epoch: 686\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.3599e-04\n",
      "Epoch: 687\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.0632e-04\n",
      "Epoch: 688\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 3.2181e-04\n",
      "Epoch: 689\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 4.1418e-04\n",
      "Epoch: 690\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.4543e-04\n",
      "Epoch: 691\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 5.2463e-04\n",
      "Epoch: 692\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 9.1183e-04\n",
      "Epoch: 693\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 8.7577e-04\n",
      "Epoch: 694\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 7.7836e-04\n",
      "Epoch: 695\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 696\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.8453e-04\n",
      "Epoch: 697\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.1076e-04\n",
      "Epoch: 698\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.2733e-04\n",
      "Epoch: 699\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.8720e-04\n",
      "Epoch: 700\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.2205e-04\n",
      "Epoch: 701\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.5781e-04\n",
      "Epoch: 702\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.4472e-04\n",
      "Epoch: 703\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.3589e-04\n",
      "Epoch: 704\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.1490e-04\n",
      "Epoch: 705\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.4966e-04\n",
      "Epoch: 706\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.4661e-04\n",
      "Epoch: 707\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.6023e-04\n",
      "Epoch: 708\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.0731e-04\n",
      "Epoch: 709\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.4342e-04\n",
      "Epoch: 710\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.3145e-04\n",
      "Epoch: 711\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.5697e-04\n",
      "Epoch: 712\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.4447e-04\n",
      "Epoch: 713\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0012\n",
      "Epoch: 714\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0011\n",
      "Epoch: 715\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.5421e-04\n",
      "Epoch: 716\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0010\n",
      "Epoch: 717\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 9.1995e-04\n",
      "Epoch: 718\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.5397e-04\n",
      "Epoch: 719\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 24ms/sample - loss: 2.9398e-04\n",
      "Epoch: 720\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 1.7515e-04\n",
      "Epoch: 721\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 24ms/sample - loss: 1.1938e-04\n",
      "Epoch: 722\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 1.2176e-04\n",
      "Epoch: 723\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 2.0414e-04\n",
      "Epoch: 724\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.0718e-04\n",
      "Epoch: 725\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.0599e-04\n",
      "Epoch: 726\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0011\n",
      "Epoch: 727\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 8.0310e-04\n",
      "Epoch: 728\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 9.9572e-04\n",
      "Epoch: 729\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.0563e-04\n",
      "Epoch: 730\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.5840e-04\n",
      "Epoch: 731\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.1682e-04\n",
      "Epoch: 732\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.6631e-04\n",
      "Epoch: 733\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 2.8749e-04\n",
      "Epoch: 734\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.5980e-04\n",
      "Epoch: 735\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 7.3252e-04\n",
      "Epoch: 736\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 6.2412e-04\n",
      "Epoch: 737\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 5.8108e-04\n",
      "Epoch: 738\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 5.7261e-04\n",
      "Epoch: 739\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0014\n",
      "Epoch: 740\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0013\n",
      "Epoch: 741\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 7.3356e-04\n",
      "Epoch: 742\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 6.6939e-04\n",
      "Epoch: 743\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.0266e-04\n",
      "Epoch: 744\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.0514e-04\n",
      "Epoch: 745\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 2.4414e-04\n",
      "Epoch: 746\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 2.0247e-04\n",
      "Epoch: 747\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 1.5566e-04\n",
      "Epoch: 748\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 1.3154e-04\n",
      "Epoch: 749\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 1.9645e-04\n",
      "Epoch: 750\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.6080e-04\n",
      "Epoch: 751\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 7.6221e-04\n",
      "Epoch: 752\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0012\n",
      "Epoch: 753\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0021\n",
      "Epoch: 754\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0015\n",
      "Epoch: 755\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 8.0436e-04\n",
      "Epoch: 756\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 6.7781e-04\n",
      "Epoch: 757\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.4764e-04\n",
      "Epoch: 758\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 2.5431e-04\n",
      "Epoch: 759\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.7372e-04\n",
      "Epoch: 760\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 7.9220e-04\n",
      "Epoch: 761\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 5.6542e-04\n",
      "Epoch: 762\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 5.6523e-04\n",
      "Epoch: 763\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.2245e-04\n",
      "Epoch: 764\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.3963e-04\n",
      "Epoch: 765\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.9825e-04\n",
      "Epoch: 766\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 5.9272e-04\n",
      "Epoch: 767\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 5.5241e-04\n",
      "Epoch: 768\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.5633e-04\n",
      "Epoch: 769\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.4799e-04\n",
      "Epoch: 770\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 5.3577e-04\n",
      "Epoch: 771\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 3.9583e-04\n",
      "Epoch: 772\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.2527e-04\n",
      "Epoch: 773\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 7.8737e-04\n",
      "Epoch: 774\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0014\n",
      "Epoch: 775\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0019\n",
      "Epoch: 776\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0013\n",
      "Epoch: 777\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 6.5710e-04\n",
      "Epoch: 778\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.3932e-04\n",
      "Epoch: 779\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 2.7400e-04\n",
      "Epoch: 780\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 2.9654e-04\n",
      "Epoch: 781\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 1.9957e-04\n",
      "Epoch: 782\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 2.2914e-04\n",
      "Epoch: 783\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.1066e-04\n",
      "Epoch: 784\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.7712e-04\n",
      "Epoch: 785\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.4550e-04\n",
      "Epoch: 786\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 6.3557e-04\n",
      "Epoch: 787\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.4544e-04\n",
      "Epoch: 788\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.0709e-04\n",
      "Epoch: 789\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.7077e-04\n",
      "Epoch: 790\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 5.5216e-04\n",
      "Epoch: 791\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 4.5475e-04\n",
      "Epoch: 792\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.0881e-04\n",
      "Epoch: 793\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.3101e-04\n",
      "Epoch: 794\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 6.4793e-04\n",
      "Epoch: 795\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 8.5327e-04\n",
      "Epoch: 796\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 5.9884e-04\n",
      "Epoch: 797\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 6.3410e-04\n",
      "Epoch: 798\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 4.4975e-04\n",
      "Epoch: 799\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 3.8712e-04\n",
      "Forecasting Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-04-18 13:57:55.992280: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=1, Predicted=9.420734, Expected=9.510000\n",
      "Month=2, Predicted=9.725936, Expected=9.796000\n",
      "Month=3, Predicted=9.467804, Expected=9.468500\n",
      "Month=4, Predicted=9.630894, Expected=9.672000\n",
      "Month=5, Predicted=9.750530, Expected=9.610000\n",
      "Month=6, Predicted=9.325850, Expected=9.240000\n",
      "Month=7, Predicted=10.414488, Expected=10.318300\n",
      "Month=8, Predicted=9.000726, Expected=8.974800\n",
      "Month=9, Predicted=9.072520, Expected=9.114000\n",
      "Month=10, Predicted=9.365121, Expected=9.300000\n",
      "Month=11, Predicted=8.428969, Expected=8.400000\n",
      "Month=12, Predicted=9.290528, Expected=9.300000\n",
      "Month=13, Predicted=9.030118, Expected=9.000000\n",
      "Month=14, Predicted=9.296440, Expected=9.300000\n",
      "Month=15, Predicted=9.463687, Expected=9.460000\n",
      "Month=16, Predicted=9.187060, Expected=9.145000\n",
      "Month=17, Predicted=9.065496, Expected=9.021000\n",
      "Month=18, Predicted=8.796984, Expected=8.750000\n",
      "Month=19, Predicted=8.768035, Expected=8.710000\n",
      "Month=20, Predicted=8.428126, Expected=8.370000\n",
      "Month=21, Predicted=8.578026, Expected=8.504000\n",
      "Month=22, Predicted=9.922040, Expected=9.819700\n",
      "Month=23, Predicted=9.850543, Expected=9.827300\n",
      "Month=24, Predicted=9.905421, Expected=9.929800\n",
      "Month=25, Predicted=9.301725, Expected=9.288000\n",
      "Month=26, Predicted=9.325280, Expected=9.300000\n",
      "Month=27, Predicted=9.044122, Expected=9.060000\n",
      "Month=28, Predicted=8.853224, Expected=8.835000\n",
      "Month=29, Predicted=8.471921, Expected=8.388600\n",
      "Month=30, Predicted=8.505920, Expected=8.400000\n",
      "Month=31, Predicted=8.532047, Expected=8.525000\n",
      "Month=32, Predicted=8.360612, Expected=8.250000\n",
      "Month=33, Predicted=8.443001, Expected=8.419000\n",
      "Month=34, Predicted=9.440896, Expected=9.455000\n",
      "Month=35, Predicted=8.493979, Expected=8.540000\n",
      "Month=36, Predicted=9.430684, Expected=9.455000\n",
      "Month=37, Predicted=9.031697, Expected=9.000000\n",
      "Month=38, Predicted=9.614045, Expected=9.599000\n",
      "Month=39, Predicted=9.452007, Expected=9.436000\n",
      "Month=40, Predicted=9.588946, Expected=9.539800\n",
      "Month=41, Predicted=9.067420, Expected=9.028600\n",
      "Month=42, Predicted=8.979635, Expected=8.932000\n",
      "Month=43, Predicted=9.013262, Expected=8.993000\n",
      "Month=44, Predicted=8.709089, Expected=8.678400\n",
      "Month=45, Predicted=9.020090, Expected=9.011100\n",
      "Month=46, Predicted=9.659577, Expected=9.630000\n",
      "Month=47, Predicted=8.583846, Expected=8.590400\n",
      "Month=48, Predicted=9.769860, Expected=9.736300\n",
      "Month=49, Predicted=9.384134, Expected=9.384500\n",
      "Month=50, Predicted=9.959464, Expected=9.947200\n",
      "Month=51, Predicted=9.624027, Expected=9.577100\n",
      "Month=52, Predicted=9.184641, Expected=9.117200\n",
      "Month=53, Predicted=9.117217, Expected=9.122500\n",
      "Month=54, Predicted=8.898421, Expected=8.880000\n",
      "Month=55, Predicted=8.722606, Expected=8.709200\n",
      "Month=56, Predicted=8.401833, Expected=8.428200\n",
      "Month=57, Predicted=9.627927, Expected=9.907600\n",
      "Month=58, Predicted=9.117074, Expected=9.145000\n",
      "Month=59, Predicted=8.496469, Expected=8.498000\n",
      "Month=60, Predicted=9.396759, Expected=9.362000\n",
      "Month=61, Predicted=8.995608, Expected=9.000000\n",
      "Month=62, Predicted=9.300848, Expected=9.455000\n",
      "Month=63, Predicted=9.311296, Expected=9.300000\n",
      "Month=64, Predicted=9.010842, Expected=8.990000\n",
      "Month=65, Predicted=8.982708, Expected=8.990000\n",
      "Month=66, Predicted=8.812264, Expected=8.790000\n",
      "Month=67, Predicted=8.858553, Expected=8.835000\n",
      "Month=68, Predicted=8.692091, Expected=8.700000\n",
      "Month=69, Predicted=8.962190, Expected=8.935000\n",
      "Month=70, Predicted=8.876411, Expected=8.835000\n",
      "Month=71, Predicted=8.299595, Expected=8.265000\n",
      "Month=72, Predicted=8.751412, Expected=8.835000\n",
      "Month=73, Predicted=8.547227, Expected=8.550000\n",
      "Month=74, Predicted=8.685820, Expected=8.680000\n",
      "Month=75, Predicted=8.441601, Expected=8.400000\n",
      "Month=76, Predicted=8.575379, Expected=8.525000\n",
      "Month=77, Predicted=8.377754, Expected=8.370000\n",
      "Month=78, Predicted=7.889911, Expected=7.890000\n",
      "Month=79, Predicted=7.822669, Expected=7.812000\n",
      "Month=80, Predicted=7.596116, Expected=7.620000\n",
      "Month=81, Predicted=7.698645, Expected=7.718000\n",
      "Month=82, Predicted=8.373646, Expected=8.323500\n",
      "Month=83, Predicted=6.806787, Expected=6.860000\n",
      "Month=84, Predicted=8.305682, Expected=8.308000\n",
      "Month=85, Predicted=8.040925, Expected=8.100000\n",
      "Month=86, Predicted=8.558423, Expected=8.525000\n",
      "Month=87, Predicted=8.297483, Expected=8.250000\n",
      "Month=88, Predicted=8.274297, Expected=8.215000\n",
      "Month=89, Predicted=8.099988, Expected=8.122600\n",
      "Month=90, Predicted=7.765091, Expected=7.778100\n",
      "Month=91, Predicted=7.993855, Expected=7.954600\n",
      "Month=92, Predicted=7.378378, Expected=7.420000\n",
      "Month=93, Predicted=7.487402, Expected=7.538300\n",
      "Month=94, Predicted=7.910467, Expected=7.905000\n",
      "Month=95, Predicted=7.161566, Expected=7.140000\n",
      "Month=96, Predicted=8.419737, Expected=8.432000\n",
      "Month=97, Predicted=7.775807, Expected=7.710000\n",
      "Month=98, Predicted=7.969290, Expected=7.967000\n",
      "Month=99, Predicted=7.352495, Expected=7.320000\n",
      "Month=100, Predicted=7.586847, Expected=7.502000\n",
      "Month=101, Predicted=7.357455, Expected=7.409000\n",
      "Month=102, Predicted=7.276507, Expected=7.200600\n",
      "Month=103, Predicted=7.977454, Expected=7.865000\n",
      "Month=104, Predicted=6.779627, Expected=6.690000\n",
      "Month=105, Predicted=6.819557, Expected=6.879400\n",
      "Month=106, Predicted=7.444903, Expected=7.440000\n",
      "Month=107, Predicted=6.875842, Expected=6.860000\n",
      "Month=108, Predicted=7.620659, Expected=7.595000\n",
      "Month=109, Predicted=7.281360, Expected=7.200000\n",
      "Month=110, Predicted=7.166305, Expected=7.130000\n",
      "Month=111, Predicted=6.956457, Expected=6.900000\n",
      "Month=112, Predicted=7.236436, Expected=7.130000\n",
      "Month=113, Predicted=7.114907, Expected=7.130000\n",
      "Month=114, Predicted=6.802736, Expected=6.840000\n",
      "Month=115, Predicted=6.991671, Expected=7.006000\n",
      "Month=116, Predicted=6.791629, Expected=6.780000\n",
      "Month=117, Predicted=7.062376, Expected=7.089600\n",
      "Month=118, Predicted=6.894501, Expected=6.882000\n",
      "Month=119, Predicted=6.399311, Expected=6.446700\n",
      "Month=120, Predicted=6.947255, Expected=6.882000\n",
      "Month=121, Predicted=6.618368, Expected=6.600000\n",
      "Month=122, Predicted=6.829841, Expected=6.820000\n",
      "Month=123, Predicted=6.655933, Expected=6.600000\n",
      "Month=124, Predicted=6.848638, Expected=6.820000\n",
      "Month=125, Predicted=6.701131, Expected=6.665000\n",
      "Month=126, Predicted=6.381242, Expected=6.450000\n",
      "Month=127, Predicted=6.663745, Expected=6.665000\n",
      "Month=128, Predicted=6.489200, Expected=6.450000\n",
      "Month=129, Predicted=6.748428, Expected=6.722100\n",
      "Month=130, Predicted=6.862990, Expected=6.820000\n",
      "Month=131, Predicted=6.207922, Expected=6.160000\n",
      "Month=132, Predicted=6.762463, Expected=6.820000\n",
      "Month=133, Predicted=6.538383, Expected=6.480000\n",
      "Month=134, Predicted=6.604490, Expected=6.596900\n",
      "Month=135, Predicted=6.541969, Expected=6.492000\n",
      "Month=136, Predicted=6.664786, Expected=6.510000\n",
      "Month=137, Predicted=6.399888, Expected=6.339500\n",
      "Month=138, Predicted=6.017418, Expected=6.001600\n",
      "Month=139, Predicted=6.082986, Expected=6.107000\n",
      "Month=140, Predicted=5.770696, Expected=5.790000\n",
      "Month=141, Predicted=5.868869, Expected=5.885000\n",
      "Month=142, Predicted=7.350967, Expected=7.280000\n",
      "Month=143, Predicted=6.023460, Expected=5.941600\n",
      "Month=144, Predicted=6.829758, Expected=6.810000\n",
      "Month=145, Predicted=6.250624, Expected=6.182000\n",
      "Month=146, Predicted=6.381031, Expected=6.293000\n",
      "Month=147, Predicted=6.175077, Expected=6.118600\n",
      "Month=148, Predicted=6.391339, Expected=6.138000\n",
      "Month=149, Predicted=6.158277, Expected=6.107000\n",
      "Month=150, Predicted=6.052463, Expected=5.913000\n",
      "Month=151, Predicted=6.135051, Expected=6.141100\n",
      "Month=152, Predicted=6.310145, Expected=6.248000\n",
      "Month=153, Predicted=5.846457, Expected=5.829700\n",
      "Month=154, Predicted=6.779761, Expected=6.829300\n",
      "Month=155, Predicted=6.739694, Expected=6.694400\n",
      "Month=156, Predicted=7.791320, Expected=7.726200\n",
      "Month=157, Predicted=7.109448, Expected=7.054400\n",
      "Month=158, Predicted=7.348508, Expected=7.268900\n",
      "Month=159, Predicted=7.046298, Expected=7.020000\n",
      "Month=160, Predicted=6.565289, Expected=6.510000\n",
      "Month=161, Predicted=6.364545, Expected=6.370500\n",
      "Month=162, Predicted=5.782461, Expected=5.730000\n",
      "Month=163, Predicted=5.827361, Expected=5.828000\n",
      "Month=164, Predicted=5.652772, Expected=5.580000\n",
      "Month=165, Predicted=5.746178, Expected=5.709900\n",
      "Month=166, Predicted=6.887721, Expected=6.696000\n",
      "Month=167, Predicted=6.320726, Expected=6.248000\n",
      "Month=168, Predicted=6.720691, Expected=6.711600\n",
      "Month=169, Predicted=6.621090, Expected=6.600100\n",
      "Month=170, Predicted=7.534315, Expected=7.508200\n",
      "Month=171, Predicted=7.790570, Expected=7.765000\n",
      "Month=172, Predicted=7.327387, Expected=7.285000\n",
      "Month=173, Predicted=7.001892, Expected=6.959500\n",
      "Month=174, Predicted=6.471376, Expected=6.450000\n",
      "Month=175, Predicted=6.568312, Expected=6.572000\n",
      "Month=176, Predicted=6.606407, Expected=6.600000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=177, Predicted=4.242057, Expected=4.265300\n",
      "Month=178, Predicted=7.376387, Expected=7.367000\n",
      "Month=179, Predicted=6.528580, Expected=6.544000\n",
      "Month=180, Predicted=6.961516, Expected=6.940800\n",
      "Train RMSE: 0.05871\n",
      "Train RMSPE: 0.78999\n",
      "Train MAE: 0.04239\n",
      "Train MAPE: 0.56157\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=5.956868, Expected=6.786000\n",
      "Month=2, Predicted=7.939080, Expected=6.981200\n",
      "Month=3, Predicted=7.121496, Expected=6.756000\n",
      "Month=4, Predicted=6.541326, Expected=6.733200\n",
      "Month=5, Predicted=6.348282, Expected=6.671200\n",
      "Month=6, Predicted=6.370402, Expected=6.295600\n",
      "Month=7, Predicted=6.511046, Expected=6.432500\n",
      "Month=8, Predicted=5.954389, Expected=6.153000\n",
      "Month=9, Predicted=6.110460, Expected=6.389500\n",
      "Month=10, Predicted=6.821103, Expected=7.192000\n",
      "Month=11, Predicted=5.999278, Expected=6.524000\n",
      "Month=12, Predicted=7.322189, Expected=7.238500\n",
      "Month=13, Predicted=6.886131, Expected=6.990000\n",
      "Month=14, Predicted=7.270499, Expected=7.254000\n",
      "Month=15, Predicted=6.942311, Expected=6.720000\n",
      "Month=16, Predicted=6.600149, Expected=6.944000\n",
      "Month=17, Predicted=6.843278, Expected=7.052500\n",
      "Month=18, Predicted=6.703680, Expected=6.690000\n",
      "Month=19, Predicted=7.813301, Expected=6.909900\n",
      "Month=20, Predicted=6.436243, Expected=6.819000\n",
      "Month=21, Predicted=6.956073, Expected=7.167200\n",
      "Month=22, Predicted=7.128241, Expected=7.254000\n",
      "Month=23, Predicted=6.575451, Expected=6.664000\n",
      "Month=24, Predicted=7.150822, Expected=7.393500\n",
      "Month=25, Predicted=7.230361, Expected=7.125000\n",
      "Month=26, Predicted=7.319401, Expected=7.347000\n",
      "Month=27, Predicted=7.290232, Expected=7.216500\n",
      "Month=28, Predicted=7.149430, Expected=7.254000\n",
      "Month=29, Predicted=7.050531, Expected=7.238500\n",
      "Month=30, Predicted=6.658126, Expected=6.990000\n",
      "Month=31, Predicted=7.257586, Expected=7.192000\n",
      "Month=32, Predicted=7.260652, Expected=6.900000\n",
      "Month=33, Predicted=7.133413, Expected=7.427300\n",
      "Month=34, Predicted=7.083471, Expected=7.300500\n",
      "Month=35, Predicted=7.039776, Expected=6.902000\n",
      "Month=36, Predicted=7.764621, Expected=7.409000\n",
      "Month=37, Predicted=7.094932, Expected=7.179000\n",
      "Month=38, Predicted=7.659375, Expected=7.424500\n",
      "Month=39, Predicted=7.218822, Expected=7.275000\n",
      "Month=40, Predicted=7.430557, Expected=7.316000\n",
      "Month=41, Predicted=6.993533, Expected=7.086300\n",
      "Month=42, Predicted=6.898547, Expected=7.020000\n",
      "Month=43, Predicted=6.748290, Expected=7.270500\n",
      "Month=44, Predicted=6.912084, Expected=7.168800\n",
      "Month=45, Predicted=7.310383, Expected=7.448600\n",
      "Month=46, Predicted=7.490012, Expected=7.440200\n",
      "Test RMSE: 0.32270\n",
      "Test RMSPE: 4.65891\n",
      "Test MAE: 0.24074\n",
      "Test MAPE: 3.45759\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# oil static.py d-lstm \n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='relu', batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')   \n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=5\n",
    "\tneurons=[7,6,4,2] \n",
    "\tn_epochs=800\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ffbe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 17:17:03.541629: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-18 17:17:03.543138: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_79316/52366647.py:25: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_79316/52366647.py:247: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_79316/52366647.py:151: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 17:17:04.015302: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-18 17:17:04.089481: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-18 17:17:04.160489: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0547\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "  9/180 [>.............................] - ETA: 2s - loss: 0.0634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 17:17:07.190065: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-18 17:17:07.217912: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0491\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0483\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0476\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0470\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0463\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0456\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0449\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0443\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0436\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0429\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0422\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0416\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0409\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0403\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0397\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0391\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0385\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0379\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0374\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0369\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0365\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0360\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0356\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0352\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0349\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0346\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0343\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0341\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0338\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0336\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0334\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0333\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0331\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0330\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0328\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0327\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0326\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0325\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0324\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0323\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0322\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0321\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0320\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0319\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0319\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0318\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0317\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0317\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0316\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0315\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0315\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0314\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0314\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0313\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0313\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0312\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0312\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0311\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0311\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0310\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0310\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0309\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0309\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0309\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0308\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0308\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0307\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0307\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0307\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0306\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0306\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0306\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0305\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0305\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0305\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0305\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0304\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0304\n",
      "Epoch: 79\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0304\n",
      "Epoch: 80\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0303\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0303\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0303\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0303\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0302\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0302\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0302\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0302\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0301\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0301\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0301\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0301\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0301\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0300\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0300\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0300\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0300\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0299\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0299\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0299\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0299\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0299\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0298\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0298\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0298\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0298\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0298\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0298\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0297\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0297\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0297\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0297\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0297\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0296\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0296\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0296\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0296\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0296\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0296\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0295\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0295\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0295\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0295\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0295\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0295\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0294\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0294\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0294\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0294\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0294\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0294\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0293\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0293\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0293\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0293\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0293\n",
      "Epoch: 136\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0293\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0292\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0292\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0292\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0292\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0292\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0292\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0291\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0291\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0291\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0291\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0291\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0290\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0290\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0290\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0290\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0290\n",
      "Epoch: 153\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0290\n",
      "Epoch: 154\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0289\n",
      "Epoch: 155\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0289\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0289\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0289\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0289\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0289\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0288\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0288\n",
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0288\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0288\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0288\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0287\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0287\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0287\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0287\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0287\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0286\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0286\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0286\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0286\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0286\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0286\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0285\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0285\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0285\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0285\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0285\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0284\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0284\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0284\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0284\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0284\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0283\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0283\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0283\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0283\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0283\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0282\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0282\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0282\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0282\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0281\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0281\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0281\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0281\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0281\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0280\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0280\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0280\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0280\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0280\n",
      "Epoch: 205\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0279\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0279\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0279\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0279\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0279\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0278\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0278\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0278\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0278\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0277\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0277\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0277\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0277\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0277\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0276\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0276\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0276\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0276\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0275\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0275\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0275\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0275\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0274\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0274\n",
      "Epoch: 229\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0274\n",
      "Epoch: 230\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0274\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0273\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0273\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0273\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0272\n",
      "Epoch: 235\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0272\n",
      "Epoch: 236\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0272\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0271\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0271\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0271\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0270\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0270\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0270\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0269\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0269\n",
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0269\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0268\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0268\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0267\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0267\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0266\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0266\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0265\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0265\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0264\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0264\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0263\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0263\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0262\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0261\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0261\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0260\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0259\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0259\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0258\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0257\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0256\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0256\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0255\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0254\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0253\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0252\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0251\n",
      "Epoch: 273\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0251\n",
      "Epoch: 274\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0250\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0249\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0248\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0248\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0247\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0246\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0245\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0245\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0244\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0244\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0243\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0243\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0242\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0242\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0241\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0240\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0240\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0239\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0239\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0238\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0238\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0237\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0237\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0236\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0235\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0235\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0234\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0234\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0233\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0232\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0232\n",
      "Epoch: 305\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0231\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0231\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0230\n",
      "Epoch: 308\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0229\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0229\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0228\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0228\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0227\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0226\n",
      "Epoch: 314\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0226\n",
      "Epoch: 315\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0225\n",
      "Epoch: 316\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0225\n",
      "Epoch: 317\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0224\n",
      "Epoch: 318\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0224\n",
      "Epoch: 319\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0223\n",
      "Epoch: 320\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0223\n",
      "Epoch: 321\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0222\n",
      "Epoch: 322\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 323\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 324\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0221\n",
      "Epoch: 325\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0220\n",
      "Epoch: 326\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0220\n",
      "Epoch: 327\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0219\n",
      "Epoch: 328\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0219\n",
      "Epoch: 329\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0218\n",
      "Epoch: 330\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0218\n",
      "Epoch: 331\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0217\n",
      "Epoch: 332\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0217\n",
      "Epoch: 333\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0217\n",
      "Epoch: 334\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 335\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0216\n",
      "Epoch: 336\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0215\n",
      "Epoch: 337\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0215\n",
      "Epoch: 338\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0215\n",
      "Epoch: 339\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0214\n",
      "Epoch: 340\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0214\n",
      "Epoch: 341\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0213\n",
      "Epoch: 342\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0213\n",
      "Epoch: 343\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0213\n",
      "Epoch: 344\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0212\n",
      "Epoch: 345\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0212\n",
      "Epoch: 346\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0212\n",
      "Epoch: 347\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0211\n",
      "Epoch: 348\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0211\n",
      "Epoch: 349\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0211\n",
      "Epoch: 350\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0210\n",
      "Epoch: 351\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0210\n",
      "Epoch: 352\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0210\n",
      "Epoch: 353\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0209\n",
      "Epoch: 354\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0209\n",
      "Epoch: 355\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0209\n",
      "Epoch: 356\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0208\n",
      "Epoch: 357\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0208\n",
      "Epoch: 358\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0208\n",
      "Epoch: 359\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0208\n",
      "Epoch: 360\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0207\n",
      "Epoch: 361\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0207\n",
      "Epoch: 362\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0207\n",
      "Epoch: 363\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0206\n",
      "Epoch: 364\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0206\n",
      "Epoch: 365\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0206\n",
      "Epoch: 366\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0206\n",
      "Epoch: 367\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0205\n",
      "Epoch: 368\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0205\n",
      "Epoch: 369\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0205\n",
      "Epoch: 370\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0204\n",
      "Epoch: 371\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0204\n",
      "Epoch: 372\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0204\n",
      "Epoch: 373\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0204\n",
      "Epoch: 374\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0203\n",
      "Epoch: 375\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0203\n",
      "Epoch: 376\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0203\n",
      "Epoch: 377\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0203\n",
      "Epoch: 378\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 379\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0202\n",
      "Epoch: 380\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 381\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0202\n",
      "Epoch: 382\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0202\n",
      "Epoch: 383\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0201\n",
      "Epoch: 384\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0201\n",
      "Epoch: 385\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0201\n",
      "Epoch: 386\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0201\n",
      "Epoch: 387\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 388\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 389\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0200\n",
      "Epoch: 390\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 391\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0200\n",
      "Epoch: 392\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0199\n",
      "Epoch: 393\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0199\n",
      "Epoch: 394\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0199\n",
      "Epoch: 395\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0199\n",
      "Epoch: 396\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0199\n",
      "Epoch: 397\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0199\n",
      "Epoch: 398\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0198\n",
      "Epoch: 399\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0198\n",
      "Epoch: 400\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0198\n",
      "Epoch: 401\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0198\n",
      "Epoch: 402\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0198\n",
      "Epoch: 403\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0198\n",
      "Epoch: 404\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0197\n",
      "Epoch: 405\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0197\n",
      "Epoch: 406\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0197\n",
      "Epoch: 407\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0197\n",
      "Epoch: 408\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0197\n",
      "Epoch: 409\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0197\n",
      "Epoch: 410\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0196\n",
      "Epoch: 411\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0196\n",
      "Epoch: 412\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0196\n",
      "Epoch: 413\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0196\n",
      "Epoch: 414\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0196\n",
      "Epoch: 415\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0196\n",
      "Epoch: 416\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0195\n",
      "Epoch: 417\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0195\n",
      "Epoch: 418\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0195\n",
      "Epoch: 419\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0195\n",
      "Epoch: 420\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0195\n",
      "Epoch: 421\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0195\n",
      "Epoch: 422\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0195\n",
      "Epoch: 423\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0194\n",
      "Epoch: 424\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0194\n",
      "Epoch: 425\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0194\n",
      "Epoch: 426\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0194\n",
      "Epoch: 427\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0194\n",
      "Epoch: 428\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0194\n",
      "Epoch: 429\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0194\n",
      "Epoch: 430\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0194\n",
      "Epoch: 431\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0193\n",
      "Epoch: 432\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0193\n",
      "Epoch: 433\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0193\n",
      "Epoch: 434\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0193\n",
      "Epoch: 435\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0193\n",
      "Epoch: 436\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0193\n",
      "Epoch: 437\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0193\n",
      "Epoch: 438\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0193\n",
      "Epoch: 439\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0192\n",
      "Epoch: 440\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0192\n",
      "Epoch: 441\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0192\n",
      "Epoch: 442\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0192\n",
      "Epoch: 443\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0192\n",
      "Epoch: 444\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0192\n",
      "Epoch: 445\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0192\n",
      "Epoch: 446\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0192\n",
      "Epoch: 447\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 448\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 449\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 450\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 451\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 452\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 453\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 454\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0191\n",
      "Epoch: 455\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0190\n",
      "Epoch: 456\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0190\n",
      "Epoch: 457\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0190\n",
      "Epoch: 458\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0190\n",
      "Epoch: 459\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0190\n",
      "Epoch: 460\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0190\n",
      "Epoch: 461\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0190\n",
      "Epoch: 462\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0190\n",
      "Epoch: 463\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0190\n",
      "Epoch: 464\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0189\n",
      "Epoch: 465\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0189\n",
      "Epoch: 466\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0189\n",
      "Epoch: 467\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0189\n",
      "Epoch: 468\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0189\n",
      "Epoch: 469\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0189\n",
      "Epoch: 470\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0189\n",
      "Epoch: 471\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0189\n",
      "Epoch: 472\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0189\n",
      "Epoch: 473\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0188\n",
      "Epoch: 474\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0188\n",
      "Epoch: 475\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0188\n",
      "Epoch: 476\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0188\n",
      "Epoch: 477\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0188\n",
      "Epoch: 478\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0188\n",
      "Epoch: 479\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0188\n",
      "Epoch: 480\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0188\n",
      "Epoch: 481\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0187\n",
      "Epoch: 482\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0187\n",
      "Epoch: 483\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0187\n",
      "Epoch: 484\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0187\n",
      "Epoch: 485\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0187\n",
      "Epoch: 486\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0187\n",
      "Epoch: 487\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0187\n",
      "Epoch: 488\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0187\n",
      "Epoch: 489\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0186\n",
      "Epoch: 490\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0186\n",
      "Epoch: 491\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0186\n",
      "Epoch: 492\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0186\n",
      "Epoch: 493\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0186\n",
      "Epoch: 494\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0186\n",
      "Epoch: 495\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0186\n",
      "Epoch: 496\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0185\n",
      "Epoch: 497\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0185\n",
      "Epoch: 498\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0185\n",
      "Epoch: 499\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0185\n",
      "Epoch: 500\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0185\n",
      "Epoch: 501\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0185\n",
      "Epoch: 502\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0185\n",
      "Epoch: 503\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0184\n",
      "Epoch: 504\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0184\n",
      "Epoch: 505\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0184\n",
      "Epoch: 506\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0184\n",
      "Epoch: 507\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0184\n",
      "Epoch: 508\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0184\n",
      "Epoch: 509\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0183\n",
      "Epoch: 510\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0183\n",
      "Epoch: 511\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0183\n",
      "Epoch: 512\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0183\n",
      "Epoch: 513\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0184\n",
      "Epoch: 514\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0183\n",
      "Epoch: 515\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0183\n",
      "Epoch: 516\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0182\n",
      "Epoch: 517\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0190\n",
      "Epoch: 518\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0182\n",
      "Epoch: 519\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0181\n",
      "Epoch: 520\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0180\n",
      "Epoch: 521\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0180\n",
      "Epoch: 522\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0179\n",
      "Epoch: 523\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0179\n",
      "Epoch: 524\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0178\n",
      "Epoch: 525\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0178\n",
      "Epoch: 526\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0177\n",
      "Epoch: 527\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0177\n",
      "Epoch: 528\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0177\n",
      "Epoch: 529\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0177\n",
      "Epoch: 530\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0177\n",
      "Epoch: 531\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0176\n",
      "Epoch: 532\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0176\n",
      "Epoch: 533\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0176\n",
      "Epoch: 534\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0176\n",
      "Epoch: 535\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0176\n",
      "Epoch: 536\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0175\n",
      "Epoch: 537\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0175\n",
      "Epoch: 538\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0175\n",
      "Epoch: 539\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0175\n",
      "Epoch: 540\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0175\n",
      "Epoch: 541\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0175\n",
      "Epoch: 542\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0174\n",
      "Epoch: 543\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0174\n",
      "Epoch: 544\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0174\n",
      "Epoch: 545\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0174\n",
      "Epoch: 546\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0174\n",
      "Epoch: 547\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0174\n",
      "Epoch: 548\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0174\n",
      "Epoch: 549\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0175\n",
      "Epoch: 550\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0173\n",
      "Epoch: 551\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0174\n",
      "Epoch: 552\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0173\n",
      "Epoch: 553\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0173\n",
      "Epoch: 554\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0193\n",
      "Epoch: 555\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0175\n",
      "Epoch: 556\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0171\n",
      "Epoch: 557\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0171\n",
      "Epoch: 558\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0171\n",
      "Epoch: 559\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0171\n",
      "Epoch: 560\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0171\n",
      "Epoch: 561\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0171\n",
      "Epoch: 562\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0171\n",
      "Epoch: 563\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0171\n",
      "Epoch: 564\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0170\n",
      "Epoch: 565\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0170\n",
      "Epoch: 566\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0170\n",
      "Epoch: 567\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0170\n",
      "Epoch: 568\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0170\n",
      "Epoch: 569\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0169\n",
      "Epoch: 570\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0169\n",
      "Epoch: 571\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0169\n",
      "Epoch: 572\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0169\n",
      "Epoch: 573\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0169\n",
      "Epoch: 574\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0168\n",
      "Epoch: 575\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0168\n",
      "Epoch: 576\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0168\n",
      "Epoch: 577\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0168\n",
      "Epoch: 578\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0168\n",
      "Epoch: 579\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0168\n",
      "Epoch: 580\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0168\n",
      "Epoch: 581\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0171\n",
      "Epoch: 582\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0167\n",
      "Epoch: 583\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0167\n",
      "Epoch: 584\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0211\n",
      "Epoch: 585\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0172\n",
      "Epoch: 586\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0171\n",
      "Epoch: 587\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0170\n",
      "Epoch: 588\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0170\n",
      "Epoch: 589\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0168\n",
      "Epoch: 590\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0166\n",
      "Epoch: 591\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0166\n",
      "Epoch: 592\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0166\n",
      "Epoch: 593\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0166\n",
      "Epoch: 594\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0165\n",
      "Epoch: 595\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0165\n",
      "Epoch: 596\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0165\n",
      "Epoch: 597\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0165\n",
      "Epoch: 598\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0165\n",
      "Epoch: 599\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0165\n",
      "Epoch: 600\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0179\n",
      "Epoch: 601\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0169\n",
      "Epoch: 602\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0169\n",
      "Epoch: 603\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0168\n",
      "Epoch: 604\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0168\n",
      "Epoch: 605\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0168\n",
      "Epoch: 606\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0167\n",
      "Epoch: 607\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0165\n",
      "Epoch: 608\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0184\n",
      "Epoch: 609\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0168\n",
      "Epoch: 610\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0167\n",
      "Epoch: 611\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0167\n",
      "Epoch: 612\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0167\n",
      "Epoch: 613\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0166\n",
      "Epoch: 614\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0164\n",
      "Epoch: 615\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0166\n",
      "Epoch: 616\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0164\n",
      "Epoch: 617\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0164\n",
      "Epoch: 618\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0163\n",
      "Epoch: 619\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0164\n",
      "Epoch: 620\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0163\n",
      "Epoch: 621\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0164\n",
      "Epoch: 622\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0163\n",
      "Epoch: 623\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0164\n",
      "Epoch: 624\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0163\n",
      "Epoch: 625\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0164\n",
      "Epoch: 626\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0162\n",
      "Epoch: 627\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0164\n",
      "Epoch: 628\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0162\n",
      "Epoch: 629\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0164\n",
      "Epoch: 630\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0162\n",
      "Epoch: 631\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0164\n",
      "Epoch: 632\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0161\n",
      "Epoch: 633\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0164\n",
      "Epoch: 634\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0161\n",
      "Epoch: 635\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0164\n",
      "Epoch: 636\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0161\n",
      "Epoch: 637\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0164\n",
      "Epoch: 638\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0160\n",
      "Epoch: 639\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0163\n",
      "Epoch: 640\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0160\n",
      "Epoch: 641\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0165\n",
      "Epoch: 642\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0160\n",
      "Epoch: 643\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0162\n",
      "Epoch: 644\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0160\n",
      "Epoch: 645\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0166\n",
      "Epoch: 646\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0160\n",
      "Epoch: 647\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0160\n",
      "Epoch: 648\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0160\n",
      "Epoch: 649\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0159\n",
      "Epoch: 650\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0166\n",
      "Epoch: 651\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0160\n",
      "Epoch: 652\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0160\n",
      "Epoch: 653\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0159\n",
      "Epoch: 654\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0162\n",
      "Epoch: 655\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0160\n",
      "Epoch: 656\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0168\n",
      "Epoch: 657\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0167\n",
      "Epoch: 658\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0169\n",
      "Epoch: 659\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0171\n",
      "Epoch: 660\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0172\n",
      "Epoch: 661\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0174\n",
      "Epoch: 662\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0172\n",
      "Epoch: 663\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0173\n",
      "Epoch: 664\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0175\n",
      "Epoch: 665\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0188\n",
      "Epoch: 666\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 70s 390ms/sample - loss: 0.0186\n",
      "Epoch: 667\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0184\n",
      "Epoch: 668\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0182\n",
      "Epoch: 669\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0181\n",
      "Epoch: 670\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0180\n",
      "Epoch: 671\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0179\n",
      "Epoch: 672\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0178\n",
      "Epoch: 673\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0177\n",
      "Epoch: 674\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0175\n",
      "Epoch: 675\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0175\n",
      "Epoch: 676\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0174\n",
      "Epoch: 677\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0173\n",
      "Epoch: 678\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0172\n",
      "Epoch: 679\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0172\n",
      "Epoch: 680\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0171\n",
      "Epoch: 681\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0171\n",
      "Epoch: 682\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0170\n",
      "Epoch: 683\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0169\n",
      "Epoch: 684\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0169\n",
      "Epoch: 685\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0168\n",
      "Epoch: 686\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0168\n",
      "Epoch: 687\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0167\n",
      "Epoch: 688\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0167\n",
      "Epoch: 689\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0167\n",
      "Epoch: 690\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0166\n",
      "Epoch: 691\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0166\n",
      "Epoch: 692\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0166\n",
      "Epoch: 693\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0165\n",
      "Epoch: 694\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0165\n",
      "Epoch: 695\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0165\n",
      "Epoch: 696\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0164\n",
      "Epoch: 697\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0164\n",
      "Epoch: 698\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0164\n",
      "Epoch: 699\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0163\n",
      "Epoch: 700\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0163\n",
      "Epoch: 701\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0163\n",
      "Epoch: 702\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0162\n",
      "Epoch: 703\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0162\n",
      "Epoch: 704\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0162\n",
      "Epoch: 705\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0162\n",
      "Epoch: 706\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0161\n",
      "Epoch: 707\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0161\n",
      "Epoch: 708\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0161\n",
      "Epoch: 709\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0161\n",
      "Epoch: 710\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0161\n",
      "Epoch: 711\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0160\n",
      "Epoch: 712\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0160\n",
      "Epoch: 713\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0160\n",
      "Epoch: 714\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0160\n",
      "Epoch: 715\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0159\n",
      "Epoch: 716\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0162\n",
      "Epoch: 717\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0157\n",
      "Epoch: 718\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0157\n",
      "Epoch: 719\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0157\n",
      "Epoch: 720\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0158\n",
      "Epoch: 721\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0164\n",
      "Epoch: 722\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0159\n",
      "Epoch: 723\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 19ms/sample - loss: 0.0166\n",
      "Epoch: 724\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0159\n",
      "Epoch: 725\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0159\n",
      "Epoch: 726\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0167\n",
      "Epoch: 727\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 24ms/sample - loss: 0.0159\n",
      "Epoch: 728\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 26ms/sample - loss: 0.0161\n",
      "Epoch: 729\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 25ms/sample - loss: 0.0166\n",
      "Epoch: 730\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 25ms/sample - loss: 0.0164\n",
      "Epoch: 731\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 24ms/sample - loss: 0.0164\n",
      "Epoch: 732\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 5s 28ms/sample - loss: 0.0164\n",
      "Epoch: 733\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 24ms/sample - loss: 0.0164\n",
      "Epoch: 734\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0163\n",
      "Epoch: 735\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 23ms/sample - loss: 0.0162\n",
      "Epoch: 736\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0161\n",
      "Epoch: 737\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 21ms/sample - loss: 0.0160\n",
      "Epoch: 738\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0162\n",
      "Epoch: 739\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0163\n",
      "Epoch: 740\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 20ms/sample - loss: 0.0162\n",
      "Epoch: 741\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0160\n",
      "Epoch: 742\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0158\n",
      "Epoch: 743\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0158\n",
      "Epoch: 744\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0161\n",
      "Epoch: 745\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0163\n",
      "Epoch: 746\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0162\n",
      "Epoch: 747\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0161\n",
      "Epoch: 748\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0160\n",
      "Epoch: 749\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0159\n",
      "Epoch: 750\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0160\n",
      "Epoch: 751\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0161\n",
      "Epoch: 752\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0161\n",
      "Epoch: 753\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0161\n",
      "Epoch: 754\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0160\n",
      "Epoch: 755\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0159\n",
      "Epoch: 756\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0158\n",
      "Epoch: 757\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0158\n",
      "Epoch: 758\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0160\n",
      "Epoch: 759\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0161\n",
      "Epoch: 760\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0160\n",
      "Epoch: 761\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0164\n",
      "Epoch: 762\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0175\n",
      "Epoch: 763\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0160\n",
      "Epoch: 764\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0158\n",
      "Epoch: 765\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0157\n",
      "Epoch: 766\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0156\n",
      "Epoch: 767\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0155\n",
      "Epoch: 768\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0155\n",
      "Epoch: 769\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0155\n",
      "Epoch: 770\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0155\n",
      "Epoch: 771\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0156\n",
      "Epoch: 772\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0156\n",
      "Epoch: 773\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0156\n",
      "Epoch: 774\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0156\n",
      "Epoch: 775\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0156\n",
      "Epoch: 776\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0156\n",
      "Epoch: 777\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0158\n",
      "Epoch: 778\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0158\n",
      "Epoch: 779\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0158\n",
      "Epoch: 780\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0156\n",
      "Epoch: 781\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0160\n",
      "Epoch: 782\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0156\n",
      "Epoch: 783\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0162\n",
      "Epoch: 784\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0163\n",
      "Epoch: 785\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0164\n",
      "Epoch: 786\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0166\n",
      "Epoch: 787\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0167\n",
      "Epoch: 788\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0168\n",
      "Epoch: 789\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0168\n",
      "Epoch: 790\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0169\n",
      "Epoch: 791\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0168\n",
      "Epoch: 792\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0169\n",
      "Epoch: 793\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0168\n",
      "Epoch: 794\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0168\n",
      "Epoch: 795\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0167\n",
      "Epoch: 796\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0166\n",
      "Epoch: 797\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0166\n",
      "Epoch: 798\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0165\n",
      "Epoch: 799\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0165\n",
      "Forecasting Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-04-18 17:53:20.389110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=1, Predicted=11.288139, Expected=9.510000\n",
      "Month=2, Predicted=11.013027, Expected=9.796000\n",
      "Month=3, Predicted=11.421617, Expected=9.468500\n",
      "Month=4, Predicted=11.443331, Expected=9.672000\n",
      "Month=5, Predicted=10.189705, Expected=9.610000\n",
      "Month=6, Predicted=11.054571, Expected=9.240000\n",
      "Month=7, Predicted=10.125894, Expected=10.318300\n",
      "Month=8, Predicted=10.648629, Expected=8.974800\n",
      "Month=9, Predicted=8.926896, Expected=9.114000\n",
      "Month=10, Predicted=9.484587, Expected=9.300000\n",
      "Month=11, Predicted=9.184483, Expected=8.400000\n",
      "Month=12, Predicted=8.790840, Expected=9.300000\n",
      "Month=13, Predicted=9.229171, Expected=9.000000\n",
      "Month=14, Predicted=9.189502, Expected=9.300000\n",
      "Month=15, Predicted=9.334831, Expected=9.460000\n",
      "Month=16, Predicted=9.174029, Expected=9.145000\n",
      "Month=17, Predicted=9.232822, Expected=9.021000\n",
      "Month=18, Predicted=9.301113, Expected=8.750000\n",
      "Month=19, Predicted=9.054397, Expected=8.710000\n",
      "Month=20, Predicted=9.118358, Expected=8.370000\n",
      "Month=21, Predicted=9.263298, Expected=8.504000\n",
      "Month=22, Predicted=10.666479, Expected=9.819700\n",
      "Month=23, Predicted=10.269361, Expected=9.827300\n",
      "Month=24, Predicted=10.366110, Expected=9.929800\n",
      "Month=25, Predicted=10.100671, Expected=9.288000\n",
      "Month=26, Predicted=9.300065, Expected=9.300000\n",
      "Month=27, Predicted=9.624172, Expected=9.060000\n",
      "Month=28, Predicted=9.337992, Expected=8.835000\n",
      "Month=29, Predicted=9.441849, Expected=8.388600\n",
      "Month=30, Predicted=9.959535, Expected=8.400000\n",
      "Month=31, Predicted=10.799984, Expected=8.525000\n",
      "Month=32, Predicted=10.272302, Expected=8.250000\n",
      "Month=33, Predicted=10.442352, Expected=8.419000\n",
      "Month=34, Predicted=10.071355, Expected=9.455000\n",
      "Month=35, Predicted=9.682470, Expected=8.540000\n",
      "Month=36, Predicted=9.020615, Expected=9.455000\n",
      "Month=37, Predicted=9.493811, Expected=9.000000\n",
      "Month=38, Predicted=9.036159, Expected=9.599000\n",
      "Month=39, Predicted=9.318886, Expected=9.436000\n",
      "Month=40, Predicted=9.302455, Expected=9.539800\n",
      "Month=41, Predicted=9.498604, Expected=9.028600\n",
      "Month=42, Predicted=9.202979, Expected=8.932000\n",
      "Month=43, Predicted=9.316816, Expected=8.993000\n",
      "Month=44, Predicted=9.314091, Expected=8.678400\n",
      "Month=45, Predicted=9.185240, Expected=9.011100\n",
      "Month=46, Predicted=10.364349, Expected=9.630000\n",
      "Month=47, Predicted=9.947855, Expected=8.590400\n",
      "Month=48, Predicted=9.237003, Expected=9.736300\n",
      "Month=49, Predicted=9.516118, Expected=9.384500\n",
      "Month=50, Predicted=9.599168, Expected=9.947200\n",
      "Month=51, Predicted=9.719501, Expected=9.577100\n",
      "Month=52, Predicted=9.449263, Expected=9.117200\n",
      "Month=53, Predicted=9.297932, Expected=9.122500\n",
      "Month=54, Predicted=9.524765, Expected=8.880000\n",
      "Month=55, Predicted=9.119453, Expected=8.709200\n",
      "Month=56, Predicted=9.934909, Expected=8.428200\n",
      "Month=57, Predicted=11.076785, Expected=9.907600\n",
      "Month=58, Predicted=10.593494, Expected=9.145000\n",
      "Month=59, Predicted=9.330103, Expected=8.498000\n",
      "Month=60, Predicted=10.089142, Expected=9.362000\n",
      "Month=61, Predicted=9.440027, Expected=9.000000\n",
      "Month=62, Predicted=9.089758, Expected=9.455000\n",
      "Month=63, Predicted=10.383152, Expected=9.300000\n",
      "Month=64, Predicted=9.428400, Expected=8.990000\n",
      "Month=65, Predicted=9.221562, Expected=8.990000\n",
      "Month=66, Predicted=9.389534, Expected=8.790000\n",
      "Month=67, Predicted=9.066670, Expected=8.835000\n",
      "Month=68, Predicted=9.731730, Expected=8.700000\n",
      "Month=69, Predicted=10.134437, Expected=8.935000\n",
      "Month=70, Predicted=10.280676, Expected=8.835000\n",
      "Month=71, Predicted=10.233086, Expected=8.265000\n",
      "Month=72, Predicted=10.364155, Expected=8.835000\n",
      "Month=73, Predicted=9.807621, Expected=8.550000\n",
      "Month=74, Predicted=9.976924, Expected=8.680000\n",
      "Month=75, Predicted=9.967275, Expected=8.400000\n",
      "Month=76, Predicted=9.480056, Expected=8.525000\n",
      "Month=77, Predicted=9.181467, Expected=8.370000\n",
      "Month=78, Predicted=9.059315, Expected=7.890000\n",
      "Month=79, Predicted=8.894605, Expected=7.812000\n",
      "Month=80, Predicted=9.886794, Expected=7.620000\n",
      "Month=81, Predicted=9.612386, Expected=7.718000\n",
      "Month=82, Predicted=9.151836, Expected=8.323500\n",
      "Month=83, Predicted=8.894045, Expected=6.860000\n",
      "Month=84, Predicted=8.573534, Expected=8.308000\n",
      "Month=85, Predicted=8.537627, Expected=8.100000\n",
      "Month=86, Predicted=8.490409, Expected=8.525000\n",
      "Month=87, Predicted=8.436561, Expected=8.250000\n",
      "Month=88, Predicted=8.115644, Expected=8.215000\n",
      "Month=89, Predicted=8.218249, Expected=8.122600\n",
      "Month=90, Predicted=8.092488, Expected=7.778100\n",
      "Month=91, Predicted=8.046333, Expected=7.954600\n",
      "Month=92, Predicted=8.593241, Expected=7.420000\n",
      "Month=93, Predicted=8.034281, Expected=7.538300\n",
      "Month=94, Predicted=9.203307, Expected=7.905000\n",
      "Month=95, Predicted=8.630861, Expected=7.140000\n",
      "Month=96, Predicted=8.193084, Expected=8.432000\n",
      "Month=97, Predicted=9.106735, Expected=7.710000\n",
      "Month=98, Predicted=7.791432, Expected=7.967000\n",
      "Month=99, Predicted=8.008151, Expected=7.320000\n",
      "Month=100, Predicted=7.548439, Expected=7.502000\n",
      "Month=101, Predicted=7.632323, Expected=7.409000\n",
      "Month=102, Predicted=7.661057, Expected=7.200600\n",
      "Month=103, Predicted=7.553951, Expected=7.865000\n",
      "Month=104, Predicted=7.996011, Expected=6.690000\n",
      "Month=105, Predicted=6.771669, Expected=6.879400\n",
      "Month=106, Predicted=7.022260, Expected=7.440000\n",
      "Month=107, Predicted=6.832688, Expected=6.860000\n",
      "Month=108, Predicted=7.329234, Expected=7.595000\n",
      "Month=109, Predicted=7.355756, Expected=7.200000\n",
      "Month=110, Predicted=7.186036, Expected=7.130000\n",
      "Month=111, Predicted=7.217055, Expected=6.900000\n",
      "Month=112, Predicted=7.197198, Expected=7.130000\n",
      "Month=113, Predicted=7.233450, Expected=7.130000\n",
      "Month=114, Predicted=7.384758, Expected=6.840000\n",
      "Month=115, Predicted=7.289872, Expected=7.006000\n",
      "Month=116, Predicted=7.298698, Expected=6.780000\n",
      "Month=117, Predicted=7.002502, Expected=7.089600\n",
      "Month=118, Predicted=7.261433, Expected=6.882000\n",
      "Month=119, Predicted=7.044668, Expected=6.446700\n",
      "Month=120, Predicted=6.774692, Expected=6.882000\n",
      "Month=121, Predicted=6.826657, Expected=6.600000\n",
      "Month=122, Predicted=6.733299, Expected=6.820000\n",
      "Month=123, Predicted=7.300375, Expected=6.600000\n",
      "Month=124, Predicted=6.843704, Expected=6.820000\n",
      "Month=125, Predicted=6.961746, Expected=6.665000\n",
      "Month=126, Predicted=6.785994, Expected=6.450000\n",
      "Month=127, Predicted=6.701611, Expected=6.665000\n",
      "Month=128, Predicted=6.731989, Expected=6.450000\n",
      "Month=129, Predicted=6.639196, Expected=6.722100\n",
      "Month=130, Predicted=6.908817, Expected=6.820000\n",
      "Month=131, Predicted=6.808557, Expected=6.160000\n",
      "Month=132, Predicted=6.441344, Expected=6.820000\n",
      "Month=133, Predicted=6.491839, Expected=6.480000\n",
      "Month=134, Predicted=6.568486, Expected=6.596900\n",
      "Month=135, Predicted=6.700588, Expected=6.492000\n",
      "Month=136, Predicted=6.555529, Expected=6.510000\n",
      "Month=137, Predicted=6.620339, Expected=6.339500\n",
      "Month=138, Predicted=6.579557, Expected=6.001600\n",
      "Month=139, Predicted=6.390551, Expected=6.107000\n",
      "Month=140, Predicted=6.483610, Expected=5.790000\n",
      "Month=141, Predicted=6.191289, Expected=5.885000\n",
      "Month=142, Predicted=7.347513, Expected=7.280000\n",
      "Month=143, Predicted=7.431703, Expected=5.941600\n",
      "Month=144, Predicted=6.431206, Expected=6.810000\n",
      "Month=145, Predicted=6.567512, Expected=6.182000\n",
      "Month=146, Predicted=6.176319, Expected=6.293000\n",
      "Month=147, Predicted=6.213693, Expected=6.118600\n",
      "Month=148, Predicted=6.236049, Expected=6.138000\n",
      "Month=149, Predicted=6.233298, Expected=6.107000\n",
      "Month=150, Predicted=6.323985, Expected=5.913000\n",
      "Month=151, Predicted=6.249833, Expected=6.141100\n",
      "Month=152, Predicted=6.360575, Expected=6.248000\n",
      "Month=153, Predicted=6.395611, Expected=5.829700\n",
      "Month=154, Predicted=6.113016, Expected=6.829300\n",
      "Month=155, Predicted=6.386458, Expected=6.694400\n",
      "Month=156, Predicted=6.908319, Expected=7.726200\n",
      "Month=157, Predicted=7.474195, Expected=7.054400\n",
      "Month=158, Predicted=6.821247, Expected=7.268900\n",
      "Month=159, Predicted=7.078129, Expected=7.020000\n",
      "Month=160, Predicted=6.900083, Expected=6.510000\n",
      "Month=161, Predicted=6.758103, Expected=6.370500\n",
      "Month=162, Predicted=7.271695, Expected=5.730000\n",
      "Month=163, Predicted=6.663605, Expected=5.828000\n",
      "Month=164, Predicted=7.794701, Expected=5.580000\n",
      "Month=165, Predicted=7.614686, Expected=5.709900\n",
      "Month=166, Predicted=7.927947, Expected=6.696000\n",
      "Month=167, Predicted=7.381082, Expected=6.248000\n",
      "Month=168, Predicted=6.990905, Expected=6.711600\n",
      "Month=169, Predicted=7.115670, Expected=6.600100\n",
      "Month=170, Predicted=6.557685, Expected=7.508200\n",
      "Month=171, Predicted=7.264485, Expected=7.765000\n",
      "Month=172, Predicted=7.687703, Expected=7.285000\n",
      "Month=173, Predicted=7.409144, Expected=6.959500\n",
      "Month=174, Predicted=7.243491, Expected=6.450000\n",
      "Month=175, Predicted=7.153696, Expected=6.572000\n",
      "Month=176, Predicted=7.379298, Expected=6.600000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=177, Predicted=7.913088, Expected=4.265300\n",
      "Month=178, Predicted=7.897607, Expected=7.367000\n",
      "Month=179, Predicted=7.771427, Expected=6.544000\n",
      "Month=180, Predicted=6.964315, Expected=6.940800\n",
      "Train RMSE: 0.89034\n",
      "Train RMSPE: 12.75416\n",
      "Train MAE: 0.65276\n",
      "Train MAPE: 8.61200\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=6.668063, Expected=6.786000\n",
      "Month=2, Predicted=6.627946, Expected=6.981200\n",
      "Month=3, Predicted=6.781033, Expected=6.756000\n",
      "Month=4, Predicted=6.932523, Expected=6.733200\n",
      "Month=5, Predicted=6.826364, Expected=6.671200\n",
      "Month=6, Predicted=6.719891, Expected=6.295600\n",
      "Month=7, Predicted=6.571988, Expected=6.432500\n",
      "Month=8, Predicted=6.853072, Expected=6.153000\n",
      "Month=9, Predicted=6.577554, Expected=6.389500\n",
      "Month=10, Predicted=7.265739, Expected=7.192000\n",
      "Month=11, Predicted=7.265401, Expected=6.524000\n",
      "Month=12, Predicted=7.021582, Expected=7.238500\n",
      "Month=13, Predicted=6.902135, Expected=6.990000\n",
      "Month=14, Predicted=6.974218, Expected=7.254000\n",
      "Month=15, Predicted=7.166497, Expected=6.720000\n",
      "Month=16, Predicted=6.788380, Expected=6.944000\n",
      "Month=17, Predicted=6.978525, Expected=7.052500\n",
      "Month=18, Predicted=6.905850, Expected=6.690000\n",
      "Month=19, Predicted=6.939519, Expected=6.909900\n",
      "Month=20, Predicted=7.031270, Expected=6.819000\n",
      "Month=21, Predicted=6.889767, Expected=7.167200\n",
      "Month=22, Predicted=7.207719, Expected=7.254000\n",
      "Month=23, Predicted=7.240364, Expected=6.664000\n",
      "Month=24, Predicted=6.851056, Expected=7.393500\n",
      "Month=25, Predicted=6.813718, Expected=7.125000\n",
      "Month=26, Predicted=7.243040, Expected=7.347000\n",
      "Month=27, Predicted=7.368208, Expected=7.216500\n",
      "Month=28, Predicted=7.149270, Expected=7.254000\n",
      "Month=29, Predicted=7.311832, Expected=7.238500\n",
      "Month=30, Predicted=7.320607, Expected=6.990000\n",
      "Month=31, Predicted=7.197937, Expected=7.192000\n",
      "Month=32, Predicted=7.266499, Expected=6.900000\n",
      "Month=33, Predicted=7.076110, Expected=7.427300\n",
      "Month=34, Predicted=7.375187, Expected=7.300500\n",
      "Month=35, Predicted=7.346388, Expected=6.902000\n",
      "Month=36, Predicted=7.110274, Expected=7.409000\n",
      "Month=37, Predicted=7.066108, Expected=7.179000\n",
      "Month=38, Predicted=7.297200, Expected=7.424500\n",
      "Month=39, Predicted=7.538061, Expected=7.275000\n",
      "Month=40, Predicted=7.268100, Expected=7.316000\n",
      "Month=41, Predicted=7.424681, Expected=7.086300\n",
      "Month=42, Predicted=7.260124, Expected=7.020000\n",
      "Month=43, Predicted=7.277588, Expected=7.270500\n",
      "Month=44, Predicted=7.336278, Expected=7.168800\n",
      "Month=45, Predicted=7.413611, Expected=7.448600\n",
      "Month=46, Predicted=7.517042, Expected=7.440200\n",
      "Test RMSE: 0.28581\n",
      "Test RMSPE: 4.22693\n",
      "Test MAE: 0.22417\n",
      "Test MAPE: 3.25563\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# d-lstm static \n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "\t\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons[0], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\t#model.add(LSTM(neurons[1], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\t#model.add(Dropout(0.3))\n",
    "\t#model.add(LSTM(neurons[2], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\t#model.add(Dropout(0.3))\n",
    "\t# model.add(LSTM(neurons[3], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\t# model.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\t\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tprint('Epoch:',i)\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\t\n",
    "\treturn model\n",
    "\t\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=5\n",
    "\tneurons= [ 5 , 4, 2] \n",
    "\tn_epochs=800\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "995c4d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 19:37:02.636301: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-18 19:37:02.637782: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-04-18 19:37:02.651257: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-18 19:37:02.651278: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_81798/4259575078.py:27: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_81798/4259575078.py:249: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_81798/4259575078.py:153: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "2022-04-18 19:37:03.140746: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-18 19:37:03.140767: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 19:37:03.625617: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-18 19:37:04.239568: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-18 19:37:04.341530: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-18 19:37:05.144555: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 3s 5ms/step - loss: 0.0489\n",
      "Epoch: 1\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0418\n",
      "Epoch: 2\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0405\n",
      "Epoch: 3\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0394\n",
      "Epoch: 4\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0384\n",
      "Epoch: 5\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0374\n",
      "Epoch: 6\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0366\n",
      "Epoch: 7\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0357\n",
      "Epoch: 8\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0350\n",
      "Epoch: 9\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0344\n",
      "Epoch: 10\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0339\n",
      "Epoch: 11\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0334\n",
      "Epoch: 12\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0330\n",
      "Epoch: 13\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0327\n",
      "Epoch: 14\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0324\n",
      "Epoch: 15\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0322\n",
      "Epoch: 16\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0320\n",
      "Epoch: 17\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0318\n",
      "Epoch: 18\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0317\n",
      "Epoch: 19\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0316\n",
      "Epoch: 20\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0314\n",
      "Epoch: 21\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0313\n",
      "Epoch: 22\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0312\n",
      "Epoch: 23\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0311\n",
      "Epoch: 24\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0310\n",
      "Epoch: 25\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0310\n",
      "Epoch: 26\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0309\n",
      "Epoch: 27\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0308\n",
      "Epoch: 28\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0308\n",
      "Epoch: 29\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0307\n",
      "Epoch: 30\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0307\n",
      "Epoch: 31\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0306\n",
      "Epoch: 32\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0306\n",
      "Epoch: 33\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0305\n",
      "Epoch: 34\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0305\n",
      "Epoch: 35\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0304\n",
      "Epoch: 36\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0304\n",
      "Epoch: 37\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0303\n",
      "Epoch: 38\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0303\n",
      "Epoch: 39\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0302\n",
      "Epoch: 40\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0302\n",
      "Epoch: 41\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0301\n",
      "Epoch: 42\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0301\n",
      "Epoch: 43\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0300\n",
      "Epoch: 44\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0300\n",
      "Epoch: 45\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0299\n",
      "Epoch: 46\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0299\n",
      "Epoch: 47\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0298\n",
      "Epoch: 48\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0297\n",
      "Epoch: 49\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0296\n",
      "Epoch: 50\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0296\n",
      "Epoch: 51\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0295\n",
      "Epoch: 52\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0294\n",
      "Epoch: 53\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0293\n",
      "Epoch: 54\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0291\n",
      "Epoch: 55\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0290\n",
      "Epoch: 56\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0288\n",
      "Epoch: 57\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0286\n",
      "Epoch: 58\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0285\n",
      "Epoch: 59\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0282\n",
      "Epoch: 60\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0280\n",
      "Epoch: 61\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0278\n",
      "Epoch: 62\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0276\n",
      "Epoch: 63\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0274\n",
      "Epoch: 64\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0273\n",
      "Epoch: 65\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0271\n",
      "Epoch: 66\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0270\n",
      "Epoch: 67\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0269\n",
      "Epoch: 68\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0268\n",
      "Epoch: 69\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0267\n",
      "Epoch: 70\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0267\n",
      "Epoch: 71\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0266\n",
      "Epoch: 72\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0265\n",
      "Epoch: 73\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0265\n",
      "Epoch: 74\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0264\n",
      "Epoch: 75\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0264\n",
      "Epoch: 76\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0264\n",
      "Epoch: 77\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0263\n",
      "Epoch: 78\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0263\n",
      "Epoch: 79\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0263\n",
      "Epoch: 80\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0262\n",
      "Epoch: 81\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0262\n",
      "Epoch: 82\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0262\n",
      "Epoch: 83\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0262\n",
      "Epoch: 84\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0261\n",
      "Epoch: 85\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0261\n",
      "Epoch: 86\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0261\n",
      "Epoch: 87\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0261\n",
      "Epoch: 88\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0260\n",
      "Epoch: 89\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0260\n",
      "Epoch: 90\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0260\n",
      "Epoch: 91\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0260\n",
      "Epoch: 92\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0260\n",
      "Epoch: 93\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0259\n",
      "Epoch: 94\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0259\n",
      "Epoch: 95\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0259\n",
      "Epoch: 96\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0259\n",
      "Epoch: 97\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0258\n",
      "Epoch: 98\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0258\n",
      "Epoch: 99\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0258\n",
      "Epoch: 100\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0258\n",
      "Epoch: 101\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0257\n",
      "Epoch: 102\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0257\n",
      "Epoch: 103\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0257\n",
      "Epoch: 104\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0256\n",
      "Epoch: 105\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0256\n",
      "Epoch: 106\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0255\n",
      "Epoch: 107\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0255\n",
      "Epoch: 108\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0254\n",
      "Epoch: 109\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0254\n",
      "Epoch: 110\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0253\n",
      "Epoch: 111\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0253\n",
      "Epoch: 112\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0252\n",
      "Epoch: 113\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0251\n",
      "Epoch: 114\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0250\n",
      "Epoch: 115\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0250\n",
      "Epoch: 116\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0249\n",
      "Epoch: 117\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0248\n",
      "Epoch: 118\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0248\n",
      "Epoch: 119\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0247\n",
      "Epoch: 120\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0247\n",
      "Epoch: 121\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0247\n",
      "Epoch: 122\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0247\n",
      "Epoch: 123\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0248\n",
      "Epoch: 124\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0249\n",
      "Epoch: 125\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0250\n",
      "Epoch: 126\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0252\n",
      "Epoch: 127\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0253\n",
      "Epoch: 128\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0255\n",
      "Epoch: 129\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0256\n",
      "Epoch: 130\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0257\n",
      "Epoch: 131\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0257\n",
      "Epoch: 132\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0257\n",
      "Epoch: 133\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0258\n",
      "Epoch: 134\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0258\n",
      "Epoch: 135\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0258\n",
      "Epoch: 136\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0258\n",
      "Epoch: 137\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0257\n",
      "Epoch: 138\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0257\n",
      "Epoch: 139\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0257\n",
      "Epoch: 140\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0256\n",
      "Epoch: 141\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0256\n",
      "Epoch: 142\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0255\n",
      "Epoch: 143\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 0.0255\n",
      "Epoch: 144\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0254\n",
      "Epoch: 145\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0254\n",
      "Epoch: 146\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 0.0253\n",
      "Epoch: 147\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0253\n",
      "Epoch: 148\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0252\n",
      "Epoch: 149\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0251\n",
      "Epoch: 150\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0250\n",
      "Epoch: 151\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0249\n",
      "Epoch: 152\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0248\n",
      "Epoch: 153\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0248\n",
      "Epoch: 154\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0246\n",
      "Epoch: 155\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 0.0245\n",
      "Epoch: 156\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0244\n",
      "Epoch: 157\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0243\n",
      "Epoch: 158\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0242\n",
      "Epoch: 159\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0241\n",
      "Epoch: 160\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0239\n",
      "Epoch: 161\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0238\n",
      "Epoch: 162\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0236\n",
      "Epoch: 163\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0235\n",
      "Epoch: 164\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0234\n",
      "Epoch: 165\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0232\n",
      "Epoch: 166\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0231\n",
      "Epoch: 167\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0229\n",
      "Epoch: 168\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0228\n",
      "Epoch: 169\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0226\n",
      "Epoch: 170\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0225\n",
      "Epoch: 171\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0223\n",
      "Epoch: 172\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0222\n",
      "Epoch: 173\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0221\n",
      "Epoch: 174\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0219\n",
      "Epoch: 175\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0218\n",
      "Epoch: 176\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0217\n",
      "Epoch: 177\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0216\n",
      "Epoch: 178\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0215\n",
      "Epoch: 179\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0214\n",
      "Epoch: 180\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0213\n",
      "Epoch: 181\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0212\n",
      "Epoch: 182\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0211\n",
      "Epoch: 183\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0211\n",
      "Epoch: 184\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0210\n",
      "Epoch: 185\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0209\n",
      "Epoch: 186\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0208\n",
      "Epoch: 187\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0208\n",
      "Epoch: 188\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0207\n",
      "Epoch: 189\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0206\n",
      "Epoch: 190\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0206\n",
      "Epoch: 191\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0205\n",
      "Epoch: 192\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0204\n",
      "Epoch: 193\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0204\n",
      "Epoch: 194\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0203\n",
      "Epoch: 195\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0202\n",
      "Epoch: 196\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0201\n",
      "Epoch: 197\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0201\n",
      "Epoch: 198\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0200\n",
      "Epoch: 199\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0199\n",
      "Epoch: 200\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0198\n",
      "Epoch: 201\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0198\n",
      "Epoch: 202\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 0.0197\n",
      "Epoch: 203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0196\n",
      "Epoch: 204\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0195\n",
      "Epoch: 205\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0195\n",
      "Epoch: 206\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0194\n",
      "Epoch: 207\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0193\n",
      "Epoch: 208\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0192\n",
      "Epoch: 209\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0192\n",
      "Epoch: 210\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0191\n",
      "Epoch: 211\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0190\n",
      "Epoch: 212\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0189\n",
      "Epoch: 213\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0189\n",
      "Epoch: 214\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0188\n",
      "Epoch: 215\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0188\n",
      "Epoch: 216\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0187\n",
      "Epoch: 217\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0186\n",
      "Epoch: 218\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0186\n",
      "Epoch: 219\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0185\n",
      "Epoch: 220\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0185\n",
      "Epoch: 221\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0184\n",
      "Epoch: 222\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0184\n",
      "Epoch: 223\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0183\n",
      "Epoch: 224\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0182\n",
      "Epoch: 225\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0181\n",
      "Epoch: 226\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0181\n",
      "Epoch: 227\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0180\n",
      "Epoch: 228\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0179\n",
      "Epoch: 229\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0179\n",
      "Epoch: 230\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0178\n",
      "Epoch: 231\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0177\n",
      "Epoch: 232\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0177\n",
      "Epoch: 233\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0176\n",
      "Epoch: 234\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0176\n",
      "Epoch: 235\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0181\n",
      "Epoch: 236\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0177\n",
      "Epoch: 237\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0177\n",
      "Epoch: 238\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0177\n",
      "Epoch: 239\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0176\n",
      "Epoch: 240\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0176\n",
      "Epoch: 241\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0172\n",
      "Epoch: 242\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0172\n",
      "Epoch: 243\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0171\n",
      "Epoch: 244\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0170\n",
      "Epoch: 245\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0170\n",
      "Epoch: 246\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0170\n",
      "Epoch: 247\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0169\n",
      "Epoch: 248\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0169\n",
      "Epoch: 249\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0169\n",
      "Epoch: 250\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0168\n",
      "Epoch: 251\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0168\n",
      "Epoch: 252\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0168\n",
      "Epoch: 253\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0167\n",
      "Epoch: 254\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0167\n",
      "Epoch: 255\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0167\n",
      "Epoch: 256\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0167\n",
      "Epoch: 257\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0168\n",
      "Epoch: 258\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0168\n",
      "Epoch: 259\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0168\n",
      "Epoch: 260\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0181\n",
      "Epoch: 261\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0174\n",
      "Epoch: 262\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0176\n",
      "Epoch: 263\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0169\n",
      "Epoch: 264\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0166\n",
      "Epoch: 265\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0170\n",
      "Epoch: 266\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0166\n",
      "Epoch: 267\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0169\n",
      "Epoch: 268\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0165\n",
      "Epoch: 269\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0168\n",
      "Epoch: 270\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0164\n",
      "Epoch: 271\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0167\n",
      "Epoch: 272\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0164\n",
      "Epoch: 273\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0166\n",
      "Epoch: 274\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 275\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0165\n",
      "Epoch: 276\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 277\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 278\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 279\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 280\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 281\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0164\n",
      "Epoch: 282\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 283\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0164\n",
      "Epoch: 284\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0169\n",
      "Epoch: 285\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0175\n",
      "Epoch: 286\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0168\n",
      "Epoch: 287\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0164\n",
      "Epoch: 288\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0162\n",
      "Epoch: 289\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0167\n",
      "Epoch: 290\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0165\n",
      "Epoch: 291\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0169\n",
      "Epoch: 292\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0168\n",
      "Epoch: 293\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0171\n",
      "Epoch: 294\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0169\n",
      "Epoch: 295\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0169\n",
      "Epoch: 296\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0166\n",
      "Epoch: 297\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0167\n",
      "Epoch: 298\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 299\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0166\n",
      "Epoch: 300\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 301\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0167\n",
      "Epoch: 302\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0165\n",
      "Epoch: 303\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0167\n",
      "Epoch: 304\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0165\n",
      "Epoch: 305\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0166\n",
      "Epoch: 306\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 307\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0165\n",
      "Epoch: 308\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 309\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0166\n",
      "Epoch: 310\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 311\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0166\n",
      "Epoch: 312\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 313\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0165\n",
      "Epoch: 314\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0162\n",
      "Epoch: 315\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0165\n",
      "Epoch: 316\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0162\n",
      "Epoch: 317\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0165\n",
      "Epoch: 318\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0162\n",
      "Epoch: 319\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0164\n",
      "Epoch: 320\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0162\n",
      "Epoch: 321\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0164\n",
      "Epoch: 322\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0161\n",
      "Epoch: 323\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0164\n",
      "Epoch: 324\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0161\n",
      "Epoch: 325\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 326\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0161\n",
      "Epoch: 327\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0163\n",
      "Epoch: 328\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0161\n",
      "Epoch: 329\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 330\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0160\n",
      "Epoch: 331\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch: 332\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0160\n",
      "Epoch: 333\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0162\n",
      "Epoch: 334\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0160\n",
      "Epoch: 335\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0162\n",
      "Epoch: 336\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0159\n",
      "Epoch: 337\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0162\n",
      "Epoch: 338\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0159\n",
      "Epoch: 339\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0162\n",
      "Epoch: 340\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0159\n",
      "Epoch: 341\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0161\n",
      "Epoch: 342\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0159\n",
      "Epoch: 343\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0161\n",
      "Epoch: 344\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0158\n",
      "Epoch: 345\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0161\n",
      "Epoch: 346\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0158\n",
      "Epoch: 347\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0160\n",
      "Epoch: 348\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0158\n",
      "Epoch: 349\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0160\n",
      "Epoch: 350\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0158\n",
      "Epoch: 351\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0160\n",
      "Epoch: 352\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0157\n",
      "Epoch: 353\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0159\n",
      "Epoch: 354\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0157\n",
      "Epoch: 355\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0159\n",
      "Epoch: 356\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0157\n",
      "Epoch: 357\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0159\n",
      "Epoch: 358\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0156\n",
      "Epoch: 359\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0158\n",
      "Epoch: 360\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0156\n",
      "Epoch: 361\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0158\n",
      "Epoch: 362\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0156\n",
      "Epoch: 363\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0158\n",
      "Epoch: 364\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0156\n",
      "Epoch: 365\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0157\n",
      "Epoch: 366\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0155\n",
      "Epoch: 367\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0157\n",
      "Epoch: 368\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0155\n",
      "Epoch: 369\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0157\n",
      "Epoch: 370\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0155\n",
      "Epoch: 371\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0156\n",
      "Epoch: 372\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0154\n",
      "Epoch: 373\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0156\n",
      "Epoch: 374\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0154\n",
      "Epoch: 375\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0156\n",
      "Epoch: 376\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0154\n",
      "Epoch: 377\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0155\n",
      "Epoch: 378\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0154\n",
      "Epoch: 379\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0155\n",
      "Epoch: 380\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0153\n",
      "Epoch: 381\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0155\n",
      "Epoch: 382\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0153\n",
      "Epoch: 383\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0154\n",
      "Epoch: 384\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0153\n",
      "Epoch: 385\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0154\n",
      "Epoch: 386\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0152\n",
      "Epoch: 387\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0154\n",
      "Epoch: 388\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0152\n",
      "Epoch: 389\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0153\n",
      "Epoch: 390\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0152\n",
      "Epoch: 391\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0153\n",
      "Epoch: 392\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0151\n",
      "Epoch: 393\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0153\n",
      "Epoch: 394\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0151\n",
      "Epoch: 395\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0152\n",
      "Epoch: 396\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0151\n",
      "Epoch: 397\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0152\n",
      "Epoch: 398\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0151\n",
      "Epoch: 399\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0152\n",
      "Epoch: 400\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0150\n",
      "Epoch: 401\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0151\n",
      "Epoch: 402\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0150\n",
      "Epoch: 403\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0151\n",
      "Epoch: 404\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0150\n",
      "Epoch: 405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0151\n",
      "Epoch: 406\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0149\n",
      "Epoch: 407\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0150\n",
      "Epoch: 408\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0149\n",
      "Epoch: 409\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0150\n",
      "Epoch: 410\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0149\n",
      "Epoch: 411\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0150\n",
      "Epoch: 412\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0149\n",
      "Epoch: 413\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0149\n",
      "Epoch: 414\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0148\n",
      "Epoch: 415\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0149\n",
      "Epoch: 416\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0148\n",
      "Epoch: 417\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0148\n",
      "Epoch: 418\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0148\n",
      "Epoch: 419\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0148\n",
      "Epoch: 420\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0148\n",
      "Epoch: 421\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0148\n",
      "Epoch: 422\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch: 423\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch: 424\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch: 425\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch: 426\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch: 427\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0146\n",
      "Epoch: 428\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch: 429\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 430\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 431\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 432\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 433\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 434\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0147\n",
      "Epoch: 435\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0148\n",
      "Epoch: 436\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 437\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 438\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 439\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 440\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0148\n",
      "Epoch: 441\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 442\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 443\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 444\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 445\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch: 446\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 447\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 448\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 449\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 450\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 451\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch: 452\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch: 453\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 454\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 455\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 456\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0144\n",
      "Epoch: 457\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch: 458\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 459\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 460\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch: 461\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch: 462\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 463\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 464\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 465\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 466\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 467\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 468\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 469\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 470\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 471\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 472\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 473\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 474\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 475\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 476\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 477\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0142\n",
      "Epoch: 478\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 479\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 480\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 481\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 482\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 483\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 484\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 485\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 486\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 487\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 488\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0142\n",
      "Epoch: 489\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0142\n",
      "Epoch: 490\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 491\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 492\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0142\n",
      "Epoch: 493\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 494\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 495\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 496\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch: 497\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 498\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 499\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 501\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 502\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 503\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 504\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 505\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 506\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 507\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 508\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 509\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 510\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 511\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0142\n",
      "Epoch: 512\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 513\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 514\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 515\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch: 516\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 517\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 518\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 519\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 520\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 521\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 522\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 523\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 524\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 525\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch: 526\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 527\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 528\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0146\n",
      "Epoch: 529\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 530\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 531\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 532\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 533\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 534\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 535\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch: 536\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 537\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 538\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0146\n",
      "Epoch: 539\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 540\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 541\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 542\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 543\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 544\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 545\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0147\n",
      "Epoch: 546\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 547\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 548\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0146\n",
      "Epoch: 549\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 550\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 551\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0146\n",
      "Epoch: 552\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 553\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 554\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch: 555\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 556\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 557\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch: 558\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 559\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 560\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 561\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 562\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 563\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 564\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 565\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 566\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 567\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0149\n",
      "Epoch: 568\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 569\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 570\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0141\n",
      "Epoch: 571\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0140\n",
      "Epoch: 572\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 573\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 574\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 575\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 576\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0151\n",
      "Epoch: 577\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch: 578\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch: 579\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 580\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 581\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0140\n",
      "Epoch: 582\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0140\n",
      "Epoch: 583\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 584\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0139\n",
      "Epoch: 585\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 586\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 587\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0140\n",
      "Epoch: 588\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0149\n",
      "Epoch: 589\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 590\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 591\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 592\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 593\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 594\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 595\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 596\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 597\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 598\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0148\n",
      "Epoch: 599\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 600\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0146\n",
      "Epoch: 601\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 602\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0148\n",
      "Epoch: 603\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 604\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch: 605\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 606\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch: 607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 608\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 609\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0141\n",
      "Epoch: 610\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 611\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 612\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 613\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0141\n",
      "Epoch: 614\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 615\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 616\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch: 617\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 618\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 619\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 620\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 621\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 622\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 623\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 624\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch: 625\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0140\n",
      "Epoch: 626\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0144\n",
      "Epoch: 627\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 628\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 629\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 630\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 0.0143\n",
      "Epoch: 631\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 0.0143\n",
      "Epoch: 632\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0141\n",
      "Epoch: 633\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 634\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 635\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 636\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0140\n",
      "Epoch: 637\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 638\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 639\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0139\n",
      "Epoch: 640\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0149\n",
      "Epoch: 641\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 642\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0140\n",
      "Epoch: 643\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0142\n",
      "Epoch: 644\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 645\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 646\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0137\n",
      "Epoch: 647\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0137\n",
      "Epoch: 648\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0137\n",
      "Epoch: 649\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0138\n",
      "Epoch: 650\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0148\n",
      "Epoch: 651\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch: 652\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0141\n",
      "Epoch: 653\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0142\n",
      "Epoch: 654\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0140\n",
      "Epoch: 655\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0139\n",
      "Epoch: 656\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0137\n",
      "Epoch: 657\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0137\n",
      "Epoch: 658\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0137\n",
      "Epoch: 659\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0137\n",
      "Epoch: 660\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 661\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0143\n",
      "Epoch: 662\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 663\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch: 664\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 665\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0139\n",
      "Epoch: 666\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0139\n",
      "Epoch: 667\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 668\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 669\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 670\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0140\n",
      "Epoch: 671\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 672\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0139\n",
      "Epoch: 673\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0136\n",
      "Epoch: 674\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0140\n",
      "Epoch: 675\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0140\n",
      "Epoch: 676\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 677\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0141\n",
      "Epoch: 678\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 679\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 680\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 681\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0136\n",
      "Epoch: 682\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0138\n",
      "Epoch: 683\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0137\n",
      "Epoch: 684\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0139\n",
      "Epoch: 685\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0136\n",
      "Epoch: 686\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch: 687\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0137\n",
      "Epoch: 688\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 689\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0136\n",
      "Epoch: 690\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0136\n",
      "Epoch: 691\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0137\n",
      "Epoch: 692\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0136\n",
      "Epoch: 693\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0140\n",
      "Epoch: 694\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 695\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 696\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 697\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0135\n",
      "Epoch: 698\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0136\n",
      "Epoch: 699\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0135\n",
      "Epoch: 700\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0136\n",
      "Epoch: 701\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0135\n",
      "Epoch: 702\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 703\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0135\n",
      "Epoch: 704\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch: 705\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0135\n",
      "Epoch: 706\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0136\n",
      "Epoch: 707\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0135\n",
      "Epoch: 708\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0136\n",
      "Epoch: 709\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0135\n",
      "Epoch: 710\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0136\n",
      "Epoch: 711\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0135\n",
      "Epoch: 712\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0136\n",
      "Epoch: 713\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0135\n",
      "Epoch: 714\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0135\n",
      "Epoch: 715\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0135\n",
      "Epoch: 716\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0135\n",
      "Epoch: 717\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0135\n",
      "Epoch: 718\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0135\n",
      "Epoch: 719\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0135\n",
      "Epoch: 720\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0135\n",
      "Epoch: 721\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0135\n",
      "Epoch: 722\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0134\n",
      "Epoch: 723\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0134\n",
      "Epoch: 724\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0134\n",
      "Epoch: 725\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0134\n",
      "Epoch: 726\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0134\n",
      "Epoch: 727\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0134\n",
      "Epoch: 728\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0134\n",
      "Epoch: 729\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0134\n",
      "Epoch: 730\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0133\n",
      "Epoch: 731\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0133\n",
      "Epoch: 732\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0133\n",
      "Epoch: 733\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0133\n",
      "Epoch: 734\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0133\n",
      "Epoch: 735\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0133\n",
      "Epoch: 736\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0132\n",
      "Epoch: 737\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0132\n",
      "Epoch: 738\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0132\n",
      "Epoch: 739\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0132\n",
      "Epoch: 740\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0132\n",
      "Epoch: 741\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0132\n",
      "Epoch: 742\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0132\n",
      "Epoch: 743\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0132\n",
      "Epoch: 744\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0132\n",
      "Epoch: 745\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0132\n",
      "Epoch: 746\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0132\n",
      "Epoch: 747\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0132\n",
      "Epoch: 748\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0132\n",
      "Epoch: 749\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0131\n",
      "Epoch: 750\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0131\n",
      "Epoch: 751\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0131\n",
      "Epoch: 752\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0131\n",
      "Epoch: 753\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0131\n",
      "Epoch: 754\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0131\n",
      "Epoch: 755\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0131\n",
      "Epoch: 756\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0131\n",
      "Epoch: 757\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0131\n",
      "Epoch: 758\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0131\n",
      "Epoch: 759\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0131\n",
      "Epoch: 760\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0131\n",
      "Epoch: 761\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0131\n",
      "Epoch: 762\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0131\n",
      "Epoch: 763\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0130\n",
      "Epoch: 764\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0130\n",
      "Epoch: 765\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0130\n",
      "Epoch: 766\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0130\n",
      "Epoch: 767\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0130\n",
      "Epoch: 768\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0130\n",
      "Epoch: 769\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0130\n",
      "Epoch: 770\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0130\n",
      "Epoch: 771\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0130\n",
      "Epoch: 772\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0130\n",
      "Epoch: 773\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0129\n",
      "Epoch: 774\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0129\n",
      "Epoch: 775\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0129\n",
      "Epoch: 776\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0129\n",
      "Epoch: 777\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0129\n",
      "Epoch: 778\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0129\n",
      "Epoch: 779\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0129\n",
      "Epoch: 780\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0129\n",
      "Epoch: 781\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0129\n",
      "Epoch: 782\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0129\n",
      "Epoch: 783\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0128\n",
      "Epoch: 784\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0128\n",
      "Epoch: 785\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0128\n",
      "Epoch: 786\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0128\n",
      "Epoch: 787\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0128\n",
      "Epoch: 788\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0128\n",
      "Epoch: 789\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0128\n",
      "Epoch: 790\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0128\n",
      "Epoch: 791\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0128\n",
      "Epoch: 792\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0128\n",
      "Epoch: 793\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0128\n",
      "Epoch: 794\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0127\n",
      "Epoch: 795\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0127\n",
      "Epoch: 796\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0127\n",
      "Epoch: 797\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0127\n",
      "Epoch: 798\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0127\n",
      "Epoch: 799\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0127\n",
      "Forecasting Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 19:50:33.531340: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-18 19:50:33.586836: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=1, Predicted=10.260723, Expected=9.510000\n",
      "Month=2, Predicted=9.967774, Expected=9.796000\n",
      "Month=3, Predicted=9.914172, Expected=9.468500\n",
      "Month=4, Predicted=9.731521, Expected=9.672000\n",
      "Month=5, Predicted=10.111255, Expected=9.610000\n",
      "Month=6, Predicted=9.737944, Expected=9.240000\n",
      "Month=7, Predicted=10.612484, Expected=10.318300\n",
      "Month=8, Predicted=9.732724, Expected=8.974800\n",
      "Month=9, Predicted=9.447815, Expected=9.114000\n",
      "Month=10, Predicted=9.418519, Expected=9.300000\n",
      "Month=11, Predicted=9.197905, Expected=8.400000\n",
      "Month=12, Predicted=8.958915, Expected=9.300000\n",
      "Month=13, Predicted=9.496394, Expected=9.000000\n",
      "Month=14, Predicted=9.608141, Expected=9.300000\n",
      "Month=15, Predicted=9.579704, Expected=9.460000\n",
      "Month=16, Predicted=9.230988, Expected=9.145000\n",
      "Month=17, Predicted=9.060602, Expected=9.021000\n",
      "Month=18, Predicted=8.889470, Expected=8.750000\n",
      "Month=19, Predicted=8.679885, Expected=8.710000\n",
      "Month=20, Predicted=8.847865, Expected=8.370000\n",
      "Month=21, Predicted=9.051091, Expected=8.504000\n",
      "Month=22, Predicted=9.466382, Expected=9.819700\n",
      "Month=23, Predicted=8.930433, Expected=9.827300\n",
      "Month=24, Predicted=9.907626, Expected=9.929800\n",
      "Month=25, Predicted=9.513547, Expected=9.288000\n",
      "Month=26, Predicted=9.317878, Expected=9.300000\n",
      "Month=27, Predicted=9.168595, Expected=9.060000\n",
      "Month=28, Predicted=9.136671, Expected=8.835000\n",
      "Month=29, Predicted=8.992401, Expected=8.388600\n",
      "Month=30, Predicted=9.256753, Expected=8.400000\n",
      "Month=31, Predicted=9.094604, Expected=8.525000\n",
      "Month=32, Predicted=8.568530, Expected=8.250000\n",
      "Month=33, Predicted=9.084139, Expected=8.419000\n",
      "Month=34, Predicted=9.189685, Expected=9.455000\n",
      "Month=35, Predicted=8.610296, Expected=8.540000\n",
      "Month=36, Predicted=9.101786, Expected=9.455000\n",
      "Month=37, Predicted=8.935165, Expected=9.000000\n",
      "Month=38, Predicted=8.867130, Expected=9.599000\n",
      "Month=39, Predicted=9.013923, Expected=9.436000\n",
      "Month=40, Predicted=9.101654, Expected=9.539800\n",
      "Month=41, Predicted=9.214987, Expected=9.028600\n",
      "Month=42, Predicted=8.876351, Expected=8.932000\n",
      "Month=43, Predicted=8.901690, Expected=8.993000\n",
      "Month=44, Predicted=8.771406, Expected=8.678400\n",
      "Month=45, Predicted=8.981590, Expected=9.011100\n",
      "Month=46, Predicted=9.505059, Expected=9.630000\n",
      "Month=47, Predicted=9.098058, Expected=8.590400\n",
      "Month=48, Predicted=9.558935, Expected=9.736300\n",
      "Month=49, Predicted=9.397000, Expected=9.384500\n",
      "Month=50, Predicted=9.298349, Expected=9.947200\n",
      "Month=51, Predicted=9.457083, Expected=9.577100\n",
      "Month=52, Predicted=9.303582, Expected=9.117200\n",
      "Month=53, Predicted=9.070992, Expected=9.122500\n",
      "Month=54, Predicted=9.032097, Expected=8.880000\n",
      "Month=55, Predicted=9.053585, Expected=8.709200\n",
      "Month=56, Predicted=8.931772, Expected=8.428200\n",
      "Month=57, Predicted=9.967362, Expected=9.907600\n",
      "Month=58, Predicted=9.009909, Expected=9.145000\n",
      "Month=59, Predicted=9.524300, Expected=8.498000\n",
      "Month=60, Predicted=9.564536, Expected=9.362000\n",
      "Month=61, Predicted=8.905855, Expected=9.000000\n",
      "Month=62, Predicted=9.280937, Expected=9.455000\n",
      "Month=63, Predicted=9.368332, Expected=9.300000\n",
      "Month=64, Predicted=9.137808, Expected=8.990000\n",
      "Month=65, Predicted=8.934521, Expected=8.990000\n",
      "Month=66, Predicted=8.786227, Expected=8.790000\n",
      "Month=67, Predicted=8.785520, Expected=8.835000\n",
      "Month=68, Predicted=9.041516, Expected=8.700000\n",
      "Month=69, Predicted=9.165085, Expected=8.935000\n",
      "Month=70, Predicted=8.936417, Expected=8.835000\n",
      "Month=71, Predicted=8.761522, Expected=8.265000\n",
      "Month=72, Predicted=8.759656, Expected=8.835000\n",
      "Month=73, Predicted=8.477868, Expected=8.550000\n",
      "Month=74, Predicted=8.581282, Expected=8.680000\n",
      "Month=75, Predicted=8.765615, Expected=8.400000\n",
      "Month=76, Predicted=8.355240, Expected=8.525000\n",
      "Month=77, Predicted=8.392596, Expected=8.370000\n",
      "Month=78, Predicted=8.205029, Expected=7.890000\n",
      "Month=79, Predicted=8.164201, Expected=7.812000\n",
      "Month=80, Predicted=7.952171, Expected=7.620000\n",
      "Month=81, Predicted=7.687439, Expected=7.718000\n",
      "Month=82, Predicted=8.532035, Expected=8.323500\n",
      "Month=83, Predicted=8.052078, Expected=6.860000\n",
      "Month=84, Predicted=8.105555, Expected=8.308000\n",
      "Month=85, Predicted=7.899195, Expected=8.100000\n",
      "Month=86, Predicted=8.172603, Expected=8.525000\n",
      "Month=87, Predicted=8.198543, Expected=8.250000\n",
      "Month=88, Predicted=8.170734, Expected=8.215000\n",
      "Month=89, Predicted=8.006001, Expected=8.122600\n",
      "Month=90, Predicted=7.870017, Expected=7.778100\n",
      "Month=91, Predicted=7.886633, Expected=7.954600\n",
      "Month=92, Predicted=7.968666, Expected=7.420000\n",
      "Month=93, Predicted=7.849173, Expected=7.538300\n",
      "Month=94, Predicted=8.800970, Expected=7.905000\n",
      "Month=95, Predicted=7.448430, Expected=7.140000\n",
      "Month=96, Predicted=7.967262, Expected=8.432000\n",
      "Month=97, Predicted=8.121269, Expected=7.710000\n",
      "Month=98, Predicted=7.740418, Expected=7.967000\n",
      "Month=99, Predicted=7.741412, Expected=7.320000\n",
      "Month=100, Predicted=7.307763, Expected=7.502000\n",
      "Month=101, Predicted=7.256728, Expected=7.409000\n",
      "Month=102, Predicted=7.528999, Expected=7.200600\n",
      "Month=103, Predicted=7.485818, Expected=7.865000\n",
      "Month=104, Predicted=7.339193, Expected=6.690000\n",
      "Month=105, Predicted=7.546034, Expected=6.879400\n",
      "Month=106, Predicted=7.659782, Expected=7.440000\n",
      "Month=107, Predicted=6.790593, Expected=6.860000\n",
      "Month=108, Predicted=7.455823, Expected=7.595000\n",
      "Month=109, Predicted=7.867476, Expected=7.200000\n",
      "Month=110, Predicted=7.141445, Expected=7.130000\n",
      "Month=111, Predicted=7.047800, Expected=6.900000\n",
      "Month=112, Predicted=6.794732, Expected=7.130000\n",
      "Month=113, Predicted=6.932471, Expected=7.130000\n",
      "Month=114, Predicted=6.949301, Expected=6.840000\n",
      "Month=115, Predicted=6.983378, Expected=7.006000\n",
      "Month=116, Predicted=6.758681, Expected=6.780000\n",
      "Month=117, Predicted=6.685155, Expected=7.089600\n",
      "Month=118, Predicted=6.972585, Expected=6.882000\n",
      "Month=119, Predicted=6.709743, Expected=6.446700\n",
      "Month=120, Predicted=6.591899, Expected=6.882000\n",
      "Month=121, Predicted=6.511588, Expected=6.600000\n",
      "Month=122, Predicted=6.620247, Expected=6.820000\n",
      "Month=123, Predicted=6.817359, Expected=6.600000\n",
      "Month=124, Predicted=6.490238, Expected=6.820000\n",
      "Month=125, Predicted=6.624065, Expected=6.665000\n",
      "Month=126, Predicted=6.429676, Expected=6.450000\n",
      "Month=127, Predicted=6.444079, Expected=6.665000\n",
      "Month=128, Predicted=6.325518, Expected=6.450000\n",
      "Month=129, Predicted=6.374098, Expected=6.722100\n",
      "Month=130, Predicted=6.574818, Expected=6.820000\n",
      "Month=131, Predicted=6.443979, Expected=6.160000\n",
      "Month=132, Predicted=6.312865, Expected=6.820000\n",
      "Month=133, Predicted=6.481018, Expected=6.480000\n",
      "Month=134, Predicted=6.417308, Expected=6.596900\n",
      "Month=135, Predicted=6.515835, Expected=6.492000\n",
      "Month=136, Predicted=6.285956, Expected=6.510000\n",
      "Month=137, Predicted=6.358345, Expected=6.339500\n",
      "Month=138, Predicted=6.211242, Expected=6.001600\n",
      "Month=139, Predicted=6.094371, Expected=6.107000\n",
      "Month=140, Predicted=6.000088, Expected=5.790000\n",
      "Month=141, Predicted=5.977496, Expected=5.885000\n",
      "Month=142, Predicted=7.071830, Expected=7.280000\n",
      "Month=143, Predicted=6.335027, Expected=5.941600\n",
      "Month=144, Predicted=6.527084, Expected=6.810000\n",
      "Month=145, Predicted=6.291670, Expected=6.182000\n",
      "Month=146, Predicted=6.021738, Expected=6.293000\n",
      "Month=147, Predicted=5.936447, Expected=6.118600\n",
      "Month=148, Predicted=6.178359, Expected=6.138000\n",
      "Month=149, Predicted=6.087676, Expected=6.107000\n",
      "Month=150, Predicted=5.962004, Expected=5.913000\n",
      "Month=151, Predicted=5.983593, Expected=6.141100\n",
      "Month=152, Predicted=5.915352, Expected=6.248000\n",
      "Month=153, Predicted=5.918529, Expected=5.829700\n",
      "Month=154, Predicted=5.943235, Expected=6.829300\n",
      "Month=155, Predicted=6.164405, Expected=6.694400\n",
      "Month=156, Predicted=6.436153, Expected=7.726200\n",
      "Month=157, Predicted=6.973356, Expected=7.054400\n",
      "Month=158, Predicted=6.763620, Expected=7.268900\n",
      "Month=159, Predicted=6.782786, Expected=7.020000\n",
      "Month=160, Predicted=6.703142, Expected=6.510000\n",
      "Month=161, Predicted=6.539448, Expected=6.370500\n",
      "Month=162, Predicted=6.400158, Expected=5.730000\n",
      "Month=163, Predicted=6.432680, Expected=5.828000\n",
      "Month=164, Predicted=5.850400, Expected=5.580000\n",
      "Month=165, Predicted=5.773905, Expected=5.709900\n",
      "Month=166, Predicted=6.913300, Expected=6.696000\n",
      "Month=167, Predicted=6.131303, Expected=6.248000\n",
      "Month=168, Predicted=6.763566, Expected=6.711600\n",
      "Month=169, Predicted=6.550388, Expected=6.600100\n",
      "Month=170, Predicted=6.544496, Expected=7.508200\n",
      "Month=171, Predicted=6.892861, Expected=7.765000\n",
      "Month=172, Predicted=7.334473, Expected=7.285000\n",
      "Month=173, Predicted=7.147262, Expected=6.959500\n",
      "Month=174, Predicted=6.690345, Expected=6.450000\n",
      "Month=175, Predicted=6.562798, Expected=6.572000\n",
      "Month=176, Predicted=6.673978, Expected=6.600000\n",
      "Month=177, Predicted=5.262616, Expected=4.265300\n",
      "Month=178, Predicted=6.900885, Expected=7.367000\n",
      "Month=179, Predicted=6.695848, Expected=6.544000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=180, Predicted=6.794445, Expected=6.940800\n",
      "Train RMSE: 0.37800\n",
      "Train RMSPE: 5.10043\n",
      "Train MAE: 0.27895\n",
      "Train MAPE: 3.65426\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=7.410449, Expected=6.786000\n",
      "Month=2, Predicted=7.166839, Expected=6.981200\n",
      "Month=3, Predicted=6.775402, Expected=6.756000\n",
      "Month=4, Predicted=6.694611, Expected=6.733200\n",
      "Month=5, Predicted=6.659293, Expected=6.671200\n",
      "Month=6, Predicted=6.403306, Expected=6.295600\n",
      "Month=7, Predicted=6.412748, Expected=6.432500\n",
      "Month=8, Predicted=6.459775, Expected=6.153000\n",
      "Month=9, Predicted=6.257806, Expected=6.389500\n",
      "Month=10, Predicted=6.951776, Expected=7.192000\n",
      "Month=11, Predicted=6.440090, Expected=6.524000\n",
      "Month=12, Predicted=6.808044, Expected=7.238500\n",
      "Month=13, Predicted=6.751939, Expected=6.990000\n",
      "Month=14, Predicted=6.758828, Expected=7.254000\n",
      "Month=15, Predicted=6.860587, Expected=6.720000\n",
      "Month=16, Predicted=6.563848, Expected=6.944000\n",
      "Month=17, Predicted=6.711365, Expected=7.052500\n",
      "Month=18, Predicted=6.744573, Expected=6.690000\n",
      "Month=19, Predicted=6.836646, Expected=6.909900\n",
      "Month=20, Predicted=6.847251, Expected=6.819000\n",
      "Month=21, Predicted=6.593118, Expected=7.167200\n",
      "Month=22, Predicted=6.927984, Expected=7.254000\n",
      "Month=23, Predicted=6.892978, Expected=6.664000\n",
      "Month=24, Predicted=6.695966, Expected=7.393500\n",
      "Month=25, Predicted=6.857329, Expected=7.125000\n",
      "Month=26, Predicted=6.977000, Expected=7.347000\n",
      "Month=27, Predicted=7.110811, Expected=7.216500\n",
      "Month=28, Predicted=6.908671, Expected=7.254000\n",
      "Month=29, Predicted=7.026284, Expected=7.238500\n",
      "Month=30, Predicted=6.934612, Expected=6.990000\n",
      "Month=31, Predicted=6.939676, Expected=7.192000\n",
      "Month=32, Predicted=6.956424, Expected=6.900000\n",
      "Month=33, Predicted=6.809552, Expected=7.427300\n",
      "Month=34, Predicted=7.152372, Expected=7.300500\n",
      "Month=35, Predicted=7.053886, Expected=6.902000\n",
      "Month=36, Predicted=6.936475, Expected=7.409000\n",
      "Month=37, Predicted=6.922152, Expected=7.179000\n",
      "Month=38, Predicted=7.080023, Expected=7.424500\n",
      "Month=39, Predicted=7.211593, Expected=7.275000\n",
      "Month=40, Predicted=7.000798, Expected=7.316000\n",
      "Month=41, Predicted=7.121239, Expected=7.086300\n",
      "Month=42, Predicted=6.877769, Expected=7.020000\n",
      "Month=43, Predicted=6.957502, Expected=7.270500\n",
      "Month=44, Predicted=6.915563, Expected=7.168800\n",
      "Month=45, Predicted=7.058472, Expected=7.448600\n",
      "Month=46, Predicted=7.170130, Expected=7.440200\n",
      "Test RMSE: 0.30097\n",
      "Test RMSPE: 4.19751\n",
      "Test MAE: 0.24385\n",
      "Test MAPE: 3.42288\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior\n",
    "import random as rn\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "\t\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons[0], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\t#model.add(LSTM(neurons[1], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\t#model.add(Dropout(0.3))\n",
    "\t#model.add(LSTM(neurons[2], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\t#model.add(Dropout(0.3))\n",
    "\t# model.add(LSTM(neurons[3], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\t# model.add(Dropout(0.3))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\t\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tprint('Epoch:',i)\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\t\n",
    "\treturn model\n",
    "\t\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=5\n",
    "\tneurons= [ 5,4,2 ] \n",
    "\tn_epochs=800\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d39da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 20:11:07.616802: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-18 20:11:07.616856: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_81798/1428441879.py:26: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_81798/1428441879.py:241: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_81798/1428441879.py:145: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 20:11:08.348773: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-18 20:11:08.394059: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-18 20:11:08.486096: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0500\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0395\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0349\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0332\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0324\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0318\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0314\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0311\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0308\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0306\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0304\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0303\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0301\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0300\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0299\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0298\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0297\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0297\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0296\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0296\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0295\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0295\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0294\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0294\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0293\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0293\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0293\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0292\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0292\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0291\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0291\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0291\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0290\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0290\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0290\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0290\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0289\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0289\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0289\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0288\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0288\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0288\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0288\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0287\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0287\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0287\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0287\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0286\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0286\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0286\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0286\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0285\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0285\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0285\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0284\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0285\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0284\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0284\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0284\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0283\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0283\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0283\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0283\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0283\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0282\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0282\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0282\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0282\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0281\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0281\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0281\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0281\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0280\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0280\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0280\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0280\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0280\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0279\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0279\n",
      "Epoch: 79\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0279\n",
      "Epoch: 80\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0279\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0278\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0278\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0278\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0277\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0277\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0277\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0277\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0276\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0276\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0276\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0276\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0275\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0275\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0274\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0274\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0274\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0273\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0273\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0273\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0272\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0272\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0272\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0271\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0271\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0270\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0270\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0270\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0269\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0269\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0268\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0268\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0267\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0267\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0266\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0266\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0265\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0265\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0265\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0264\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0264\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0263\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0263\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0263\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0262\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0262\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0261\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0261\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0261\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0260\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0260\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0259\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0259\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0259\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0258\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0258\n",
      "Epoch: 136\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0258\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0257\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0257\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0257\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0257\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0256\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0255\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0256\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0255\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0255\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0255\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0254\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0254\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0254\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0253\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0253\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0253\n",
      "Epoch: 153\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0253\n",
      "Epoch: 154\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0252\n",
      "Epoch: 155\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0252\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0252\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 4s 22ms/sample - loss: 0.0252\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0251\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0251\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0251\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0251\n",
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0251\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0250\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0250\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0250\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0250\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0249\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0249\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0249\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0249\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0249\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0248\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0248\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0248\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0247\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0247\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0247\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0246\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 17ms/sample - loss: 0.0246\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0246\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0246\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0246\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0246\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0246\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0245\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0245\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0244\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0244\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0244\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0245\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0245\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0244\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0244\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0243\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0244\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0244\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0243\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0243\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0242\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0242\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0242\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0243\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0242\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 19ms/sample - loss: 0.0241\n",
      "Epoch: 205\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0242\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0241\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0241\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0241\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0241\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0240\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0241\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0240\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0240\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0239\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0239\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0240\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0239\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 18ms/sample - loss: 0.0239\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0239\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0239\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0238\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0239\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 16ms/sample - loss: 0.0239\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0238\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0238\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0237\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0238\n",
      "Epoch: 229\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0237\n",
      "Epoch: 230\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0237\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0236\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0236\n",
      "Epoch: 235\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0236\n",
      "Epoch: 236\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0236\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0236\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0236\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0236\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0235\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0235\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0235\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0236\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0234\n",
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0235\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0234\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0234\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0235\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0234\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0234\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0234\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0234\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0233\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0233\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0233\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0233\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0233\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0233\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0233\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0232\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0231\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0232\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0232\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0232\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0232\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0232\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0231\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0231\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0230\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 14ms/sample - loss: 0.0231\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0231\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 15ms/sample - loss: 0.0230\n",
      "Epoch: 273\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0230\n",
      "Epoch: 274\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0230\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 3s 14ms/sample - loss: 0.0230\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0229\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0229\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0229\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0228\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0229\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0229\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0228\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0228\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0228\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0228\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0229\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0228\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0228\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0229\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0227\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0228\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0227\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0228\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 12ms/sample - loss: 0.0226\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0226\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0226\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0226\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0226\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0225\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0225\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0225\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0225\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0225\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0225\n",
      "Epoch: 305\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0224\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0224\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0224\n",
      "Epoch: 308\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0224\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0223\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0224\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0223\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 2s 13ms/sample - loss: 0.0224\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "134/180 [=====================>........] - ETA: 0s - loss: 0.0182"
     ]
    }
   ],
   "source": [
    "# oil static.py bi lstm \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='relu')))\n",
    "    model.add(Dense(1))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=2\n",
    "\tneurons=[5,4,2] \n",
    "\tn_epochs=2000\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff6bebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 13:54:40.269748: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-19 13:54:40.269774: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_1636/1744498523.py:27: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_1636/1744498523.py:263: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_1636/1744498523.py:167: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 13:54:40.729273: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 13:54:40.829215: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 13:54:40.894317: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 13:54:40.911301: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 19ms/sample\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 17ms/sample\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 79\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 80\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 136\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 153\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 154\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 155\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 205\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 229\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 230\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 235\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 236\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 273\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 274\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 305\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 308\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 314\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 315\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 316\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 317\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 318\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 319\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 320\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 321\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 322\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 323\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 324\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 325\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 326\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 327\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 328\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 329\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 330\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 331\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 332\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 333\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 334\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 335\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 336\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 337\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 338\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 339\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 340\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 341\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 342\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 343\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 344\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 345\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 346\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 347\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 348\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 349\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 350\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 351\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 352\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 353\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 354\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 355\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 356\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 357\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 358\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 359\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 360\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 361\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 362\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 363\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 364\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 365\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 366\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 367\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 368\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 369\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 370\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 371\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 372\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 373\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 374\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 375\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 376\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 377\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 378\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 379\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 380\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 381\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 382\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 383\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 384\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 385\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 386\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 387\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 388\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 389\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 390\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 391\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 392\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 393\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 394\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 395\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 396\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 397\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 398\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 399\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 400\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 401\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 402\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 403\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 404\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 405\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 406\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 407\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 408\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 409\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 410\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 411\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 412\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 413\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 414\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 415\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 416\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 417\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 418\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 419\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 420\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 421\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 422\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 423\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 424\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 17ms/sample\n",
      "Epoch: 425\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 426\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 427\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 428\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 429\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 430\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 431\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 432\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 433\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 434\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 435\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 436\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 437\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 438\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 439\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 440\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 441\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 442\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 443\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 444\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 445\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 446\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 447\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 448\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 449\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 450\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 451\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 452\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 453\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 454\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 455\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 456\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 457\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 458\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 459\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 460\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 461\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 462\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 463\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 464\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 465\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 466\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 467\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 468\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 469\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 470\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 471\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 472\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 473\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 474\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 475\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 476\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 477\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 478\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 479\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 480\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 481\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 482\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 483\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 484\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 485\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 486\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 487\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 488\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 489\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 490\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 491\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 492\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 493\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 494\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 495\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 496\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 497\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 498\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 499\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 500\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 501\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 502\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 503\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 504\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 505\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 506\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 507\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 508\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 509\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 510\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 511\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 512\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 513\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 514\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 515\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 516\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 517\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 518\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 519\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 520\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 521\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 522\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 523\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 524\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 525\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 526\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 527\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 528\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 529\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 530\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 531\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 532\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 533\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 534\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 535\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 536\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 537\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 538\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 539\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 540\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 541\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 542\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 543\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 544\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 545\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 546\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 547\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 548\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 549\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 550\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 551\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 552\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 553\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 554\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 555\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 556\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 557\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 558\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 559\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 560\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 561\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 562\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 563\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 564\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 565\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 566\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 567\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 568\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 569\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 570\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 571\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 572\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 573\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 574\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 575\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 576\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 577\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 578\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 579\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 580\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 581\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 582\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 583\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 584\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 585\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 586\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 587\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 588\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 589\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 590\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 591\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 592\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 593\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 594\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 595\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 596\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 597\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 598\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 599\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 600\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 601\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 602\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 603\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 604\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 605\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 606\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 607\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 608\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 609\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 610\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 611\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 612\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 613\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 614\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 615\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 616\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 617\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 618\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 619\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 620\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 621\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 622\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 623\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 624\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 625\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 626\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 627\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 628\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 629\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 630\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 631\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 632\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 633\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 634\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 635\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 636\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 637\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 638\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 639\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 640\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 641\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 642\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 643\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 644\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 645\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 646\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 647\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 648\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 649\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 650\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 651\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 652\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 653\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 654\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 655\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 656\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 657\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 658\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 659\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 660\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 661\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 662\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 663\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 664\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 665\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 666\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 667\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 668\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 669\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 670\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 671\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 672\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 673\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 674\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 675\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 676\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 677\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 678\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 679\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 680\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 681\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 682\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 683\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 684\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 685\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 686\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 687\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 688\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 689\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 690\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 691\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 692\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 693\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 694\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 695\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 696\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 697\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 698\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 699\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 700\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 701\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 702\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 703\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 704\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 705\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 706\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 707\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 708\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 709\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 710\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 711\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 712\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 713\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 714\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 715\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 716\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 717\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 718\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 719\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 720\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 721\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 722\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 723\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 724\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 725\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 726\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 727\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 728\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 729\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 730\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 731\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 732\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 733\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 734\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 735\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 736\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 737\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 738\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 739\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 740\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 741\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 742\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 743\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 744\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 745\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 746\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 747\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 748\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 749\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 750\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 751\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 752\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 753\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 754\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 755\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 756\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 757\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 758\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 759\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 760\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 761\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 762\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 763\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 764\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 765\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 766\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 767\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 768\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 769\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 770\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 771\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 772\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 773\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 774\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 775\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 776\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 777\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 778\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 779\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 780\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 781\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 782\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 783\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 784\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 785\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 786\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 787\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 788\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 789\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 790\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 791\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 792\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 793\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 794\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 795\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 796\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 797\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 798\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 799\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 800\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 801\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 802\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 803\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 804\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 805\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 806\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 807\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 808\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 809\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 810\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 811\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 812\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 813\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 814\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 815\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 816\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 817\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 818\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 819\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 820\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 821\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 822\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 823\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 824\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 825\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 826\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 827\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 828\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 829\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 830\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 831\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 832\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 833\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 834\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 835\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 836\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 837\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 838\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 839\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 840\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 841\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 842\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 843\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 844\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 845\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 846\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 847\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 848\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 849\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 850\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 851\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 852\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 853\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 854\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 855\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 856\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 857\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 858\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 859\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 860\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 861\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 862\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 863\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 864\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 865\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 866\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 867\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 868\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 869\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 870\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 871\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 872\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 873\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 874\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 875\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 876\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 877\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 878\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 879\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 880\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 881\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 882\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 883\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 884\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 885\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 886\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 887\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 888\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 889\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 890\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 891\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 892\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 893\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 894\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 895\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 896\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 897\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 898\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 899\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 900\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 901\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 902\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 903\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 904\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 905\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 906\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 907\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 908\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 909\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 910\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 911\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 912\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 913\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 914\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 915\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 916\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 917\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 918\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 919\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 920\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 921\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 922\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 923\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 924\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 925\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 926\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 927\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 928\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 929\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 930\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 931\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 932\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 933\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 934\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 935\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 936\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 937\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 938\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 939\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 940\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 941\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 942\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 943\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 944\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 945\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 946\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 947\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 948\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 949\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 950\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 951\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 952\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 953\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 954\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 955\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 956\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 957\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 958\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 959\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 960\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 961\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 962\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 963\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 964\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 965\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 966\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 967\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 968\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 969\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 970\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 971\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 972\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 973\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 974\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 975\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 976\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 977\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 978\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 979\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 980\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 981\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 982\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 983\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 984\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 985\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 986\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 987\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 988\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 989\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 990\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 991\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 992\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 993\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 994\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 995\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 996\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 997\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 998\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 999\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1000\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1001\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1002\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1003\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1004\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1005\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1006\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1007\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1008\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1009\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1010\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1011\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1012\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1013\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1014\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1015\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1016\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1017\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1018\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1019\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1020\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1021\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1022\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1023\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1024\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1025\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1026\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1027\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1028\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1029\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1030\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1031\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1032\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1033\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1034\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1035\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1036\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1037\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1038\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1039\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1040\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1041\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1042\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1043\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1044\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1045\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1046\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1047\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1048\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1049\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1050\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1051\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1052\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1053\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1054\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1055\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1056\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1057\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1058\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1059\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1060\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1061\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1062\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1063\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1064\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1065\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1066\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1067\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1068\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1069\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1070\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1071\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1072\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1073\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1074\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1075\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1076\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1077\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1078\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1079\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1080\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1081\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1082\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1083\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1084\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1085\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1086\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1087\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1088\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1089\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1090\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1091\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1092\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1093\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1094\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1095\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1096\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1097\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1098\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1099\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1100\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1101\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1102\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1103\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1104\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1105\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1106\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 1107\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1108\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1109\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1110\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1111\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1112\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1113\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1114\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1115\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1116\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1117\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1118\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1119\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1120\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1121\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1122\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1123\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1124\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1125\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1126\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1127\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1128\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1129\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1130\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1131\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1132\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1133\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1134\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1135\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1136\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1137\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1138\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1139\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1140\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1141\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1142\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1143\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1144\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1145\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1146\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1147\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1148\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1149\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1150\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1151\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1152\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1153\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1154\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1155\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1156\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1157\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1158\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1159\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1160\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1161\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1162\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1163\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1164\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1165\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1166\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1167\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1168\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1169\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1170\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1171\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1172\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1173\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1174\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1175\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1176\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1177\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1178\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1179\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1180\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1181\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1182\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1183\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1184\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1185\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1186\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1187\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1188\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1189\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1190\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1191\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1192\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1193\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1194\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1195\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1196\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1197\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1198\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1199\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1200\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1201\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1202\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1203\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1204\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1205\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1206\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1207\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1208\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1209\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1210\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1211\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1212\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1213\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1214\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1215\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1216\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1217\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1218\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1219\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1220\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1221\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1222\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1223\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1224\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1225\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1226\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1227\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1228\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1229\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1230\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1231\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1232\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1233\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1234\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1235\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1236\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1237\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1238\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1239\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1240\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1241\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1242\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1243\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1244\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1245\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1246\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1247\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1248\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1249\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1250\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1251\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1252\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1253\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1254\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1255\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1256\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1257\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1258\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1259\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1260\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1261\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1262\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1263\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1264\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1265\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1266\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1267\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1268\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1269\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1270\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1271\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1272\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1273\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1274\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1275\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1276\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1277\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1278\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1279\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1280\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1281\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1282\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1283\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1284\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1285\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1286\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1287\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1288\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1289\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1290\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1291\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1292\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1293\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1294\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1295\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1296\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1297\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1298\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1299\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1300\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1301\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1302\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1303\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1304\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1305\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1306\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1307\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1308\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1309\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1310\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1311\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1312\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1313\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1314\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1315\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1316\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1317\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1318\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1319\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1320\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1321\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1322\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1323\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1324\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1325\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1326\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1327\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1328\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1329\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1330\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1331\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1332\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1333\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1334\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1335\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1336\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1337\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1338\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1339\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1340\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1341\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1342\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1343\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1344\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1345\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1346\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1347\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1348\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1349\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1350\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1351\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1352\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1353\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1354\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1355\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1356\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1357\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1358\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1359\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1360\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1361\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1362\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1363\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1364\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1365\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1366\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1367\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1368\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1369\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1370\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1371\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1372\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1373\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1374\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1375\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1376\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1377\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1378\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1379\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1380\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1381\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1382\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1383\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1384\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1385\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1386\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1387\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1388\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1389\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1390\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1391\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1392\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1393\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1394\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1395\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1396\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1397\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1398\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: -2.2821e+00 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1399\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: -2.2821e+00 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Forecasting Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-04-19 14:53:50.634460: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=1, Predicted=10.780535, Expected=9.510000\n",
      "Month=2, Predicted=10.366289, Expected=9.796000\n",
      "Month=3, Predicted=10.696010, Expected=9.468500\n",
      "Month=4, Predicted=9.920429, Expected=9.672000\n",
      "Month=5, Predicted=10.277243, Expected=9.610000\n",
      "Month=6, Predicted=9.991014, Expected=9.240000\n",
      "Month=7, Predicted=9.938371, Expected=10.318300\n",
      "Month=8, Predicted=10.881598, Expected=8.974800\n",
      "Month=9, Predicted=9.722026, Expected=9.114000\n",
      "Month=10, Predicted=10.441286, Expected=9.300000\n",
      "Month=11, Predicted=9.604778, Expected=8.400000\n",
      "Month=12, Predicted=9.186351, Expected=9.300000\n",
      "Month=13, Predicted=10.270453, Expected=9.000000\n",
      "Month=14, Predicted=9.204223, Expected=9.300000\n",
      "Month=15, Predicted=9.853806, Expected=9.460000\n",
      "Month=16, Predicted=9.672862, Expected=9.145000\n",
      "Month=17, Predicted=9.672440, Expected=9.021000\n",
      "Month=18, Predicted=9.767014, Expected=8.750000\n",
      "Month=19, Predicted=9.440569, Expected=8.710000\n",
      "Month=20, Predicted=9.388639, Expected=8.370000\n",
      "Month=21, Predicted=9.039956, Expected=8.504000\n",
      "Month=22, Predicted=9.147571, Expected=9.819700\n",
      "Month=23, Predicted=9.986969, Expected=9.827300\n",
      "Month=24, Predicted=9.624807, Expected=9.929800\n",
      "Month=25, Predicted=10.359787, Expected=9.288000\n",
      "Month=26, Predicted=10.005594, Expected=9.300000\n",
      "Month=27, Predicted=10.196897, Expected=9.060000\n",
      "Month=28, Predicted=9.648857, Expected=8.835000\n",
      "Month=29, Predicted=9.577697, Expected=8.388600\n",
      "Month=30, Predicted=9.227453, Expected=8.400000\n",
      "Month=31, Predicted=9.169349, Expected=8.525000\n",
      "Month=32, Predicted=8.942393, Expected=8.250000\n",
      "Month=33, Predicted=8.783111, Expected=8.419000\n",
      "Month=34, Predicted=9.004072, Expected=9.455000\n",
      "Month=35, Predicted=9.620107, Expected=8.540000\n",
      "Month=36, Predicted=9.047184, Expected=9.455000\n",
      "Month=37, Predicted=10.435781, Expected=9.000000\n",
      "Month=38, Predicted=9.290324, Expected=9.599000\n",
      "Month=39, Predicted=10.256755, Expected=9.436000\n",
      "Month=40, Predicted=9.708106, Expected=9.539800\n",
      "Month=41, Predicted=10.081190, Expected=9.028600\n",
      "Month=42, Predicted=9.685165, Expected=8.932000\n",
      "Month=43, Predicted=9.793524, Expected=8.993000\n",
      "Month=44, Predicted=9.510804, Expected=8.678400\n",
      "Month=45, Predicted=9.271644, Expected=9.011100\n",
      "Month=46, Predicted=9.566957, Expected=9.630000\n",
      "Month=47, Predicted=9.705344, Expected=8.590400\n",
      "Month=48, Predicted=9.380290, Expected=9.736300\n",
      "Month=49, Predicted=10.790076, Expected=9.384500\n",
      "Month=50, Predicted=9.493376, Expected=9.947200\n",
      "Month=51, Predicted=10.531468, Expected=9.577100\n",
      "Month=52, Predicted=9.990814, Expected=9.117200\n",
      "Month=53, Predicted=10.054848, Expected=9.122500\n",
      "Month=54, Predicted=9.903478, Expected=8.880000\n",
      "Month=55, Predicted=9.474336, Expected=8.709200\n",
      "Month=56, Predicted=9.428290, Expected=8.428200\n",
      "Month=57, Predicted=9.153422, Expected=9.907600\n",
      "Month=58, Predicted=10.368926, Expected=9.145000\n",
      "Month=59, Predicted=9.327979, Expected=8.498000\n",
      "Month=60, Predicted=9.774877, Expected=9.362000\n",
      "Month=61, Predicted=10.148576, Expected=9.000000\n",
      "Month=62, Predicted=9.260019, Expected=9.455000\n",
      "Month=63, Predicted=10.050999, Expected=9.300000\n",
      "Month=64, Predicted=9.638753, Expected=8.990000\n",
      "Month=65, Predicted=9.718990, Expected=8.990000\n",
      "Month=66, Predicted=9.675558, Expected=8.790000\n",
      "Month=67, Predicted=9.367401, Expected=8.835000\n",
      "Month=68, Predicted=9.427838, Expected=8.700000\n",
      "Month=69, Predicted=9.217549, Expected=8.935000\n",
      "Month=70, Predicted=9.398169, Expected=8.835000\n",
      "Month=71, Predicted=9.211811, Expected=8.265000\n",
      "Month=72, Predicted=9.083632, Expected=8.835000\n",
      "Month=73, Predicted=9.580166, Expected=8.550000\n",
      "Month=74, Predicted=8.909092, Expected=8.680000\n",
      "Month=75, Predicted=9.289140, Expected=8.400000\n",
      "Month=76, Predicted=8.932041, Expected=8.525000\n",
      "Month=77, Predicted=9.133135, Expected=8.370000\n",
      "Month=78, Predicted=8.845861, Expected=7.890000\n",
      "Month=79, Predicted=8.700389, Expected=7.812000\n",
      "Month=80, Predicted=8.644584, Expected=7.620000\n",
      "Month=81, Predicted=8.243460, Expected=7.718000\n",
      "Month=82, Predicted=8.281050, Expected=8.323500\n",
      "Month=83, Predicted=8.574038, Expected=6.860000\n",
      "Month=84, Predicted=7.920576, Expected=8.308000\n",
      "Month=85, Predicted=9.648756, Expected=8.100000\n",
      "Month=86, Predicted=7.959495, Expected=8.525000\n",
      "Month=87, Predicted=9.008935, Expected=8.250000\n",
      "Month=88, Predicted=8.662039, Expected=8.215000\n",
      "Month=89, Predicted=8.893930, Expected=8.122600\n",
      "Month=90, Predicted=8.671055, Expected=7.778100\n",
      "Month=91, Predicted=8.483650, Expected=7.954600\n",
      "Month=92, Predicted=8.582359, Expected=7.420000\n",
      "Month=93, Predicted=8.037964, Expected=7.538300\n",
      "Month=94, Predicted=8.317427, Expected=7.905000\n",
      "Month=95, Predicted=8.148414, Expected=7.140000\n",
      "Month=96, Predicted=7.807050, Expected=8.432000\n",
      "Month=97, Predicted=9.268518, Expected=7.710000\n",
      "Month=98, Predicted=7.967467, Expected=7.967000\n",
      "Month=99, Predicted=8.827642, Expected=7.320000\n",
      "Month=100, Predicted=7.945485, Expected=7.502000\n",
      "Month=101, Predicted=8.332450, Expected=7.409000\n",
      "Month=102, Predicted=7.818637, Expected=7.200600\n",
      "Month=103, Predicted=7.841475, Expected=7.865000\n",
      "Month=104, Predicted=8.339928, Expected=6.690000\n",
      "Month=105, Predicted=7.540444, Expected=6.879400\n",
      "Month=106, Predicted=8.074215, Expected=7.440000\n",
      "Month=107, Predicted=7.625993, Expected=6.860000\n",
      "Month=108, Predicted=7.400759, Expected=7.595000\n",
      "Month=109, Predicted=8.338711, Expected=7.200000\n",
      "Month=110, Predicted=7.543961, Expected=7.130000\n",
      "Month=111, Predicted=7.903453, Expected=6.900000\n",
      "Month=112, Predicted=7.536489, Expected=7.130000\n",
      "Month=113, Predicted=7.658974, Expected=7.130000\n",
      "Month=114, Predicted=7.464382, Expected=6.840000\n",
      "Month=115, Predicted=7.460461, Expected=7.006000\n",
      "Month=116, Predicted=7.602325, Expected=6.780000\n",
      "Month=117, Predicted=7.262526, Expected=7.089600\n",
      "Month=118, Predicted=7.589051, Expected=6.882000\n",
      "Month=119, Predicted=7.262880, Expected=6.446700\n",
      "Month=120, Predicted=7.269158, Expected=6.882000\n",
      "Month=121, Predicted=7.531397, Expected=6.600000\n",
      "Month=122, Predicted=7.017118, Expected=6.820000\n",
      "Month=123, Predicted=7.388073, Expected=6.600000\n",
      "Month=124, Predicted=7.042097, Expected=6.820000\n",
      "Month=125, Predicted=7.346122, Expected=6.665000\n",
      "Month=126, Predicted=7.077404, Expected=6.450000\n",
      "Month=127, Predicted=7.133644, Expected=6.665000\n",
      "Month=128, Predicted=7.190019, Expected=6.450000\n",
      "Month=129, Predicted=6.893327, Expected=6.722100\n",
      "Month=130, Predicted=7.225543, Expected=6.820000\n",
      "Month=131, Predicted=7.080532, Expected=6.160000\n",
      "Month=132, Predicted=6.889176, Expected=6.820000\n",
      "Month=133, Predicted=7.624836, Expected=6.480000\n",
      "Month=134, Predicted=6.827961, Expected=6.596900\n",
      "Month=135, Predicted=7.248162, Expected=6.492000\n",
      "Month=136, Predicted=6.949112, Expected=6.510000\n",
      "Month=137, Predicted=7.052739, Expected=6.339500\n",
      "Month=138, Predicted=6.891290, Expected=6.001600\n",
      "Month=139, Predicted=6.753813, Expected=6.107000\n",
      "Month=140, Predicted=6.762058, Expected=5.790000\n",
      "Month=141, Predicted=6.355896, Expected=5.885000\n",
      "Month=142, Predicted=6.531193, Expected=7.280000\n",
      "Month=143, Predicted=7.468903, Expected=5.941600\n",
      "Month=144, Predicted=6.522935, Expected=6.810000\n",
      "Month=145, Predicted=8.100400, Expected=6.182000\n",
      "Month=146, Predicted=6.599783, Expected=6.293000\n",
      "Month=147, Predicted=7.137114, Expected=6.118600\n",
      "Month=148, Predicted=6.612716, Expected=6.138000\n",
      "Month=149, Predicted=6.725982, Expected=6.107000\n",
      "Month=150, Predicted=6.591352, Expected=5.913000\n",
      "Month=151, Predicted=6.507361, Expected=6.141100\n",
      "Month=152, Predicted=6.646418, Expected=6.248000\n",
      "Month=153, Predicted=6.532661, Expected=5.829700\n",
      "Month=154, Predicted=6.441449, Expected=6.829300\n",
      "Month=155, Predicted=7.433645, Expected=6.694400\n",
      "Month=156, Predicted=6.747494, Expected=7.726200\n",
      "Month=157, Predicted=8.119216, Expected=7.054400\n",
      "Month=158, Predicted=7.416430, Expected=7.268900\n",
      "Month=159, Predicted=8.107618, Expected=7.020000\n",
      "Month=160, Predicted=7.479120, Expected=6.510000\n",
      "Month=161, Predicted=7.394530, Expected=6.370500\n",
      "Month=162, Predicted=7.251094, Expected=5.730000\n",
      "Month=163, Predicted=6.607687, Expected=5.828000\n",
      "Month=164, Predicted=6.686026, Expected=5.580000\n",
      "Month=165, Predicted=6.117652, Expected=5.709900\n",
      "Month=166, Predicted=6.294833, Expected=6.696000\n",
      "Month=167, Predicted=6.893947, Expected=6.248000\n",
      "Month=168, Predicted=6.497725, Expected=6.711600\n",
      "Month=169, Predicted=7.370170, Expected=6.600100\n",
      "Month=170, Predicted=6.907436, Expected=7.508200\n",
      "Month=171, Predicted=7.893828, Expected=7.765000\n",
      "Month=172, Predicted=7.626462, Expected=7.285000\n",
      "Month=173, Predicted=7.826962, Expected=6.959500\n",
      "Month=174, Predicted=7.904966, Expected=6.450000\n",
      "Month=175, Predicted=7.383004, Expected=6.572000\n",
      "Month=176, Predicted=7.332908, Expected=6.600000\n",
      "Month=177, Predicted=6.990426, Expected=4.265300\n",
      "Month=178, Predicted=5.858967, Expected=7.367000\n",
      "Month=179, Predicted=9.161853, Expected=6.544000\n",
      "Month=180, Predicted=5.827778, Expected=6.940800\n",
      "Train RMSE: 0.86539\n",
      "Train RMSPE: 12.31491\n",
      "Train MAE: 0.74623\n",
      "Train MAPE: 9.99804\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=7.854559, Expected=6.786000\n",
      "Month=2, Predicted=7.128062, Expected=6.981200\n",
      "Month=3, Predicted=7.475143, Expected=6.756000\n",
      "Month=4, Predicted=7.217801, Expected=6.733200\n",
      "Month=5, Predicted=7.373955, Expected=6.671200\n",
      "Month=6, Predicted=7.197360, Expected=6.295600\n",
      "Month=7, Predicted=6.996655, Expected=6.432500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=8, Predicted=7.098306, Expected=6.153000\n",
      "Month=9, Predicted=6.680131, Expected=6.389500\n",
      "Month=10, Predicted=6.949557, Expected=7.192000\n",
      "Month=11, Predicted=7.325260, Expected=6.524000\n",
      "Month=12, Predicted=6.998735, Expected=7.238500\n",
      "Month=13, Predicted=8.046845, Expected=6.990000\n",
      "Month=14, Predicted=7.256397, Expected=7.254000\n",
      "Month=15, Predicted=7.783139, Expected=6.720000\n",
      "Month=16, Predicted=7.285586, Expected=6.944000\n",
      "Month=17, Predicted=7.683872, Expected=7.052500\n",
      "Month=18, Predicted=7.339035, Expected=6.690000\n",
      "Month=19, Predicted=7.274937, Expected=6.909900\n",
      "Month=20, Predicted=7.532596, Expected=6.819000\n",
      "Month=21, Predicted=7.202205, Expected=7.167200\n",
      "Month=22, Predicted=7.562211, Expected=7.254000\n",
      "Month=23, Predicted=7.470290, Expected=6.664000\n",
      "Month=24, Predicted=7.368618, Expected=7.393500\n",
      "Month=25, Predicted=8.144661, Expected=7.125000\n",
      "Month=26, Predicted=7.395941, Expected=7.347000\n",
      "Month=27, Predicted=7.905152, Expected=7.216500\n",
      "Month=28, Predicted=7.616316, Expected=7.254000\n",
      "Month=29, Predicted=7.804884, Expected=7.238500\n",
      "Month=30, Predicted=7.703865, Expected=6.990000\n",
      "Month=31, Predicted=7.600501, Expected=7.192000\n",
      "Month=32, Predicted=7.744950, Expected=6.900000\n",
      "Month=33, Predicted=7.387586, Expected=7.427300\n",
      "Month=34, Predicted=7.970135, Expected=7.300500\n",
      "Month=35, Predicted=7.585982, Expected=6.902000\n",
      "Month=36, Predicted=7.655350, Expected=7.409000\n",
      "Month=37, Predicted=8.031771, Expected=7.179000\n",
      "Month=38, Predicted=7.536105, Expected=7.424500\n",
      "Month=39, Predicted=7.947530, Expected=7.275000\n",
      "Month=40, Predicted=7.666952, Expected=7.316000\n",
      "Month=41, Predicted=7.877681, Expected=7.086300\n",
      "Month=42, Predicted=7.651685, Expected=7.020000\n",
      "Month=43, Predicted=7.683513, Expected=7.270500\n",
      "Month=44, Predicted=7.681267, Expected=7.168800\n",
      "Month=45, Predicted=7.535561, Expected=7.448600\n",
      "Month=46, Predicted=7.871393, Expected=7.440200\n",
      "Test RMSE: 0.61068\n",
      "Test RMSPE: 8.91814\n",
      "Test MAE: 0.52722\n",
      "Test MAPE: 7.64054\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# oil static.py bi lstm \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "# from keras.optimizers import sgd\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "import math \n",
    "\n",
    "# # learning rate schedule\n",
    "# def step_decay(epoch):\n",
    "# \tinitial_lrate = 0.1\n",
    "# \tdrop = 0.5\n",
    "# \tepochs_drop = 10.0\n",
    "# \tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "# \treturn lrate\n",
    " \n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='relu'  )))\n",
    "    model.add(Dropout(0.5))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Dense(1))\n",
    "    # Compile model\n",
    "#     sgd = sgd(lr=0.01, momentum=0.9 , decay=1e-6)\n",
    "#     model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # learning schedule callback\n",
    "#     lrate = LearningRateScheduler(step_decay)\n",
    "#     callbacks_list = [lrate]\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size  , verbose=2, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=2\n",
    "\tneurons=[ 8,7,6,4,2 ] \n",
    "\tn_epochs=1400\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "083d3691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 15:03:50.905242: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-19 15:03:50.905579: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_1636/2817990124.py:27: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_1636/2817990124.py:246: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_1636/2817990124.py:150: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 15:03:51.400409: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 15:03:51.513798: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 15:03:51.579135: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 15:03:51.597946: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 3s - loss: 0.0499 - acc: 0.0000e+00 - 3s/epoch - 16ms/sample\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0455 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0433 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0418 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0407 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0399 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0394 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0389 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0387 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0384 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0383 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0382 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0381 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0380 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0380 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0379 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0379 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0378 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0378 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0377 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0377 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0376 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0376 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0375 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0375 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0374 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0374 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0373 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0373 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0372 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0372 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0371 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0370 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0370 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0369 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0369 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0368 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0368 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0367 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0367 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0366 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0366 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0366 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0365 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0365 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0364 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0364 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0363 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0363 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0362 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0362 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0361 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0361 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0361 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0360 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0360 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0359 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0359 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0358 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0358 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0358 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0357 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0357 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0356 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0356 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0356 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0355 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0355 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0354 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0354 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0354 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0353 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0353 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0353 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0352 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0352 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0352 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0351 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0351 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 79\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0350 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 80\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0350 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0350 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0349 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0349 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0349 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0348 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0348 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0348 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0347 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0347 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0347 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0346 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0346 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0346 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0345 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0345 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0345 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0344 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0344 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0344 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0343 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0343 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0343 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0342 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0342 - acc: 0.0000e+00 - 3s/epoch - 15ms/sample\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0342 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0341 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0341 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0341 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0340 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0340 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0340 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0339 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0339 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0339 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0338 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0338 - acc: 0.0000e+00 - 3s/epoch - 14ms/sample\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0338 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0337 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0337 - acc: 0.0000e+00 - 2s/epoch - 14ms/sample\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0337 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0336 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0336 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0336 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0335 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0335 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0335 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0334 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0334 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0334 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0333 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0333 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0333 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0332 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0332 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0332 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 136\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0331 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0331 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0331 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0331 - acc: 0.0000e+00 - 2s/epoch - 13ms/sample\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0330 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0330 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0330 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0329 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0329 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0329 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0328 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0328 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0328 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0327 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0327 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0327 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0327 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 153\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0326 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 154\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0326 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 155\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0326 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0325 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0325 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0325 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0325 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0324 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0324 - acc: 0.0056 - 2s/epoch - 13ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0324 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0324 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0323 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0323 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0323 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0323 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0322 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0322 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0322 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0322 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0322 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0321 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0321 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0321 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0321 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0321 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0321 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0320 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0320 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0320 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0320 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0320 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0319 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0319 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0319 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0319 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0319 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0318 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0318 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0318 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0318 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0318 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0318 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0317 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0317 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0317 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0317 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0317 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0316 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0316 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0316 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0316 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0316 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 205\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0316 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0315 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0315 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0315 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0315 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0315 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0315 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0314 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0314 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0314 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0314 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0314 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0314 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0313 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0313 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0313 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0313 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0313 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0313 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0313 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0312 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0312 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0312 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0312 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 229\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0312 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 230\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0312 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0311 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0311 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0311 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0311 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 235\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0311 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 236\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0311 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0311 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0310 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0310 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0310 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0310 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0310 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0310 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0310 - acc: 0.0056 - 2s/epoch - 13ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0309 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0309 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0309 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0309 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0309 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0309 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0309 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0309 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0308 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0308 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0308 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0308 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0308 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0308 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0308 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0308 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0307 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0307 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0307 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0307 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0307 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0307 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0307 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0307 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0306 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0306 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0306 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0306 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 273\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0306 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 274\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0306 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0306 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0306 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0305 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0305 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0305 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0305 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0305 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0305 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0305 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0305 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0305 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0304 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0304 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0304 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0304 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0304 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0304 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0304 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0304 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0304 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0304 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0303 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0303 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0303 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0303 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0303 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0303 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0303 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0303 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0303 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 305\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0303 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0302 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0302 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 308\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0302 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0302 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0302 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0302 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0302 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0302 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 314\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0302 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 315\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0302 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 316\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0301 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 317\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0301 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 318\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0301 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 319\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0301 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 320\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0301 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 321\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0301 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 322\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0301 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 323\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0301 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 324\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0301 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 325\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0301 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 326\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0301 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 327\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0300 - acc: 0.0056 - 2s/epoch - 13ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 328\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0300 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 329\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0300 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 330\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0300 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 331\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0300 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 332\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0300 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 333\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0300 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 334\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0300 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 335\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0300 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 336\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0300 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 337\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0300 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 338\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0299 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 339\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0299 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 340\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0299 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 341\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0299 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 342\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0299 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 343\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0299 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 344\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0299 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 345\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0299 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 346\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0299 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 347\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0299 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 348\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0299 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 349\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0298 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 350\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0298 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 351\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0298 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 352\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0298 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 353\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0298 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 354\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0298 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 355\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0298 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 356\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0298 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 357\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0298 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 358\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0298 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 359\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0298 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 360\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0297 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 361\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0297 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 362\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0297 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 363\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0297 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 364\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0297 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 365\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0297 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 366\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0297 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 367\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0297 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 368\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0297 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 369\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0297 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 370\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0296 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 371\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0296 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 372\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0296 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 373\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0296 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 374\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0296 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 375\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0296 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 376\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0296 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 377\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0296 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 378\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0296 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 379\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0296 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 380\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0296 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 381\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0295 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 382\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0295 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 383\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0295 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 384\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0295 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 385\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0295 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 386\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0295 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 387\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0295 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 388\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0295 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 389\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0295 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 390\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0295 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 391\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0295 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 392\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0294 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 393\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0294 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 394\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0294 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 395\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0294 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 396\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0294 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 397\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0294 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 398\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0294 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 399\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0294 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 400\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0294 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 401\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0294 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 402\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0294 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 403\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0294 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 404\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0293 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 405\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0293 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 406\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0293 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 407\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0293 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 408\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0293 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 409\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0293 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 410\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0293 - acc: 0.0056 - 2s/epoch - 13ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 411\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0293 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 412\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0293 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 413\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0293 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 414\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0293 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 415\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0293 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 416\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 417\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 418\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 419\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 420\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 421\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 422\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 423\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 424\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 425\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 426\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 427\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 428\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0292 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 429\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 430\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 431\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 432\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 433\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 434\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 435\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 436\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 437\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 438\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 439\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 440\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 441\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 442\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0291 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 443\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 444\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 445\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 446\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 447\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 448\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 449\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 450\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 451\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 452\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 453\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 454\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 455\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 456\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 457\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 458\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0290 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 459\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 460\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 461\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 462\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 463\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 464\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 465\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 466\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 467\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 468\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 469\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 470\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 471\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 472\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 473\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 474\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 475\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 476\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0289 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 477\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 478\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 479\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 480\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 481\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 482\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 483\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 484\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 485\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 486\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 487\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 488\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 489\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 490\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 491\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 492\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 493\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 494\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 495\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0288 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 496\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 497\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 498\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 499\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 500\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 501\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 502\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 503\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 504\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 505\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 506\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 507\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 508\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 509\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 510\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 511\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 512\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 513\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 514\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 515\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 516\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0287 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 517\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 518\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 519\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 520\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 521\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 522\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 523\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 524\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 525\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 526\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 527\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 528\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 529\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 530\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 531\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 532\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 533\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 534\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 535\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0286 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 536\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 537\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0286 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 538\n",
      "Train on 180 samples\n",
      "180/180 - 24s - loss: 0.0285 - acc: 0.0056 - 24s/epoch - 134ms/sample\n",
      "Epoch: 539\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 15ms/sample\n",
      "Epoch: 540\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0285 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 541\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0285 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 542\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0285 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 543\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0285 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 544\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 16ms/sample\n",
      "Epoch: 545\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0285 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 546\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0285 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 547\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 16ms/sample\n",
      "Epoch: 548\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 16ms/sample\n",
      "Epoch: 549\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0285 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 550\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 551\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 552\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 553\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 554\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 555\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 15ms/sample\n",
      "Epoch: 556\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 557\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 558\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 15ms/sample\n",
      "Epoch: 559\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0285 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 560\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0285 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 561\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0284 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 562\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0284 - acc: 0.0056 - 3s/epoch - 15ms/sample\n",
      "Epoch: 563\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0284 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 564\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0284 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 565\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0284 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 566\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0284 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 567\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0284 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 568\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0284 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 569\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0284 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 570\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0284 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 571\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0284 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 572\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0284 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 573\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0284 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 574\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0284 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 575\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0284 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 576\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0284 - acc: 0.0056 - 3s/epoch - 14ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 577\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0284 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 578\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0284 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 579\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0284 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 580\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0284 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 581\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0284 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 582\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0284 - acc: 0.0056 - 3s/epoch - 15ms/sample\n",
      "Epoch: 583\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0284 - acc: 0.0056 - 3s/epoch - 15ms/sample\n",
      "Epoch: 584\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0284 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 585\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 586\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 587\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 588\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 589\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 590\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 591\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 592\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 593\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 594\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 595\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 596\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 597\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 598\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 599\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 600\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 601\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 602\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 603\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 604\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 605\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 606\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 607\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 608\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 609\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 610\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0283 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 611\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0283 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 612\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 613\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 614\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 615\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 616\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 617\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 618\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 619\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 620\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 621\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 622\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 623\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 624\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0282 - acc: 0.0056 - 3s/epoch - 16ms/sample\n",
      "Epoch: 625\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0282 - acc: 0.0056 - 3s/epoch - 16ms/sample\n",
      "Epoch: 626\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0282 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 627\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0282 - acc: 0.0056 - 3s/epoch - 15ms/sample\n",
      "Epoch: 628\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0282 - acc: 0.0056 - 3s/epoch - 17ms/sample\n",
      "Epoch: 629\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0282 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 630\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 631\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 632\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0282 - acc: 0.0056 - 3s/epoch - 15ms/sample\n",
      "Epoch: 633\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0282 - acc: 0.0056 - 3s/epoch - 17ms/sample\n",
      "Epoch: 634\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 635\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 636\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0282 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 637\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0282 - acc: 0.0056 - 3s/epoch - 15ms/sample\n",
      "Epoch: 638\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 639\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 640\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0282 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 641\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 642\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0281 - acc: 0.0056 - 3s/epoch - 15ms/sample\n",
      "Epoch: 643\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0281 - acc: 0.0056 - 3s/epoch - 16ms/sample\n",
      "Epoch: 644\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 645\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 646\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 647\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 648\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 649\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 650\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 651\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 652\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 653\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 654\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 655\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 656\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 657\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 658\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 659\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 660\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 661\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 662\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 663\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 664\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 665\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 666\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 667\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 668\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 669\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 670\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 671\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 672\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 673\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0281 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 674\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 675\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 676\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 677\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 678\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 679\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 680\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 681\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 682\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 683\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 684\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 685\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 686\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 687\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 688\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 689\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 690\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 691\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 692\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 693\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 694\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 695\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 696\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 697\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 698\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 699\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 700\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 701\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 702\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 703\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 704\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 705\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 706\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 707\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0280 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 708\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 709\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 710\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 711\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 712\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 713\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 714\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 715\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 716\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 717\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 718\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 719\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 720\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 721\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 722\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 723\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 724\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 725\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 726\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 727\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 728\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 729\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 730\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 731\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 732\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 733\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 734\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 735\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 736\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 737\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 738\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 739\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 740\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 741\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 742\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0279 - acc: 0.0056 - 2s/epoch - 13ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 743\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 744\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 745\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 746\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 747\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 748\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 749\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 750\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 751\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 752\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 753\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 754\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 755\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 756\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 757\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 758\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 759\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 760\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 761\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 762\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 763\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 764\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 765\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 766\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 767\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 768\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 769\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0278 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 770\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 771\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 772\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 773\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 774\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 775\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 776\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 777\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 778\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 779\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 780\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 781\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 782\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 783\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 784\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 785\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 786\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 787\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 788\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 789\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 790\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 791\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 792\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0277 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 793\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 794\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 795\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 796\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0276 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 797\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 798\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 799\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 800\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 801\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 802\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 803\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 804\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 805\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 806\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 807\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 808\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 809\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 810\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 811\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 812\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 813\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 814\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 815\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0276 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 816\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 817\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 818\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 819\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 820\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 821\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 822\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 823\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 824\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 825\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 826\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 827\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 828\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 829\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 830\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 831\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 832\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 833\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 834\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 835\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 836\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 837\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 838\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 839\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 840\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 841\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 842\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0275 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 843\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 844\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 845\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 846\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 847\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 848\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 849\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 850\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 851\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 852\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 853\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 854\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 855\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 856\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 857\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 858\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 859\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 860\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 861\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 862\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 863\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 864\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 865\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 866\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 867\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 868\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 869\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 870\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 871\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 872\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0274 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 873\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 874\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 875\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 876\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 877\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 878\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 879\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 880\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 881\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 882\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 883\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 884\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 885\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 886\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 887\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 888\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 889\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 890\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 891\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 892\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 893\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 894\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 895\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 896\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 897\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 898\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 899\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 900\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 901\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 902\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 903\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 904\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0273 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 905\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 906\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 907\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 908\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 909\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 910\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 911\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 912\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 913\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 914\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 915\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 916\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 917\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 918\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 919\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 920\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 921\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 922\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 923\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 924\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 925\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 926\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 927\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 928\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 929\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 930\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 931\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 932\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 933\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 934\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0272 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 935\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 936\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 937\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 938\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 939\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 940\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 941\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 942\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 943\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 944\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 945\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 946\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 947\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 948\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 949\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 950\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 951\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 952\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 953\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0271 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 954\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 955\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 956\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 957\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 958\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 959\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 960\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 961\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0271 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 962\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 963\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 964\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 965\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 966\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 967\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 968\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 969\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 970\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 971\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 972\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 973\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 974\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 975\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 976\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 977\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 978\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 979\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 980\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 981\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 982\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 983\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 984\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 985\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 986\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 987\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0270 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 988\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 989\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 990\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 991\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 992\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 993\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 994\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 995\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 996\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 997\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 998\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 999\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1000\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1001\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1002\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1003\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1004\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1005\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1006\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1007\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1008\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1009\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1010\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1011\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1012\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1013\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1014\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0269 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1015\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1016\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1017\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1018\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1019\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1020\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1021\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1022\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1023\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1024\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1025\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1026\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1027\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1028\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1029\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1030\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1031\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1032\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1033\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1034\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1035\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1036\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1037\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1038\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1039\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1040\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1041\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1042\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1043\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1044\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1045\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0268 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1046\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1047\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1048\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1049\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1050\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1051\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1052\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1053\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1054\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1055\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1056\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1057\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1058\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1059\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1060\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1061\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1062\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1063\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1064\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1065\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1066\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1067\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1068\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1069\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 1070\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1071\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1072\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1073\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1074\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1075\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1076\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1077\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1078\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1079\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1080\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1081\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1082\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1083\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0267 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 1084\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1085\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1086\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1087\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1088\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1089\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1090\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1091\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1092\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1093\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1094\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1095\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1096\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1097\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1098\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1099\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1100\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1101\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1102\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1103\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1104\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1105\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1106\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1107\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1108\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1109\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1110\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1111\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1112\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1113\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1114\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1115\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1116\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1117\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1118\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1119\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1120\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1121\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1122\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1123\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1124\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1125\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0266 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1126\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1127\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1128\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1129\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1130\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1131\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1132\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1133\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1134\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1135\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1136\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1137\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1138\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1139\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1140\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1141\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1142\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1143\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1144\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1145\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1146\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1147\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1148\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1149\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1150\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1151\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1152\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1153\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1154\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1155\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1156\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1157\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1158\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1159\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1160\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1161\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 12ms/sample\n",
      "Epoch: 1162\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1163\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1164\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0265 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1165\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0265 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1166\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1167\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0265 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1168\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1169\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1170\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0265 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1171\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1172\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1173\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1174\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1175\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1176\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1177\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1178\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1179\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1180\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1181\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1182\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1183\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1184\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1185\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1186\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1187\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1188\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1189\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1190\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1191\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1192\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1193\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1194\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1195\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1196\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1197\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1198\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1199\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1200\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1201\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1202\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1203\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1204\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1205\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1206\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1207\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1208\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1209\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1210\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1211\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1212\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1213\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1214\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1215\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1216\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1217\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0264 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1218\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1219\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1220\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1221\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1222\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1223\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1224\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1225\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1226\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1227\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1228\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1229\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1230\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1231\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1232\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1233\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1234\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1235\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1236\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1237\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1238\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1239\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1240\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1241\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1242\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1243\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1244\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1245\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1246\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1247\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1248\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1249\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1250\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1251\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1252\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1253\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1254\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1255\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1256\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1257\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1258\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1259\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1260\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1261\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1262\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1263\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1264\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1265\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1266\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0263 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1267\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1268\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1269\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1270\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1271\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1272\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1273\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1274\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1275\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1276\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1277\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1278\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1279\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1280\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1281\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1282\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1283\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1284\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1285\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1286\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1287\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1288\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1289\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1290\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1291\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1292\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1293\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1294\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1295\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1296\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1297\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1298\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1299\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1300\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1301\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1302\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1303\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1304\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1305\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1306\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1307\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1308\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1309\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1310\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1311\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1312\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1313\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1314\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1315\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1316\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0262 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1317\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1318\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1319\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1320\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1321\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1322\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1323\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1324\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1325\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0261 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1326\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1327\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1328\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1329\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0261 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1330\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1331\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1332\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1333\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1334\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1335\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1336\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1337\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1338\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1339\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1340\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1341\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1342\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1343\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1344\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1345\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1346\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0261 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1347\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1348\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1349\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1350\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1351\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1352\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1353\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1354\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1355\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1356\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1357\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1358\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1359\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1360\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1361\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1362\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1363\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1364\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1365\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1366\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1367\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0261 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1368\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1369\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1370\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1371\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0260 - acc: 0.0056 - 3s/epoch - 14ms/sample\n",
      "Epoch: 1372\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1373\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1374\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1375\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1376\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1377\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1378\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1379\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1380\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1381\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1382\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1383\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1384\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1385\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1386\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1387\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1388\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1389\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1390\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1391\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0260 - acc: 0.0056 - 3s/epoch - 15ms/sample\n",
      "Epoch: 1392\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1393\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1394\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1395\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Epoch: 1396\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1397\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 14ms/sample\n",
      "Epoch: 1398\n",
      "Train on 180 samples\n",
      "180/180 - 3s - loss: 0.0260 - acc: 0.0056 - 3s/epoch - 15ms/sample\n",
      "Epoch: 1399\n",
      "Train on 180 samples\n",
      "180/180 - 2s - loss: 0.0260 - acc: 0.0056 - 2s/epoch - 13ms/sample\n",
      "Forecasting Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-04-19 15:58:09.847243: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=1, Predicted=11.059890, Expected=9.510000\n",
      "Month=2, Predicted=10.727090, Expected=9.796000\n",
      "Month=3, Predicted=10.555650, Expected=9.468500\n",
      "Month=4, Predicted=10.372752, Expected=9.672000\n",
      "Month=5, Predicted=10.446553, Expected=9.610000\n",
      "Month=6, Predicted=10.317720, Expected=9.240000\n",
      "Month=7, Predicted=10.227810, Expected=10.318300\n",
      "Month=8, Predicted=10.822715, Expected=8.974800\n",
      "Month=9, Predicted=10.192207, Expected=9.114000\n",
      "Month=10, Predicted=9.904777, Expected=9.300000\n",
      "Month=11, Predicted=9.878707, Expected=8.400000\n",
      "Month=12, Predicted=9.742814, Expected=9.300000\n",
      "Month=13, Predicted=9.859054, Expected=9.000000\n",
      "Month=14, Predicted=9.964921, Expected=9.300000\n",
      "Month=15, Predicted=10.030287, Expected=9.460000\n",
      "Month=16, Predicted=10.001215, Expected=9.145000\n",
      "Month=17, Predicted=10.042533, Expected=9.021000\n",
      "Month=18, Predicted=9.931247, Expected=8.750000\n",
      "Month=19, Predicted=9.698501, Expected=8.710000\n",
      "Month=20, Predicted=9.577758, Expected=8.370000\n",
      "Month=21, Predicted=9.336918, Expected=8.504000\n",
      "Month=22, Predicted=9.309088, Expected=9.819700\n",
      "Month=23, Predicted=10.253657, Expected=9.827300\n",
      "Month=24, Predicted=10.729089, Expected=9.929800\n",
      "Month=25, Predicted=10.630618, Expected=9.288000\n",
      "Month=26, Predicted=10.417704, Expected=9.300000\n",
      "Month=27, Predicted=10.170412, Expected=9.060000\n",
      "Month=28, Predicted=9.955341, Expected=8.835000\n",
      "Month=29, Predicted=9.780382, Expected=8.388600\n",
      "Month=30, Predicted=9.430581, Expected=8.400000\n",
      "Month=31, Predicted=9.266122, Expected=8.525000\n",
      "Month=32, Predicted=9.211574, Expected=8.250000\n",
      "Month=33, Predicted=9.129714, Expected=8.419000\n",
      "Month=34, Predicted=9.197105, Expected=9.455000\n",
      "Month=35, Predicted=9.814272, Expected=8.540000\n",
      "Month=36, Predicted=9.660263, Expected=9.455000\n",
      "Month=37, Predicted=10.011675, Expected=9.000000\n",
      "Month=38, Predicted=10.013910, Expected=9.599000\n",
      "Month=39, Predicted=10.242265, Expected=9.436000\n",
      "Month=40, Predicted=10.318850, Expected=9.539800\n",
      "Month=41, Predicted=10.315129, Expected=9.028600\n",
      "Month=42, Predicted=10.070900, Expected=8.932000\n",
      "Month=43, Predicted=9.842912, Expected=8.993000\n",
      "Month=44, Predicted=9.764444, Expected=8.678400\n",
      "Month=45, Predicted=9.603517, Expected=9.011100\n",
      "Month=46, Predicted=9.731768, Expected=9.630000\n",
      "Month=47, Predicted=9.959043, Expected=8.590400\n",
      "Month=48, Predicted=9.963786, Expected=9.736300\n",
      "Month=49, Predicted=10.277479, Expected=9.384500\n",
      "Month=50, Predicted=10.348881, Expected=9.947200\n",
      "Month=51, Predicted=10.590492, Expected=9.577100\n",
      "Month=52, Predicted=10.575494, Expected=9.117200\n",
      "Month=53, Predicted=10.164050, Expected=9.122500\n",
      "Month=54, Predicted=9.991839, Expected=8.880000\n",
      "Month=55, Predicted=9.778999, Expected=8.709200\n",
      "Month=56, Predicted=9.630627, Expected=8.428200\n",
      "Month=57, Predicted=9.389800, Expected=9.907600\n",
      "Month=58, Predicted=10.323819, Expected=9.145000\n",
      "Month=59, Predicted=10.164548, Expected=8.498000\n",
      "Month=60, Predicted=9.575462, Expected=9.362000\n",
      "Month=61, Predicted=9.929116, Expected=9.000000\n",
      "Month=62, Predicted=9.987809, Expected=9.455000\n",
      "Month=63, Predicted=10.138624, Expected=9.300000\n",
      "Month=64, Predicted=10.136565, Expected=8.990000\n",
      "Month=65, Predicted=9.963122, Expected=8.990000\n",
      "Month=66, Predicted=9.846697, Expected=8.790000\n",
      "Month=67, Predicted=9.666038, Expected=8.835000\n",
      "Month=68, Predicted=9.648849, Expected=8.700000\n",
      "Month=69, Predicted=9.520205, Expected=8.935000\n",
      "Month=70, Predicted=9.639546, Expected=8.835000\n",
      "Month=71, Predicted=9.561745, Expected=8.265000\n",
      "Month=72, Predicted=9.360734, Expected=8.835000\n",
      "Month=73, Predicted=9.492798, Expected=8.550000\n",
      "Month=74, Predicted=9.497674, Expected=8.680000\n",
      "Month=75, Predicted=9.476766, Expected=8.400000\n",
      "Month=76, Predicted=9.281551, Expected=8.525000\n",
      "Month=77, Predicted=9.322842, Expected=8.370000\n",
      "Month=78, Predicted=9.169784, Expected=7.890000\n",
      "Month=79, Predicted=8.944274, Expected=7.812000\n",
      "Month=80, Predicted=8.714919, Expected=7.620000\n",
      "Month=81, Predicted=8.516503, Expected=7.718000\n",
      "Month=82, Predicted=8.505265, Expected=8.323500\n",
      "Month=83, Predicted=8.735264, Expected=6.860000\n",
      "Month=84, Predicted=8.504380, Expected=8.308000\n",
      "Month=85, Predicted=8.870176, Expected=8.100000\n",
      "Month=86, Predicted=9.031675, Expected=8.525000\n",
      "Month=87, Predicted=9.179846, Expected=8.250000\n",
      "Month=88, Predicted=9.164615, Expected=8.215000\n",
      "Month=89, Predicted=9.081242, Expected=8.122600\n",
      "Month=90, Predicted=8.950572, Expected=7.778100\n",
      "Month=91, Predicted=8.758094, Expected=7.954600\n",
      "Month=92, Predicted=8.743018, Expected=7.420000\n",
      "Month=93, Predicted=8.473813, Expected=7.538300\n",
      "Month=94, Predicted=8.366518, Expected=7.905000\n",
      "Month=95, Predicted=8.400203, Expected=7.140000\n",
      "Month=96, Predicted=8.433168, Expected=8.432000\n",
      "Month=97, Predicted=8.952076, Expected=7.710000\n",
      "Month=98, Predicted=8.739053, Expected=7.967000\n",
      "Month=99, Predicted=8.740642, Expected=7.320000\n",
      "Month=100, Predicted=8.481571, Expected=7.502000\n",
      "Month=101, Predicted=8.306551, Expected=7.409000\n",
      "Month=102, Predicted=8.145297, Expected=7.200600\n",
      "Month=103, Predicted=8.109864, Expected=7.865000\n",
      "Month=104, Predicted=8.436224, Expected=6.690000\n",
      "Month=105, Predicted=8.105189, Expected=6.879400\n",
      "Month=106, Predicted=7.657491, Expected=7.440000\n",
      "Month=107, Predicted=7.810037, Expected=6.860000\n",
      "Month=108, Predicted=7.987100, Expected=7.595000\n",
      "Month=109, Predicted=8.197397, Expected=7.200000\n",
      "Month=110, Predicted=8.208865, Expected=7.130000\n",
      "Month=111, Predicted=8.025230, Expected=6.900000\n",
      "Month=112, Predicted=7.814545, Expected=7.130000\n",
      "Month=113, Predicted=7.870663, Expected=7.130000\n",
      "Month=114, Predicted=7.787210, Expected=6.840000\n",
      "Month=115, Predicted=7.768298, Expected=7.006000\n",
      "Month=116, Predicted=7.788654, Expected=6.780000\n",
      "Month=117, Predicted=7.613677, Expected=7.089600\n",
      "Month=118, Predicted=7.796082, Expected=6.882000\n",
      "Month=119, Predicted=7.695372, Expected=6.446700\n",
      "Month=120, Predicted=7.483123, Expected=6.882000\n",
      "Month=121, Predicted=7.582415, Expected=6.600000\n",
      "Month=122, Predicted=7.523013, Expected=6.820000\n",
      "Month=123, Predicted=7.578465, Expected=6.600000\n",
      "Month=124, Predicted=7.416996, Expected=6.820000\n",
      "Month=125, Predicted=7.561907, Expected=6.665000\n",
      "Month=126, Predicted=7.434405, Expected=6.450000\n",
      "Month=127, Predicted=7.376961, Expected=6.665000\n",
      "Month=128, Predicted=7.407508, Expected=6.450000\n",
      "Month=129, Predicted=7.264108, Expected=6.722100\n",
      "Month=130, Predicted=7.440473, Expected=6.820000\n",
      "Month=131, Predicted=7.402793, Expected=6.160000\n",
      "Month=132, Predicted=7.301902, Expected=6.820000\n",
      "Month=133, Predicted=7.445643, Expected=6.480000\n",
      "Month=134, Predicted=7.463855, Expected=6.596900\n",
      "Month=135, Predicted=7.409039, Expected=6.492000\n",
      "Month=136, Predicted=7.262357, Expected=6.510000\n",
      "Month=137, Predicted=7.306275, Expected=6.339500\n",
      "Month=138, Predicted=7.191710, Expected=6.001600\n",
      "Month=139, Predicted=6.990178, Expected=6.107000\n",
      "Month=140, Predicted=6.923576, Expected=5.790000\n",
      "Month=141, Predicted=6.703521, Expected=5.885000\n",
      "Month=142, Predicted=6.702551, Expected=7.280000\n",
      "Month=143, Predicted=7.722713, Expected=5.941600\n",
      "Month=144, Predicted=7.066307, Expected=6.810000\n",
      "Month=145, Predicted=7.371938, Expected=6.182000\n",
      "Month=146, Predicted=7.262115, Expected=6.293000\n",
      "Month=147, Predicted=7.125310, Expected=6.118600\n",
      "Month=148, Predicted=6.936623, Expected=6.138000\n",
      "Month=149, Predicted=6.956577, Expected=6.107000\n",
      "Month=150, Predicted=6.876955, Expected=5.913000\n",
      "Month=151, Predicted=6.796122, Expected=6.141100\n",
      "Month=152, Predicted=6.871152, Expected=6.248000\n",
      "Month=153, Predicted=6.834326, Expected=5.829700\n",
      "Month=154, Predicted=6.809791, Expected=6.829300\n",
      "Month=155, Predicted=7.355027, Expected=6.694400\n",
      "Month=156, Predicted=7.610679, Expected=7.726200\n",
      "Month=157, Predicted=8.186353, Expected=7.054400\n",
      "Month=158, Predicted=8.112026, Expected=7.268900\n",
      "Month=159, Predicted=8.060430, Expected=7.020000\n",
      "Month=160, Predicted=7.859150, Expected=6.510000\n",
      "Month=161, Predicted=7.579323, Expected=6.370500\n",
      "Month=162, Predicted=7.297680, Expected=5.730000\n",
      "Month=163, Predicted=6.859803, Expected=5.828000\n",
      "Month=164, Predicted=6.665306, Expected=5.580000\n",
      "Month=165, Predicted=6.450752, Expected=5.709900\n",
      "Month=166, Predicted=6.498308, Expected=6.696000\n",
      "Month=167, Predicted=7.055177, Expected=6.248000\n",
      "Month=168, Predicted=7.251027, Expected=6.711600\n",
      "Month=169, Predicted=7.402768, Expected=6.600100\n",
      "Month=170, Predicted=7.409567, Expected=7.508200\n",
      "Month=171, Predicted=7.979013, Expected=7.765000\n",
      "Month=172, Predicted=8.599092, Expected=7.285000\n",
      "Month=173, Predicted=8.306857, Expected=6.959500\n",
      "Month=174, Predicted=7.955087, Expected=6.450000\n",
      "Month=175, Predicted=7.517098, Expected=6.572000\n",
      "Month=176, Predicted=7.397843, Expected=6.600000\n",
      "Month=177, Predicted=7.283240, Expected=4.265300\n",
      "Month=178, Predicted=6.759057, Expected=7.367000\n",
      "Month=179, Predicted=7.843997, Expected=6.544000\n",
      "Month=180, Predicted=7.575594, Expected=6.940800\n",
      "Train RMSE: 0.98168\n",
      "Train RMSPE: 13.88459\n",
      "Train MAE: 0.89693\n",
      "Train MAPE: 12.01471\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=7.655165, Expected=6.786000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=2, Predicted=7.595903, Expected=6.981200\n",
      "Month=3, Predicted=7.711610, Expected=6.756000\n",
      "Month=4, Predicted=7.581459, Expected=6.733200\n",
      "Month=5, Predicted=7.584317, Expected=6.671200\n",
      "Month=6, Predicted=7.477405, Expected=6.295600\n",
      "Month=7, Predicted=7.286414, Expected=6.432500\n",
      "Month=8, Predicted=7.241463, Expected=6.153000\n",
      "Month=9, Predicted=7.032153, Expected=6.389500\n",
      "Month=10, Predicted=7.140603, Expected=7.192000\n",
      "Month=11, Predicted=7.503144, Expected=6.524000\n",
      "Month=12, Predicted=7.635495, Expected=7.238500\n",
      "Month=13, Predicted=7.846454, Expected=6.990000\n",
      "Month=14, Predicted=7.933062, Expected=7.254000\n",
      "Month=15, Predicted=7.985824, Expected=6.720000\n",
      "Month=16, Predicted=7.788853, Expected=6.944000\n",
      "Month=17, Predicted=7.730995, Expected=7.052500\n",
      "Month=18, Predicted=7.639119, Expected=6.690000\n",
      "Month=19, Predicted=7.632728, Expected=6.909900\n",
      "Month=20, Predicted=7.683646, Expected=6.819000\n",
      "Month=21, Predicted=7.542401, Expected=7.167200\n",
      "Month=22, Predicted=7.801210, Expected=7.254000\n",
      "Month=23, Predicted=7.856105, Expected=6.664000\n",
      "Month=24, Predicted=7.759876, Expected=7.393500\n",
      "Month=25, Predicted=7.997633, Expected=7.125000\n",
      "Month=26, Predicted=8.077968, Expected=7.347000\n",
      "Month=27, Predicted=8.101415, Expected=7.216500\n",
      "Month=28, Predicted=7.967775, Expected=7.254000\n",
      "Month=29, Predicted=8.049816, Expected=7.238500\n",
      "Month=30, Predicted=7.990802, Expected=6.990000\n",
      "Month=31, Predicted=7.899013, Expected=7.192000\n",
      "Month=32, Predicted=7.949659, Expected=6.900000\n",
      "Month=33, Predicted=7.772758, Expected=7.427300\n",
      "Month=34, Predicted=8.070357, Expected=7.300500\n",
      "Month=35, Predicted=8.143229, Expected=6.902000\n",
      "Month=36, Predicted=7.914503, Expected=7.409000\n",
      "Month=37, Predicted=8.079129, Expected=7.179000\n",
      "Month=38, Predicted=8.082448, Expected=7.424500\n",
      "Month=39, Predicted=8.158650, Expected=7.275000\n",
      "Month=40, Predicted=8.036606, Expected=7.316000\n",
      "Month=41, Predicted=8.116565, Expected=7.086300\n",
      "Month=42, Predicted=7.965573, Expected=7.020000\n",
      "Month=43, Predicted=7.891889, Expected=7.270500\n",
      "Month=44, Predicted=7.935559, Expected=7.168800\n",
      "Month=45, Predicted=7.894602, Expected=7.448600\n",
      "Month=46, Predicted=8.118009, Expected=7.440200\n",
      "Test RMSE: 0.82184\n",
      "Test RMSPE: 11.93900\n",
      "Test MAE: 0.78306\n",
      "Test MAPE: 11.27935\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# oil static.py bi lstm \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "# from keras.optimizers import sgd\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='sigmoid'  )))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size  , verbose=2, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=2\n",
    "\tneurons=[ 8,7,6,4,2 ] \n",
    "\tn_epochs=1400\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfb12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Metal device set to: Apple M1\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 18:02:54.643988: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-19 18:02:54.644046: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_4472/1957291093.py:27: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_4472/1957291093.py:249: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_4472/1957291093.py:153: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "2022-04-19 18:02:54.843503: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-19 18:02:54.843527: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 18:02:55.576323: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-19 18:02:55.576657: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 18:02:55.621197: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 18:02:55.701267: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 18:02:55.708860: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 8s 40ms/sample - loss: 0.0551 - acc: 0.0000e+00\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0481 - acc: 0.0000e+00\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0476 - acc: 0.0000e+00\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0458 - acc: 0.0000e+00\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0409 - acc: 0.0000e+00\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0389 - acc: 0.0000e+00\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0379 - acc: 0.0000e+00\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0372 - acc: 0.0056\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0366 - acc: 0.0056\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0361 - acc: 0.0111\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0356 - acc: 0.0111\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0352 - acc: 0.0222\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0349 - acc: 0.0333\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0346 - acc: 0.0389\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0343 - acc: 0.0444\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0611\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0338 - acc: 0.0778\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0335 - acc: 0.1167\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0333 - acc: 0.1444\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0331 - acc: 0.1444\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0329 - acc: 0.1444\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0328 - acc: 0.1500\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.1500\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0326 - acc: 0.1500\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0325 - acc: 0.1444\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0324 - acc: 0.1389\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0323 - acc: 0.1333\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0322 - acc: 0.1333\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0321 - acc: 0.1333\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0320 - acc: 0.1278\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0319 - acc: 0.1278\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0318 - acc: 0.1167\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.1167\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0316 - acc: 0.1167\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.1167\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.1333\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.1333\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.1333\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0312 - acc: 0.1333\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0310 - acc: 0.1389\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0309 - acc: 0.1444\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.1500\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.1556\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.1611\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.1500\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0299 - acc: 0.1500\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0294 - acc: 0.1444\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0289 - acc: 0.1333\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0285 - acc: 0.1278\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0282 - acc: 0.1278\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0279 - acc: 0.1167\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0277 - acc: 0.1222\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0275 - acc: 0.1222\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0273 - acc: 0.1222\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0271 - acc: 0.1222\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0269 - acc: 0.1278\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0268 - acc: 0.1278\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0266 - acc: 0.1389\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0265 - acc: 0.1444\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0263 - acc: 0.1556\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0262 - acc: 0.1556\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0261 - acc: 0.1556\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0260 - acc: 0.1500\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0259 - acc: 0.1500\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0258 - acc: 0.1500\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0257 - acc: 0.1556\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0256 - acc: 0.1556\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0255 - acc: 0.1556\n",
      "Epoch: 68\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0254 - acc: 0.1500\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0253 - acc: 0.1500\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0253 - acc: 0.1389\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0252 - acc: 0.1389\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0251 - acc: 0.1389\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0251 - acc: 0.1333\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0250 - acc: 0.1333\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0249 - acc: 0.1389\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0249 - acc: 0.1389\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0248 - acc: 0.1389\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0248 - acc: 0.1333\n",
      "Epoch: 79\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0247 - acc: 0.1333\n",
      "Epoch: 80\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0246 - acc: 0.1333\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0246 - acc: 0.1278\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0245 - acc: 0.1278\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0245 - acc: 0.1278\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0244 - acc: 0.1278\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      " 75/180 [===========>..................] - ETA: 4s - loss: 0.0244 - acc: 0.1333"
     ]
    }
   ],
   "source": [
    "# oil static.py bi lstm \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "# from keras.optimizers import sgd\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(32, return_sequences = True  , input_shape = (batch_size , X.shape[1],1))))\n",
    "    model.add(Bidirectional(LSTM(32, return_sequences = True  )))\n",
    "    model.add(Bidirectional(LSTM(32 ,activation='softmax' )))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10 ))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size  , verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=2\n",
    "\tneurons=[ 5,4,2 ] \n",
    "\tn_epochs=800\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90fbfbdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:06:51.359763: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-20 13:06:51.359797: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_8732/173332726.py:27: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 48>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m concatenate\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[0;32m---> 48\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_train.shape: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[43mx_train\u001B[49m\u001B[38;5;241m.\u001B[39mshape))\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparser\u001B[39m(x):\n\u001B[1;32m     51\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m datetime\u001B[38;5;241m.\u001B[39mstrptime(x, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9c83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
