{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b1bd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow has access to the following devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "\n",
    "# See TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db05109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Metal device set to: Apple M1\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:93: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 19:33:28.559086: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-19 19:33:28.559142: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_5282/1926739007.py:27: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_5282/1926739007.py:249: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_5282/1926739007.py:153: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "2022-04-19 19:33:28.736171: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-19 19:33:28.736191: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 19:33:29.471578: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-19 19:33:29.471928: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 19:33:29.516644: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 19:33:29.593746: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 19:33:29.601352: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0546 - acc: 0.0000e+00\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0480 - acc: 0.0000e+00\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0471 - acc: 0.0000e+00\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0444 - acc: 0.0056\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0402 - acc: 0.0333\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0385 - acc: 0.0000e+00\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0376 - acc: 0.0000e+00\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0368 - acc: 0.0000e+00\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0362 - acc: 0.0000e+00\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0356 - acc: 0.0000e+00\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0352 - acc: 0.0000e+00\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0349 - acc: 0.0000e+00\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0346 - acc: 0.0000e+00\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0343 - acc: 0.0000e+00\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0341 - acc: 0.0000e+00\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0339 - acc: 0.0000e+00\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0338 - acc: 0.0000e+00\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0000e+00\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0335 - acc: 0.0000e+00\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0334 - acc: 0.0000e+00\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0333 - acc: 0.0000e+00\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0332 - acc: 0.0000e+00\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0331 - acc: 0.0000e+00\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0330 - acc: 0.0000e+00\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0329 - acc: 0.0000e+00\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0328 - acc: 0.0000e+00\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0327 - acc: 0.0000e+00\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0326 - acc: 0.0000e+00\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0325 - acc: 0.0000e+00\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0324 - acc: 0.0000e+00\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0323 - acc: 0.0000e+00\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0322 - acc: 0.0000e+00\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0321 - acc: 0.0000e+00\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0319 - acc: 0.0000e+00\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0317 - acc: 0.0000e+00\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0315 - acc: 0.0000e+00\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0312 - acc: 0.0000e+00\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0000e+00\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0303 - acc: 0.0056\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0300 - acc: 0.0056\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0297 - acc: 0.0056\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0295 - acc: 0.0056\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0292 - acc: 0.0111\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0291 - acc: 0.0111\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0289 - acc: 0.0167\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0287 - acc: 0.0222\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0286 - acc: 0.0222\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0284 - acc: 0.0167\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0283 - acc: 0.0111\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0281 - acc: 0.0167\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0280 - acc: 0.0167\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0279 - acc: 0.0222\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0277 - acc: 0.0167\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0276 - acc: 0.0167\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0275 - acc: 0.0167\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0273 - acc: 0.0167\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0272 - acc: 0.0167\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0271 - acc: 0.0111\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0269 - acc: 0.0056\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0268 - acc: 0.0056\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0267 - acc: 0.0056\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0266 - acc: 0.0056\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0265 - acc: 0.0056\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0264 - acc: 0.0000e+00\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0263 - acc: 0.0000e+00\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0262 - acc: 0.0000e+00\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0262 - acc: 0.0000e+00\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0261 - acc: 0.0000e+00\n",
      "Epoch: 68\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0260 - acc: 0.0000e+00\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0259 - acc: 0.0000e+00\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0259 - acc: 0.0000e+00\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0258 - acc: 0.0000e+00\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0257 - acc: 0.0000e+00\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0256 - acc: 0.0000e+00\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0256 - acc: 0.0000e+00\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0255 - acc: 0.0000e+00\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0254 - acc: 0.0000e+00\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0254 - acc: 0.0000e+00\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0253 - acc: 0.0000e+00\n",
      "Epoch: 79\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0252 - acc: 0.0000e+00\n",
      "Epoch: 80\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0252 - acc: 0.0000e+00\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0251 - acc: 0.0000e+00\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0250 - acc: 0.0000e+00\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0250 - acc: 0.0000e+00\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0249 - acc: 0.0056\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0248 - acc: 0.0056\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0248 - acc: 0.0056\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0247 - acc: 0.0056\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0246 - acc: 0.0056\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0246 - acc: 0.0056\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0245 - acc: 0.0111\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0244 - acc: 0.0111\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0244 - acc: 0.0222\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0243 - acc: 0.0278\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0243 - acc: 0.0278\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0242 - acc: 0.0278\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0241 - acc: 0.0278\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0241 - acc: 0.0333\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0240 - acc: 0.0444\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0240 - acc: 0.0500\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0239 - acc: 0.0556\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0238 - acc: 0.0611\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0238 - acc: 0.0611\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0237 - acc: 0.0556\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0236 - acc: 0.0556\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0236 - acc: 0.0500\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0235 - acc: 0.0500\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0235 - acc: 0.0500\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0234 - acc: 0.0500\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0234 - acc: 0.0500\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0234 - acc: 0.0500\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0233 - acc: 0.0444\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0233 - acc: 0.0333\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0233 - acc: 0.0389\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0232 - acc: 0.0389\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0232 - acc: 0.0389\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0231 - acc: 0.0389\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0231 - acc: 0.0389\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0231 - acc: 0.0389\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0231 - acc: 0.0389\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0230 - acc: 0.0444\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0230 - acc: 0.0389\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0230 - acc: 0.0389\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0229 - acc: 0.0389\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0229 - acc: 0.0389\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0229 - acc: 0.0444\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0228 - acc: 0.0444\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0228 - acc: 0.0444\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0228 - acc: 0.0444\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0228 - acc: 0.0500\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0227 - acc: 0.0500\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0228 - acc: 0.0611\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0226 - acc: 0.0556\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0227 - acc: 0.0556\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0226 - acc: 0.0556\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0228 - acc: 0.0667\n",
      "Epoch: 136\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0228 - acc: 0.0667\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0225 - acc: 0.0611\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0226 - acc: 0.0722\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0227 - acc: 0.0722\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0229 - acc: 0.0778\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0227 - acc: 0.0722\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0229 - acc: 0.0556\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0221 - acc: 0.0500\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0221 - acc: 0.0444\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0221 - acc: 0.0444\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0220 - acc: 0.0444\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0222 - acc: 0.0444\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0222 - acc: 0.0611\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0221 - acc: 0.0500\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0223 - acc: 0.0556\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0218 - acc: 0.0556\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0220 - acc: 0.0667\n",
      "Epoch: 153\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0217 - acc: 0.0611\n",
      "Epoch: 154\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0217 - acc: 0.0500\n",
      "Epoch: 155\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0217 - acc: 0.0500\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0216 - acc: 0.0556\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0218 - acc: 0.0611\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0219 - acc: 0.0611\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0219 - acc: 0.0778\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0216 - acc: 0.0833\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0215 - acc: 0.0778\n",
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0213 - acc: 0.0667\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0212 - acc: 0.0556\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0211 - acc: 0.0556\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0211 - acc: 0.0556\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0210 - acc: 0.0556\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0210 - acc: 0.0667\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0209 - acc: 0.0722\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0209 - acc: 0.0722\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0209 - acc: 0.0778\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0207 - acc: 0.0778\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0207 - acc: 0.0722\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0206 - acc: 0.0722\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0206 - acc: 0.0667\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0204 - acc: 0.0722\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0204 - acc: 0.0778\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0202 - acc: 0.0778\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0202 - acc: 0.0778\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0200 - acc: 0.0833\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0200 - acc: 0.0944\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0199 - acc: 0.0944\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0198 - acc: 0.1111\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0198 - acc: 0.1056\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0197 - acc: 0.1111\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0197 - acc: 0.1000\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0195 - acc: 0.1111\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0195 - acc: 0.1000\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0193 - acc: 0.1056\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0193 - acc: 0.1111\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0191 - acc: 0.1111\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0203 - acc: 0.1000\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0207 - acc: 0.1000\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0199 - acc: 0.1278\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0188 - acc: 0.1167\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0186 - acc: 0.1111\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0185 - acc: 0.1111\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0185 - acc: 0.1056\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0186 - acc: 0.1222\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0186 - acc: 0.1000\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0189 - acc: 0.1000\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0191 - acc: 0.1056\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0192 - acc: 0.1000\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0185 - acc: 0.1222\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0181 - acc: 0.1222\n",
      "Epoch: 205\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0181 - acc: 0.1111\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0181 - acc: 0.1278\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0182 - acc: 0.1278\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0181 - acc: 0.1167\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0180 - acc: 0.1222\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0180 - acc: 0.1278\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0179 - acc: 0.1222\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0178 - acc: 0.1111\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0177 - acc: 0.0944\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0176 - acc: 0.0944\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0175 - acc: 0.0944\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0174 - acc: 0.0944\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0174 - acc: 0.0889\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0175 - acc: 0.1000\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0174 - acc: 0.1000\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0178 - acc: 0.0889\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0175 - acc: 0.0833\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0176 - acc: 0.0833\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0173 - acc: 0.1056\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0170 - acc: 0.1000\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0168 - acc: 0.0944\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0168 - acc: 0.1000\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0168 - acc: 0.1000\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0169 - acc: 0.1056\n",
      "Epoch: 229\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0168 - acc: 0.1167\n",
      "Epoch: 230\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0167 - acc: 0.0944\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0165 - acc: 0.1000\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0166 - acc: 0.0889\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0165 - acc: 0.0722\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0165 - acc: 0.0667\n",
      "Epoch: 235\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0163 - acc: 0.0667\n",
      "Epoch: 236\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0163 - acc: 0.0722\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0162 - acc: 0.0778\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0162 - acc: 0.0889\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0171 - acc: 0.0722\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0164 - acc: 0.0778\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0162 - acc: 0.0889\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0161 - acc: 0.0944\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0156 - acc: 0.0889\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0156 - acc: 0.0889\n",
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0155 - acc: 0.0889\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0156 - acc: 0.1000\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0155 - acc: 0.1111\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0158 - acc: 0.0944\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0153 - acc: 0.1000\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0150 - acc: 0.1056\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0151 - acc: 0.1056\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0149 - acc: 0.1000\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0148 - acc: 0.1000\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0148 - acc: 0.1000\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0146 - acc: 0.1111\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0148 - acc: 0.1000\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0147 - acc: 0.1222\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0225 - acc: 0.0944\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0241 - acc: 0.1111\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0160 - acc: 0.1167\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0148 - acc: 0.1278\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0155 - acc: 0.1389\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0146 - acc: 0.1167\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0145 - acc: 0.1167\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0144 - acc: 0.1222\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0151 - acc: 0.1167\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0154 - acc: 0.1111\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0149 - acc: 0.1278\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0148 - acc: 0.1222\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0170 - acc: 0.1278\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0161 - acc: 0.1167\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0152 - acc: 0.1111\n",
      "Epoch: 273\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0145 - acc: 0.1278\n",
      "Epoch: 274\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0144 - acc: 0.1444\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0153 - acc: 0.1278\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0145 - acc: 0.1444\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0146 - acc: 0.1444\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0145 - acc: 0.1222\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0144 - acc: 0.1278\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0147 - acc: 0.1444\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0142 - acc: 0.1611\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0145 - acc: 0.1444\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0143 - acc: 0.1556\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0143 - acc: 0.1500\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0139 - acc: 0.1722\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0142 - acc: 0.1500\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0138 - acc: 0.1889\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0147 - acc: 0.1611\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0142 - acc: 0.1611\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0142 - acc: 0.1722\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0142 - acc: 0.1556\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0137 - acc: 0.1889\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0145 - acc: 0.1556\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0139 - acc: 0.1722\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0140 - acc: 0.1889\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0142 - acc: 0.1889\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0148 - acc: 0.1556\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0140 - acc: 0.1833\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0146 - acc: 0.1889\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0148 - acc: 0.1500\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0155 - acc: 0.1444\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0148 - acc: 0.1722\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0148 - acc: 0.1833\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0148 - acc: 0.1833\n",
      "Epoch: 305\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0143 - acc: 0.1833\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0140 - acc: 0.1667\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0139 - acc: 0.1667\n",
      "Epoch: 308\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0138 - acc: 0.1667\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0135 - acc: 0.1611\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0135 - acc: 0.1556\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0135 - acc: 0.1500\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0137 - acc: 0.1500\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0137 - acc: 0.1500\n",
      "Epoch: 314\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0137 - acc: 0.1500\n",
      "Epoch: 315\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0146 - acc: 0.1444\n",
      "Epoch: 316\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0139 - acc: 0.1722\n",
      "Epoch: 317\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0131 - acc: 0.1556\n",
      "Epoch: 318\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0131 - acc: 0.1500\n",
      "Epoch: 319\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0135 - acc: 0.1556\n",
      "Epoch: 320\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0130 - acc: 0.1444\n",
      "Epoch: 321\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0143 - acc: 0.1556\n",
      "Epoch: 322\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0131 - acc: 0.1556\n",
      "Epoch: 323\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0137 - acc: 0.1556\n",
      "Epoch: 324\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0135 - acc: 0.1722\n",
      "Epoch: 325\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0132 - acc: 0.1778\n",
      "Epoch: 326\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0129 - acc: 0.1833\n",
      "Epoch: 327\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0128 - acc: 0.1944\n",
      "Epoch: 328\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0128 - acc: 0.1833\n",
      "Epoch: 329\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0128 - acc: 0.1722\n",
      "Epoch: 330\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0127 - acc: 0.1611\n",
      "Epoch: 331\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0126 - acc: 0.1722\n",
      "Epoch: 332\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0131 - acc: 0.1611\n",
      "Epoch: 333\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0125 - acc: 0.1722\n",
      "Epoch: 334\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0126 - acc: 0.1667\n",
      "Epoch: 335\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0125 - acc: 0.1833\n",
      "Epoch: 336\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0125 - acc: 0.1778\n",
      "Epoch: 337\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0124 - acc: 0.1833\n",
      "Epoch: 338\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0140 - acc: 0.1611\n",
      "Epoch: 339\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0132 - acc: 0.1611\n",
      "Epoch: 340\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0126 - acc: 0.1556\n",
      "Epoch: 341\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0120 - acc: 0.1667\n",
      "Epoch: 342\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0246 - acc: 0.2222\n",
      "Epoch: 343\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0239 - acc: 0.1333\n",
      "Epoch: 344\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0196 - acc: 0.1667\n",
      "Epoch: 345\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0180 - acc: 0.1667\n",
      "Epoch: 346\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0175 - acc: 0.1833\n",
      "Epoch: 347\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0166 - acc: 0.1667\n",
      "Epoch: 348\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0165 - acc: 0.1833\n",
      "Epoch: 349\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0161 - acc: 0.1611\n",
      "Epoch: 350\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0158 - acc: 0.1833\n",
      "Epoch: 351\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0156 - acc: 0.1833\n",
      "Epoch: 352\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0155 - acc: 0.2000\n",
      "Epoch: 353\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0171 - acc: 0.1944\n",
      "Epoch: 354\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0152 - acc: 0.1944\n",
      "Epoch: 355\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0142 - acc: 0.1889\n",
      "Epoch: 356\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0149 - acc: 0.1833\n",
      "Epoch: 357\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0139 - acc: 0.1944\n",
      "Epoch: 358\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0137 - acc: 0.2056\n",
      "Epoch: 359\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0135 - acc: 0.2111\n",
      "Epoch: 360\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0135 - acc: 0.2167\n",
      "Epoch: 361\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0132 - acc: 0.2167\n",
      "Epoch: 362\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0135 - acc: 0.2167\n",
      "Epoch: 363\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0150 - acc: 0.2222\n",
      "Epoch: 364\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0153 - acc: 0.2000\n",
      "Epoch: 365\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0132 - acc: 0.2167\n",
      "Epoch: 366\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0133 - acc: 0.2222\n",
      "Epoch: 367\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0139 - acc: 0.2167\n",
      "Epoch: 368\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0137 - acc: 0.1944\n",
      "Epoch: 369\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0128 - acc: 0.2222\n",
      "Epoch: 370\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0128 - acc: 0.2111\n",
      "Epoch: 371\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0132 - acc: 0.2167\n",
      "Epoch: 372\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0132 - acc: 0.2222\n",
      "Epoch: 373\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0151 - acc: 0.2056\n",
      "Epoch: 374\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0147 - acc: 0.2111\n",
      "Epoch: 375\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0146 - acc: 0.2056\n",
      "Epoch: 376\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0133 - acc: 0.2056\n",
      "Epoch: 377\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0126 - acc: 0.2000\n",
      "Epoch: 378\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0133 - acc: 0.2111\n",
      "Epoch: 379\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0136 - acc: 0.2167\n",
      "Epoch: 380\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0126 - acc: 0.2167\n",
      "Epoch: 381\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0128 - acc: 0.2278\n",
      "Epoch: 382\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0125 - acc: 0.2389\n",
      "Epoch: 383\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0127 - acc: 0.2333\n",
      "Epoch: 384\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0125 - acc: 0.2278\n",
      "Epoch: 385\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0128 - acc: 0.2278\n",
      "Epoch: 386\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0127 - acc: 0.2278\n",
      "Epoch: 387\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0124 - acc: 0.2222\n",
      "Epoch: 388\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0123 - acc: 0.2278\n",
      "Epoch: 389\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0122 - acc: 0.2278\n",
      "Epoch: 390\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0120 - acc: 0.2389\n",
      "Epoch: 391\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0123 - acc: 0.2444\n",
      "Epoch: 392\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0119 - acc: 0.2389\n",
      "Epoch: 393\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0122 - acc: 0.2556\n",
      "Epoch: 394\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0118 - acc: 0.2444\n",
      "Epoch: 395\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0134 - acc: 0.2389\n",
      "Epoch: 396\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0148 - acc: 0.2278\n",
      "Epoch: 397\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0120 - acc: 0.2444\n",
      "Epoch: 398\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0129 - acc: 0.2500\n",
      "Epoch: 399\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0125 - acc: 0.2444\n",
      "Epoch: 400\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0117 - acc: 0.2278\n",
      "Epoch: 401\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0121 - acc: 0.2333\n",
      "Epoch: 402\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0116 - acc: 0.2167\n",
      "Epoch: 403\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0121 - acc: 0.2333\n",
      "Epoch: 404\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0120 - acc: 0.2222\n",
      "Epoch: 405\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0129 - acc: 0.2222\n",
      "Epoch: 406\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0119 - acc: 0.2111\n",
      "Epoch: 407\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0116 - acc: 0.2444\n",
      "Epoch: 408\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0119 - acc: 0.2278\n",
      "Epoch: 409\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0121 - acc: 0.2444\n",
      "Epoch: 410\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0144 - acc: 0.2222\n",
      "Epoch: 411\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0117 - acc: 0.2222\n",
      "Epoch: 412\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0133 - acc: 0.2389\n",
      "Epoch: 413\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0129 - acc: 0.2444\n",
      "Epoch: 414\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0122 - acc: 0.2222\n",
      "Epoch: 415\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0121 - acc: 0.2333\n",
      "Epoch: 416\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0132 - acc: 0.2222\n",
      "Epoch: 417\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0115 - acc: 0.2167\n",
      "Epoch: 418\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0117 - acc: 0.2278\n",
      "Epoch: 419\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0126 - acc: 0.2444\n",
      "Epoch: 420\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0128 - acc: 0.2667\n",
      "Epoch: 421\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0118 - acc: 0.2611\n",
      "Epoch: 422\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0125 - acc: 0.2833\n",
      "Epoch: 423\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0117 - acc: 0.2556\n",
      "Epoch: 424\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0119 - acc: 0.2556\n",
      "Epoch: 425\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0119 - acc: 0.2722\n",
      "Epoch: 426\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0123 - acc: 0.2722\n",
      "Epoch: 427\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0113 - acc: 0.2556\n",
      "Epoch: 428\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0130 - acc: 0.2722\n",
      "Epoch: 429\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0130 - acc: 0.2500\n",
      "Epoch: 430\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0121 - acc: 0.2444\n",
      "Epoch: 431\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0120 - acc: 0.2611\n",
      "Epoch: 432\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0111 - acc: 0.2444\n",
      "Epoch: 433\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0110 - acc: 0.2500\n",
      "Epoch: 434\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0109 - acc: 0.2444\n",
      "Epoch: 435\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0123 - acc: 0.2444\n",
      "Epoch: 436\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0155 - acc: 0.2444\n",
      "Epoch: 437\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0110 - acc: 0.2278\n",
      "Epoch: 438\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0107 - acc: 0.2278\n",
      "Epoch: 439\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0111 - acc: 0.2444\n",
      "Epoch: 440\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0105 - acc: 0.2333\n",
      "Epoch: 441\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0120 - acc: 0.2444\n",
      "Epoch: 442\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0119 - acc: 0.2389\n",
      "Epoch: 443\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0108 - acc: 0.2278\n",
      "Epoch: 444\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0114 - acc: 0.2333\n",
      "Epoch: 445\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0106 - acc: 0.2278\n",
      "Epoch: 446\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0114 - acc: 0.2333\n",
      "Epoch: 447\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0111 - acc: 0.2167\n",
      "Epoch: 448\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0105 - acc: 0.2389\n",
      "Epoch: 449\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0103 - acc: 0.2389\n",
      "Epoch: 450\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0102 - acc: 0.2389\n",
      "Epoch: 451\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0102 - acc: 0.2444\n",
      "Epoch: 452\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0103 - acc: 0.2444\n",
      "Epoch: 453\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0101 - acc: 0.2333\n",
      "Epoch: 454\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0102 - acc: 0.2389\n",
      "Epoch: 455\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0099 - acc: 0.2389\n",
      "Epoch: 456\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0099 - acc: 0.2389\n",
      "Epoch: 457\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0099 - acc: 0.2444\n",
      "Epoch: 458\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0114 - acc: 0.2333\n",
      "Epoch: 459\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0140 - acc: 0.2222\n",
      "Epoch: 460\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0101 - acc: 0.2167\n",
      "Epoch: 461\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0110 - acc: 0.2056\n",
      "Epoch: 462\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0127 - acc: 0.2222\n",
      "Epoch: 463\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0114 - acc: 0.2111\n",
      "Epoch: 464\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0105 - acc: 0.2222\n",
      "Epoch: 465\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0100 - acc: 0.2222\n",
      "Epoch: 466\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0097 - acc: 0.2333\n",
      "Epoch: 467\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0099 - acc: 0.2333\n",
      "Epoch: 468\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0097 - acc: 0.2333\n",
      "Epoch: 469\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0096 - acc: 0.2389\n",
      "Epoch: 470\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0095 - acc: 0.2389\n",
      "Epoch: 471\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0095 - acc: 0.2278\n",
      "Epoch: 472\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0096 - acc: 0.2167\n",
      "Epoch: 473\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0097 - acc: 0.2111\n",
      "Epoch: 474\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0102 - acc: 0.2111\n",
      "Epoch: 475\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0106 - acc: 0.2167\n",
      "Epoch: 476\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0118 - acc: 0.2222\n",
      "Epoch: 477\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0147 - acc: 0.1944\n",
      "Epoch: 478\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0108 - acc: 0.2278\n",
      "Epoch: 479\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0100 - acc: 0.2278\n",
      "Epoch: 480\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0095 - acc: 0.2056\n",
      "Epoch: 481\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0092 - acc: 0.2056\n",
      "Epoch: 482\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0093 - acc: 0.2056\n",
      "Epoch: 483\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0105 - acc: 0.2222\n",
      "Epoch: 484\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 36ms/sample - loss: 0.0114 - acc: 0.1944\n",
      "Epoch: 485\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0103 - acc: 0.2056\n",
      "Epoch: 486\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0101 - acc: 0.2056\n",
      "Epoch: 487\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0113 - acc: 0.2167\n",
      "Epoch: 488\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0117 - acc: 0.1889\n",
      "Epoch: 489\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0094 - acc: 0.1889\n",
      "Epoch: 490\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0108 - acc: 0.2000\n",
      "Epoch: 491\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0099 - acc: 0.2056\n",
      "Epoch: 492\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0092 - acc: 0.2056\n",
      "Epoch: 493\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0089 - acc: 0.2056\n",
      "Epoch: 494\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0088 - acc: 0.2056\n",
      "Epoch: 495\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0089 - acc: 0.2056\n",
      "Epoch: 496\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0088 - acc: 0.2056\n",
      "Epoch: 497\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0088 - acc: 0.2056\n",
      "Epoch: 498\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0088 - acc: 0.2056\n",
      "Epoch: 499\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0092 - acc: 0.1944\n",
      "Epoch: 500\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0105 - acc: 0.1944\n",
      "Epoch: 501\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0114 - acc: 0.2000\n",
      "Epoch: 502\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0094 - acc: 0.2056\n",
      "Epoch: 503\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0092 - acc: 0.2056\n",
      "Epoch: 504\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0090 - acc: 0.1778\n",
      "Epoch: 505\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0091 - acc: 0.1833\n",
      "Epoch: 506\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0091 - acc: 0.1722\n",
      "Epoch: 507\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0087 - acc: 0.1722\n",
      "Epoch: 508\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0089 - acc: 0.1778\n",
      "Epoch: 509\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0106 - acc: 0.1833\n",
      "Epoch: 510\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0126 - acc: 0.1833\n",
      "Epoch: 511\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0146 - acc: 0.2000\n",
      "Epoch: 512\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0096 - acc: 0.1722\n",
      "Epoch: 513\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0087 - acc: 0.1778\n",
      "Epoch: 514\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0085 - acc: 0.1722\n",
      "Epoch: 515\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0082 - acc: 0.1944\n",
      "Epoch: 516\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0080 - acc: 0.1944\n",
      "Epoch: 517\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0080 - acc: 0.1889\n",
      "Epoch: 518\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0080 - acc: 0.1833\n",
      "Epoch: 519\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0080 - acc: 0.2000\n",
      "Epoch: 520\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0080 - acc: 0.1889\n",
      "Epoch: 521\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0082 - acc: 0.1889\n",
      "Epoch: 522\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0110 - acc: 0.2000\n",
      "Epoch: 523\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0119 - acc: 0.1611\n",
      "Epoch: 524\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0098 - acc: 0.1722\n",
      "Epoch: 525\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0108 - acc: 0.1722\n",
      "Epoch: 526\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0107 - acc: 0.1889\n",
      "Epoch: 527\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0122 - acc: 0.1667\n",
      "Epoch: 528\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0095 - acc: 0.1611\n",
      "Epoch: 529\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0103 - acc: 0.1722\n",
      "Epoch: 530\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0087 - acc: 0.1778\n",
      "Epoch: 531\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0081 - acc: 0.1667\n",
      "Epoch: 532\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0078 - acc: 0.1778\n",
      "Epoch: 533\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.1667\n",
      "Epoch: 534\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1667\n",
      "Epoch: 535\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0075 - acc: 0.1722\n",
      "Epoch: 536\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1722\n",
      "Epoch: 537\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1722\n",
      "Epoch: 538\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1611\n",
      "Epoch: 539\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1611\n",
      "Epoch: 540\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0076 - acc: 0.1722\n",
      "Epoch: 541\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0083 - acc: 0.1778\n",
      "Epoch: 542\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0078 - acc: 0.1667\n",
      "Epoch: 543\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.1778\n",
      "Epoch: 544\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0081 - acc: 0.1556\n",
      "Epoch: 545\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0116 - acc: 0.1778\n",
      "Epoch: 546\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0100 - acc: 0.1667\n",
      "Epoch: 547\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0120 - acc: 0.1667\n",
      "Epoch: 548\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0144 - acc: 0.1833\n",
      "Epoch: 549\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0094 - acc: 0.1444\n",
      "Epoch: 550\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0094 - acc: 0.1500\n",
      "Epoch: 551\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0088 - acc: 0.1667\n",
      "Epoch: 552\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0112 - acc: 0.1500\n",
      "Epoch: 553\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0099 - acc: 0.1722\n",
      "Epoch: 554\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0079 - acc: 0.1667\n",
      "Epoch: 555\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0075 - acc: 0.1500\n",
      "Epoch: 556\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0074 - acc: 0.1500\n",
      "Epoch: 557\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0073 - acc: 0.1556\n",
      "Epoch: 558\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0073 - acc: 0.1556\n",
      "Epoch: 559\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0072 - acc: 0.1444\n",
      "Epoch: 560\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0073 - acc: 0.1500\n",
      "Epoch: 561\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0073 - acc: 0.1500\n",
      "Epoch: 562\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0074 - acc: 0.1444\n",
      "Epoch: 563\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0074 - acc: 0.1444\n",
      "Epoch: 564\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0078 - acc: 0.1278\n",
      "Epoch: 565\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0091 - acc: 0.1111\n",
      "Epoch: 566\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0129 - acc: 0.1722\n",
      "Epoch: 567\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0132 - acc: 0.1222\n",
      "Epoch: 568\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0090 - acc: 0.1222\n",
      "Epoch: 569\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0080 - acc: 0.1333\n",
      "Epoch: 570\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0074 - acc: 0.1389\n",
      "Epoch: 571\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0071 - acc: 0.1278\n",
      "Epoch: 572\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0072 - acc: 0.1333\n",
      "Epoch: 573\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0071 - acc: 0.1278\n",
      "Epoch: 574\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0071 - acc: 0.1278\n",
      "Epoch: 575\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0085 - acc: 0.1222\n",
      "Epoch: 576\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0128 - acc: 0.1556\n",
      "Epoch: 577\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0180 - acc: 0.1222\n",
      "Epoch: 578\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0088 - acc: 0.1444\n",
      "Epoch: 579\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0075 - acc: 0.1222\n",
      "Epoch: 580\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0072 - acc: 0.1167\n",
      "Epoch: 581\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0071 - acc: 0.1222\n",
      "Epoch: 582\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0071 - acc: 0.1444\n",
      "Epoch: 583\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0070 - acc: 0.1500\n",
      "Epoch: 584\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0070 - acc: 0.1389\n",
      "Epoch: 585\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0070 - acc: 0.1333\n",
      "Epoch: 586\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0069 - acc: 0.1278\n",
      "Epoch: 587\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0068 - acc: 0.1222\n",
      "Epoch: 588\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0075 - acc: 0.1167\n",
      "Epoch: 589\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0079 - acc: 0.1444\n",
      "Epoch: 590\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0073 - acc: 0.1389\n",
      "Epoch: 591\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0071 - acc: 0.1556\n",
      "Epoch: 592\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0071 - acc: 0.1278\n",
      "Epoch: 593\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0071 - acc: 0.1333\n",
      "Epoch: 594\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0083 - acc: 0.1056\n",
      "Epoch: 595\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0078 - acc: 0.1333\n",
      "Epoch: 596\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0124 - acc: 0.1722\n",
      "Epoch: 597\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0137 - acc: 0.1944\n",
      "Epoch: 598\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0117 - acc: 0.1611\n",
      "Epoch: 599\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0115 - acc: 0.1611\n",
      "Epoch: 600\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0102 - acc: 0.1944\n",
      "Epoch: 601\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0102 - acc: 0.1778\n",
      "Epoch: 602\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0097 - acc: 0.1778\n",
      "Epoch: 603\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0093 - acc: 0.2000\n",
      "Epoch: 604\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0089 - acc: 0.1889\n",
      "Epoch: 605\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0087 - acc: 0.1833\n",
      "Epoch: 606\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0084 - acc: 0.1944\n",
      "Epoch: 607\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0091 - acc: 0.2000\n",
      "Epoch: 608\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0087 - acc: 0.2000\n",
      "Epoch: 609\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0090 - acc: 0.1889\n",
      "Epoch: 610\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0083 - acc: 0.1833\n",
      "Epoch: 611\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0085 - acc: 0.1722\n",
      "Epoch: 612\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0233 - acc: 0.1500\n",
      "Epoch: 613\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0172 - acc: 0.1778\n",
      "Epoch: 614\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0124 - acc: 0.1444\n",
      "Epoch: 615\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0115 - acc: 0.1722\n",
      "Epoch: 616\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0093 - acc: 0.1556\n",
      "Epoch: 617\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0091 - acc: 0.1444\n",
      "Epoch: 618\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0087 - acc: 0.1389\n",
      "Epoch: 619\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0083 - acc: 0.1556\n",
      "Epoch: 620\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0083 - acc: 0.1556\n",
      "Epoch: 621\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0084 - acc: 0.1278\n",
      "Epoch: 622\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0085 - acc: 0.1111\n",
      "Epoch: 623\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0083 - acc: 0.1333\n",
      "Epoch: 624\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0078 - acc: 0.1278\n",
      "Epoch: 625\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0083 - acc: 0.1167\n",
      "Epoch: 626\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0081 - acc: 0.1222\n",
      "Epoch: 627\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0079 - acc: 0.1167\n",
      "Epoch: 628\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.1111\n",
      "Epoch: 629\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0088 - acc: 0.1111\n",
      "Epoch: 630\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0109 - acc: 0.1333\n",
      "Epoch: 631\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0094 - acc: 0.1167\n",
      "Epoch: 632\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0089 - acc: 0.1222\n",
      "Epoch: 633\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0088 - acc: 0.1278\n",
      "Epoch: 634\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0093 - acc: 0.1167\n",
      "Epoch: 635\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0090 - acc: 0.1167\n",
      "Epoch: 636\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0095 - acc: 0.1222\n",
      "Epoch: 637\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0096 - acc: 0.1389\n",
      "Epoch: 638\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0100 - acc: 0.1222\n",
      "Epoch: 639\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0088 - acc: 0.1167\n",
      "Epoch: 640\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.1056\n",
      "Epoch: 641\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0078 - acc: 0.1056\n",
      "Epoch: 642\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0073 - acc: 0.1167\n",
      "Epoch: 643\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0073 - acc: 0.1167\n",
      "Epoch: 644\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0091 - acc: 0.1333\n",
      "Epoch: 645\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0094 - acc: 0.1278\n",
      "Epoch: 646\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0086 - acc: 0.1278\n",
      "Epoch: 647\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0078 - acc: 0.1056\n",
      "Epoch: 648\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.1111\n",
      "Epoch: 649\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.1111\n",
      "Epoch: 650\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0081 - acc: 0.1111\n",
      "Epoch: 651\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.0944\n",
      "Epoch: 652\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.1167\n",
      "Epoch: 653\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1000\n",
      "Epoch: 654\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0084 - acc: 0.1278\n",
      "Epoch: 655\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0095 - acc: 0.1556\n",
      "Epoch: 656\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0090 - acc: 0.1167\n",
      "Epoch: 657\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0082 - acc: 0.0944\n",
      "Epoch: 658\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.0944\n",
      "Epoch: 659\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1111\n",
      "Epoch: 660\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0071 - acc: 0.1333\n",
      "Epoch: 661\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0088 - acc: 0.1500\n",
      "Epoch: 662\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1222\n",
      "Epoch: 663\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1278\n",
      "Epoch: 664\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0098 - acc: 0.1500\n",
      "Epoch: 665\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0104 - acc: 0.1167\n",
      "Epoch: 666\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0099 - acc: 0.1056\n",
      "Epoch: 667\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0079 - acc: 0.1167\n",
      "Epoch: 668\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0069 - acc: 0.1333\n",
      "Epoch: 669\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0067 - acc: 0.1389\n",
      "Epoch: 670\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0067 - acc: 0.1333\n",
      "Epoch: 671\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0068 - acc: 0.1333\n",
      "Epoch: 672\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0086 - acc: 0.1500\n",
      "Epoch: 673\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0070 - acc: 0.1444\n",
      "Epoch: 674\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0078 - acc: 0.1278\n",
      "Epoch: 675\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1333\n",
      "Epoch: 676\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0098 - acc: 0.1667\n",
      "Epoch: 677\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0107 - acc: 0.1222\n",
      "Epoch: 678\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0114 - acc: 0.1556\n",
      "Epoch: 679\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0094 - acc: 0.1278\n",
      "Epoch: 680\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0085 - acc: 0.1167\n",
      "Epoch: 681\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0088 - acc: 0.1167\n",
      "Epoch: 682\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0066 - acc: 0.1278\n",
      "Epoch: 683\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0067 - acc: 0.1389\n",
      "Epoch: 684\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0069 - acc: 0.1333\n",
      "Epoch: 685\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0067 - acc: 0.1500\n",
      "Epoch: 686\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0065 - acc: 0.1500\n",
      "Epoch: 687\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0071 - acc: 0.1444\n",
      "Epoch: 688\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0095 - acc: 0.1444\n",
      "Epoch: 689\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0084 - acc: 0.1333\n",
      "Epoch: 690\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.1556\n",
      "Epoch: 691\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0096 - acc: 0.1611\n",
      "Epoch: 692\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0066 - acc: 0.1333\n",
      "Epoch: 693\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0067 - acc: 0.1500\n",
      "Epoch: 694\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0072 - acc: 0.1667\n",
      "Epoch: 695\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0084 - acc: 0.1722\n",
      "Epoch: 696\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.1333\n",
      "Epoch: 697\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0080 - acc: 0.1333\n",
      "Epoch: 698\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0064 - acc: 0.1444\n",
      "Epoch: 699\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.1778\n",
      "Epoch: 700\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0067 - acc: 0.1222\n",
      "Epoch: 701\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0078 - acc: 0.1389\n",
      "Epoch: 702\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0096 - acc: 0.1500\n",
      "Epoch: 703\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0086 - acc: 0.1500\n",
      "Epoch: 704\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.1278\n",
      "Epoch: 705\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0069 - acc: 0.1500\n",
      "Epoch: 706\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0072 - acc: 0.1222\n",
      "Epoch: 707\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0073 - acc: 0.1278\n",
      "Epoch: 708\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0064 - acc: 0.1278\n",
      "Epoch: 709\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0111 - acc: 0.1833\n",
      "Epoch: 710\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0094 - acc: 0.1333\n",
      "Epoch: 711\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0097 - acc: 0.1167\n",
      "Epoch: 712\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0091 - acc: 0.1667\n",
      "Epoch: 713\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0083 - acc: 0.1556\n",
      "Epoch: 714\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0083 - acc: 0.1222\n",
      "Epoch: 715\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0091 - acc: 0.1222\n",
      "Epoch: 716\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0071 - acc: 0.1389\n",
      "Epoch: 717\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0063 - acc: 0.1389\n",
      "Epoch: 718\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0064 - acc: 0.1444\n",
      "Epoch: 719\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0063 - acc: 0.1444\n",
      "Epoch: 720\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0065 - acc: 0.1500\n",
      "Epoch: 721\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0075 - acc: 0.1444\n",
      "Epoch: 722\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0085 - acc: 0.1333\n",
      "Epoch: 723\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0080 - acc: 0.1611\n",
      "Epoch: 724\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0081 - acc: 0.1611\n",
      "Epoch: 725\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0077 - acc: 0.1222\n",
      "Epoch: 726\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0090 - acc: 0.1389\n",
      "Epoch: 727\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0092 - acc: 0.1111\n",
      "Epoch: 728\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0076 - acc: 0.1222\n",
      "Epoch: 729\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0064 - acc: 0.1278\n",
      "Epoch: 730\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0084 - acc: 0.1722\n",
      "Epoch: 731\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0071 - acc: 0.1111\n",
      "Epoch: 732\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0065 - acc: 0.1333\n",
      "Epoch: 733\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0117 - acc: 0.1167\n",
      "Epoch: 734\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0074 - acc: 0.1444\n",
      "Epoch: 735\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1722\n",
      "Epoch: 736\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0078 - acc: 0.1944\n",
      "Epoch: 737\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0079 - acc: 0.1444\n",
      "Epoch: 738\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0075 - acc: 0.1278\n",
      "Epoch: 739\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0063 - acc: 0.1444\n",
      "Epoch: 740\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0064 - acc: 0.1389\n",
      "Epoch: 741\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1500\n",
      "Epoch: 742\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0076 - acc: 0.1278\n",
      "Epoch: 743\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0074 - acc: 0.1222\n",
      "Epoch: 744\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0064 - acc: 0.1500\n",
      "Epoch: 745\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0074 - acc: 0.1833\n",
      "Epoch: 746\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0070 - acc: 0.1389\n",
      "Epoch: 747\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0075 - acc: 0.1722\n",
      "Epoch: 748\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0076 - acc: 0.1389\n",
      "Epoch: 749\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0085 - acc: 0.1278\n",
      "Epoch: 750\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0097 - acc: 0.0833\n",
      "Epoch: 751\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0062 - acc: 0.1222\n",
      "Epoch: 752\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0061 - acc: 0.1333\n",
      "Epoch: 753\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0085 - acc: 0.1500\n",
      "Epoch: 754\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0096 - acc: 0.1556\n",
      "Epoch: 755\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0069 - acc: 0.1333\n",
      "Epoch: 756\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0060 - acc: 0.1222\n",
      "Epoch: 757\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0059 - acc: 0.1333\n",
      "Epoch: 758\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0077 - acc: 0.1556\n",
      "Epoch: 759\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0085 - acc: 0.1611\n",
      "Epoch: 760\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0063 - acc: 0.1611\n",
      "Epoch: 761\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0057 - acc: 0.1444\n",
      "Epoch: 762\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0070 - acc: 0.1667\n",
      "Epoch: 763\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0062 - acc: 0.1556\n",
      "Epoch: 764\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0098 - acc: 0.1667\n",
      "Epoch: 765\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0085 - acc: 0.1333\n",
      "Epoch: 766\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0063 - acc: 0.1500\n",
      "Epoch: 767\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0059 - acc: 0.1389\n",
      "Epoch: 768\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0062 - acc: 0.1444\n",
      "Epoch: 769\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0056 - acc: 0.1500\n",
      "Epoch: 770\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0071 - acc: 0.1667\n",
      "Epoch: 771\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0083 - acc: 0.1444\n",
      "Epoch: 772\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0134 - acc: 0.1500\n",
      "Epoch: 773\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0093 - acc: 0.1278\n",
      "Epoch: 774\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0084 - acc: 0.1222\n",
      "Epoch: 775\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0087 - acc: 0.0944\n",
      "Epoch: 776\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0109 - acc: 0.0889\n",
      "Epoch: 777\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0081 - acc: 0.1000\n",
      "Epoch: 778\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0097 - acc: 0.1167\n",
      "Epoch: 779\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0066 - acc: 0.1278\n",
      "Epoch: 780\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0074 - acc: 0.1500\n",
      "Epoch: 781\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0088 - acc: 0.1333\n",
      "Epoch: 782\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0073 - acc: 0.1111\n",
      "Epoch: 783\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0096 - acc: 0.1444\n",
      "Epoch: 784\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0085 - acc: 0.1333\n",
      "Epoch: 785\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0058 - acc: 0.1167\n",
      "Epoch: 786\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0074 - acc: 0.1278\n",
      "Epoch: 787\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0091 - acc: 0.1056\n",
      "Epoch: 788\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0107 - acc: 0.1111\n",
      "Epoch: 789\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0104 - acc: 0.1222\n",
      "Epoch: 790\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0070 - acc: 0.1333\n",
      "Epoch: 791\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0056 - acc: 0.1278\n",
      "Epoch: 792\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0053 - acc: 0.1389\n",
      "Epoch: 793\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0052 - acc: 0.1389\n",
      "Epoch: 794\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0051 - acc: 0.1444\n",
      "Epoch: 795\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0051 - acc: 0.1389\n",
      "Epoch: 796\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0051 - acc: 0.1444\n",
      "Epoch: 797\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0074 - acc: 0.1611\n",
      "Epoch: 798\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0084 - acc: 0.1556\n",
      "Epoch: 799\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0091 - acc: 0.1222\n",
      "Forecasting Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-04-19 21:02:47.560407: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=1, Predicted=9.885745, Expected=9.510000\n",
      "Month=2, Predicted=9.719135, Expected=9.796000\n",
      "Month=3, Predicted=9.326920, Expected=9.468500\n",
      "Month=4, Predicted=9.711035, Expected=9.672000\n",
      "Month=5, Predicted=9.750172, Expected=9.610000\n",
      "Month=6, Predicted=9.328701, Expected=9.240000\n",
      "Month=7, Predicted=10.241125, Expected=10.318300\n",
      "Month=8, Predicted=9.147576, Expected=8.974800\n",
      "Month=9, Predicted=9.166576, Expected=9.114000\n",
      "Month=10, Predicted=9.325858, Expected=9.300000\n",
      "Month=11, Predicted=8.188469, Expected=8.400000\n",
      "Month=12, Predicted=9.303437, Expected=9.300000\n",
      "Month=13, Predicted=8.974294, Expected=9.000000\n",
      "Month=14, Predicted=9.317099, Expected=9.300000\n",
      "Month=15, Predicted=9.281724, Expected=9.460000\n",
      "Month=16, Predicted=9.267184, Expected=9.145000\n",
      "Month=17, Predicted=9.213099, Expected=9.021000\n",
      "Month=18, Predicted=8.721179, Expected=8.750000\n",
      "Month=19, Predicted=8.826804, Expected=8.710000\n",
      "Month=20, Predicted=8.449713, Expected=8.370000\n",
      "Month=21, Predicted=8.586951, Expected=8.504000\n",
      "Month=22, Predicted=8.837987, Expected=9.819700\n",
      "Month=23, Predicted=9.772903, Expected=9.827300\n",
      "Month=24, Predicted=10.066711, Expected=9.929800\n",
      "Month=25, Predicted=9.278422, Expected=9.288000\n",
      "Month=26, Predicted=9.742099, Expected=9.300000\n",
      "Month=27, Predicted=9.010581, Expected=9.060000\n",
      "Month=28, Predicted=9.058835, Expected=8.835000\n",
      "Month=29, Predicted=8.384989, Expected=8.388600\n",
      "Month=30, Predicted=8.449375, Expected=8.400000\n",
      "Month=31, Predicted=8.256134, Expected=8.525000\n",
      "Month=32, Predicted=8.008291, Expected=8.250000\n",
      "Month=33, Predicted=8.439574, Expected=8.419000\n",
      "Month=34, Predicted=8.624699, Expected=9.455000\n",
      "Month=35, Predicted=8.722128, Expected=8.540000\n",
      "Month=36, Predicted=9.483920, Expected=9.455000\n",
      "Month=37, Predicted=9.128462, Expected=9.000000\n",
      "Month=38, Predicted=9.482575, Expected=9.599000\n",
      "Month=39, Predicted=9.445402, Expected=9.436000\n",
      "Month=40, Predicted=9.540179, Expected=9.539800\n",
      "Month=41, Predicted=9.851726, Expected=9.028600\n",
      "Month=42, Predicted=9.016871, Expected=8.932000\n",
      "Month=43, Predicted=8.703007, Expected=8.993000\n",
      "Month=44, Predicted=8.747718, Expected=8.678400\n",
      "Month=45, Predicted=9.155533, Expected=9.011100\n",
      "Month=46, Predicted=9.147546, Expected=9.630000\n",
      "Month=47, Predicted=8.665838, Expected=8.590400\n",
      "Month=48, Predicted=8.781379, Expected=9.736300\n",
      "Month=49, Predicted=9.408023, Expected=9.384500\n",
      "Month=50, Predicted=9.984069, Expected=9.947200\n",
      "Month=51, Predicted=9.760719, Expected=9.577100\n",
      "Month=52, Predicted=9.344252, Expected=9.117200\n",
      "Month=53, Predicted=9.189592, Expected=9.122500\n",
      "Month=54, Predicted=8.986878, Expected=8.880000\n",
      "Month=55, Predicted=8.950839, Expected=8.709200\n",
      "Month=56, Predicted=8.368156, Expected=8.428200\n",
      "Month=57, Predicted=8.890873, Expected=9.907600\n",
      "Month=58, Predicted=9.191185, Expected=9.145000\n",
      "Month=59, Predicted=8.363565, Expected=8.498000\n",
      "Month=60, Predicted=9.315686, Expected=9.362000\n",
      "Month=61, Predicted=9.055750, Expected=9.000000\n",
      "Month=62, Predicted=9.463990, Expected=9.455000\n",
      "Month=63, Predicted=9.491717, Expected=9.300000\n",
      "Month=64, Predicted=8.934910, Expected=8.990000\n",
      "Month=65, Predicted=9.351649, Expected=8.990000\n",
      "Month=66, Predicted=8.755396, Expected=8.790000\n",
      "Month=67, Predicted=8.842609, Expected=8.835000\n",
      "Month=68, Predicted=8.835350, Expected=8.700000\n",
      "Month=69, Predicted=8.841352, Expected=8.935000\n",
      "Month=70, Predicted=8.821215, Expected=8.835000\n",
      "Month=71, Predicted=8.420206, Expected=8.265000\n",
      "Month=72, Predicted=8.867227, Expected=8.835000\n",
      "Month=73, Predicted=8.567757, Expected=8.550000\n",
      "Month=74, Predicted=8.601794, Expected=8.680000\n",
      "Month=75, Predicted=8.934649, Expected=8.400000\n",
      "Month=76, Predicted=8.592769, Expected=8.525000\n",
      "Month=77, Predicted=8.779693, Expected=8.370000\n",
      "Month=78, Predicted=8.227157, Expected=7.890000\n",
      "Month=79, Predicted=7.842070, Expected=7.812000\n",
      "Month=80, Predicted=7.700306, Expected=7.620000\n",
      "Month=81, Predicted=8.202121, Expected=7.718000\n",
      "Month=82, Predicted=8.060530, Expected=8.323500\n",
      "Month=83, Predicted=6.788684, Expected=6.860000\n",
      "Month=84, Predicted=8.371221, Expected=8.308000\n",
      "Month=85, Predicted=8.091446, Expected=8.100000\n",
      "Month=86, Predicted=8.532430, Expected=8.525000\n",
      "Month=87, Predicted=8.309831, Expected=8.250000\n",
      "Month=88, Predicted=8.451317, Expected=8.215000\n",
      "Month=89, Predicted=7.957551, Expected=8.122600\n",
      "Month=90, Predicted=7.830293, Expected=7.778100\n",
      "Month=91, Predicted=8.064966, Expected=7.954600\n",
      "Month=92, Predicted=8.169286, Expected=7.420000\n",
      "Month=93, Predicted=7.612741, Expected=7.538300\n",
      "Month=94, Predicted=7.715981, Expected=7.905000\n",
      "Month=95, Predicted=7.250864, Expected=7.140000\n",
      "Month=96, Predicted=8.586916, Expected=8.432000\n",
      "Month=97, Predicted=7.813710, Expected=7.710000\n",
      "Month=98, Predicted=7.844183, Expected=7.967000\n",
      "Month=99, Predicted=7.484881, Expected=7.320000\n",
      "Month=100, Predicted=7.611406, Expected=7.502000\n",
      "Month=101, Predicted=7.313092, Expected=7.409000\n",
      "Month=102, Predicted=7.318210, Expected=7.200600\n",
      "Month=103, Predicted=7.768964, Expected=7.865000\n",
      "Month=104, Predicted=6.827960, Expected=6.690000\n",
      "Month=105, Predicted=7.143448, Expected=6.879400\n",
      "Month=106, Predicted=7.527856, Expected=7.440000\n",
      "Month=107, Predicted=6.994784, Expected=6.860000\n",
      "Month=108, Predicted=7.732127, Expected=7.595000\n",
      "Month=109, Predicted=7.317795, Expected=7.200000\n",
      "Month=110, Predicted=7.226746, Expected=7.130000\n",
      "Month=111, Predicted=6.894439, Expected=6.900000\n",
      "Month=112, Predicted=7.296727, Expected=7.130000\n",
      "Month=113, Predicted=7.085341, Expected=7.130000\n",
      "Month=114, Predicted=6.949002, Expected=6.840000\n",
      "Month=115, Predicted=7.165430, Expected=7.006000\n",
      "Month=116, Predicted=7.199980, Expected=6.780000\n",
      "Month=117, Predicted=6.991781, Expected=7.089600\n",
      "Month=118, Predicted=7.099639, Expected=6.882000\n",
      "Month=119, Predicted=6.592843, Expected=6.446700\n",
      "Month=120, Predicted=6.738597, Expected=6.882000\n",
      "Month=121, Predicted=6.744948, Expected=6.600000\n",
      "Month=122, Predicted=6.845310, Expected=6.820000\n",
      "Month=123, Predicted=6.766881, Expected=6.600000\n",
      "Month=124, Predicted=6.573522, Expected=6.820000\n",
      "Month=125, Predicted=6.752422, Expected=6.665000\n",
      "Month=126, Predicted=6.589745, Expected=6.450000\n",
      "Month=127, Predicted=7.286517, Expected=6.665000\n",
      "Month=128, Predicted=6.592113, Expected=6.450000\n",
      "Month=129, Predicted=6.499575, Expected=6.722100\n",
      "Month=130, Predicted=6.880085, Expected=6.820000\n",
      "Month=131, Predicted=6.476066, Expected=6.160000\n",
      "Month=132, Predicted=6.694775, Expected=6.820000\n",
      "Month=133, Predicted=6.525179, Expected=6.480000\n",
      "Month=134, Predicted=6.574491, Expected=6.596900\n",
      "Month=135, Predicted=6.961690, Expected=6.492000\n",
      "Month=136, Predicted=6.557368, Expected=6.510000\n",
      "Month=137, Predicted=6.481663, Expected=6.339500\n",
      "Month=138, Predicted=6.286888, Expected=6.001600\n",
      "Month=139, Predicted=6.191945, Expected=6.107000\n",
      "Month=140, Predicted=6.478513, Expected=5.790000\n",
      "Month=141, Predicted=6.063147, Expected=5.885000\n",
      "Month=142, Predicted=6.262665, Expected=7.280000\n",
      "Month=143, Predicted=5.983757, Expected=5.941600\n",
      "Month=144, Predicted=6.994848, Expected=6.810000\n",
      "Month=145, Predicted=6.261882, Expected=6.182000\n",
      "Month=146, Predicted=6.363868, Expected=6.293000\n",
      "Month=147, Predicted=6.112758, Expected=6.118600\n",
      "Month=148, Predicted=6.069983, Expected=6.138000\n",
      "Month=149, Predicted=6.080520, Expected=6.107000\n",
      "Month=150, Predicted=6.032050, Expected=5.913000\n",
      "Month=151, Predicted=6.275993, Expected=6.141100\n",
      "Month=152, Predicted=6.069965, Expected=6.248000\n",
      "Month=153, Predicted=6.203727, Expected=5.829700\n",
      "Month=154, Predicted=6.984352, Expected=6.829300\n",
      "Month=155, Predicted=6.670568, Expected=6.694400\n",
      "Month=156, Predicted=7.770854, Expected=7.726200\n",
      "Month=157, Predicted=7.436424, Expected=7.054400\n",
      "Month=158, Predicted=7.274666, Expected=7.268900\n",
      "Month=159, Predicted=6.950702, Expected=7.020000\n",
      "Month=160, Predicted=6.754116, Expected=6.510000\n",
      "Month=161, Predicted=6.425831, Expected=6.370500\n",
      "Month=162, Predicted=5.689101, Expected=5.730000\n",
      "Month=163, Predicted=5.914092, Expected=5.828000\n",
      "Month=164, Predicted=5.628727, Expected=5.580000\n",
      "Month=165, Predicted=5.790749, Expected=5.709900\n",
      "Month=166, Predicted=6.044434, Expected=6.696000\n",
      "Month=167, Predicted=6.259698, Expected=6.248000\n",
      "Month=168, Predicted=6.755307, Expected=6.711600\n",
      "Month=169, Predicted=6.555689, Expected=6.600100\n",
      "Month=170, Predicted=7.478087, Expected=7.508200\n",
      "Month=171, Predicted=7.690766, Expected=7.765000\n",
      "Month=172, Predicted=7.340245, Expected=7.285000\n",
      "Month=173, Predicted=6.941716, Expected=6.959500\n",
      "Month=174, Predicted=6.465210, Expected=6.450000\n",
      "Month=175, Predicted=6.523370, Expected=6.572000\n",
      "Month=176, Predicted=6.798656, Expected=6.600000\n",
      "Month=177, Predicted=4.389511, Expected=4.265300\n",
      "Month=178, Predicted=7.357132, Expected=7.367000\n",
      "Month=179, Predicted=6.536262, Expected=6.544000\n",
      "Month=180, Predicted=6.956660, Expected=6.940800\n",
      "Train RMSE: 0.25539\n",
      "Train RMSPE: 3.23427\n",
      "Train MAE: 0.16161\n",
      "Train MAPE: 2.09034\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=6.424525, Expected=6.786000\n",
      "Month=2, Predicted=6.874083, Expected=6.981200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=3, Predicted=6.726069, Expected=6.756000\n",
      "Month=4, Predicted=6.782154, Expected=6.733200\n",
      "Month=5, Predicted=6.459397, Expected=6.671200\n",
      "Month=6, Predicted=6.392001, Expected=6.295600\n",
      "Month=7, Predicted=7.335165, Expected=6.432500\n",
      "Month=8, Predicted=6.711203, Expected=6.153000\n",
      "Month=9, Predicted=6.354147, Expected=6.389500\n",
      "Month=10, Predicted=6.316846, Expected=7.192000\n",
      "Month=11, Predicted=6.638040, Expected=6.524000\n",
      "Month=12, Predicted=7.169091, Expected=7.238500\n",
      "Month=13, Predicted=6.941124, Expected=6.990000\n",
      "Month=14, Predicted=7.109724, Expected=7.254000\n",
      "Month=15, Predicted=7.353623, Expected=6.720000\n",
      "Month=16, Predicted=6.611635, Expected=6.944000\n",
      "Month=17, Predicted=6.832255, Expected=7.052500\n",
      "Month=18, Predicted=7.030681, Expected=6.690000\n",
      "Month=19, Predicted=7.153294, Expected=6.909900\n",
      "Month=20, Predicted=6.941217, Expected=6.819000\n",
      "Month=21, Predicted=6.481642, Expected=7.167200\n",
      "Month=22, Predicted=7.290835, Expected=7.254000\n",
      "Month=23, Predicted=7.257483, Expected=6.664000\n",
      "Month=24, Predicted=6.939105, Expected=7.393500\n",
      "Month=25, Predicted=7.113464, Expected=7.125000\n",
      "Month=26, Predicted=7.270816, Expected=7.347000\n",
      "Month=27, Predicted=7.381829, Expected=7.216500\n",
      "Month=28, Predicted=7.043908, Expected=7.254000\n",
      "Month=29, Predicted=7.347875, Expected=7.238500\n",
      "Month=30, Predicted=7.201821, Expected=6.990000\n",
      "Month=31, Predicted=7.227177, Expected=7.192000\n",
      "Month=32, Predicted=7.411083, Expected=6.900000\n",
      "Month=33, Predicted=6.640115, Expected=7.427300\n",
      "Month=34, Predicted=7.227233, Expected=7.300500\n",
      "Month=35, Predicted=7.898362, Expected=6.902000\n",
      "Month=36, Predicted=6.809773, Expected=7.409000\n",
      "Month=37, Predicted=7.362137, Expected=7.179000\n",
      "Month=38, Predicted=7.029807, Expected=7.424500\n",
      "Month=39, Predicted=7.367111, Expected=7.275000\n",
      "Month=40, Predicted=7.070802, Expected=7.316000\n",
      "Month=41, Predicted=7.241955, Expected=7.086300\n",
      "Month=42, Predicted=7.059334, Expected=7.020000\n",
      "Month=43, Predicted=6.779232, Expected=7.270500\n",
      "Month=44, Predicted=7.399259, Expected=7.168800\n",
      "Month=45, Predicted=6.685852, Expected=7.448600\n",
      "Month=46, Predicted=7.464188, Expected=7.440200\n",
      "Test RMSE: 0.40241\n",
      "Test RMSPE: 5.77476\n",
      "Test MAE: 0.29721\n",
      "Test MAPE: 4.25118\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# oil static.py bi lstm \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "# from keras.optimizers import sgd\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(32, return_sequences = True  , input_shape = (batch_size , X.shape[1],1))))\n",
    "    model.add(Bidirectional(LSTM(32, return_sequences = True  )))\n",
    "    model.add(Bidirectional(LSTM(32 ,activation='softmax' )))\n",
    "    # model.add(Dropout(0.3))\n",
    "    model.add(Dense(10 ))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size  , verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=2\n",
    "\tneurons=[ 5,4,2 ] \n",
    "\tn_epochs=800\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e8577d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 22:24:17.153213: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-19 22:24:17.153466: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_5282/3414122873.py:27: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_5282/3414122873.py:249: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
      "/var/folders/pb/zjk7bcqn4l73lc2cmv6y5_gh0000gn/T/ipykernel_5282/3414122873.py:153: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 22:24:18.008263: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 22:24:18.126195: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 22:24:18.252710: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-19 22:24:18.267302: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 8s 38ms/sample - loss: 0.0570 - acc: 0.3444\n",
      "Epoch: 1\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0481 - acc: 0.0056\n",
      "Epoch: 2\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0476 - acc: 0.0000e+00\n",
      "Epoch: 3\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0459 - acc: 0.0556\n",
      "Epoch: 4\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0446 - acc: 0.0667\n",
      "Epoch: 5\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0438 - acc: 0.0333\n",
      "Epoch: 6\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0432 - acc: 0.0222\n",
      "Epoch: 7\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0428 - acc: 0.0056\n",
      "Epoch: 8\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0425 - acc: 0.0111\n",
      "Epoch: 9\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0421 - acc: 0.0167\n",
      "Epoch: 10\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0419 - acc: 0.0278\n",
      "Epoch: 11\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0416 - acc: 0.0222\n",
      "Epoch: 12\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0413 - acc: 0.0167\n",
      "Epoch: 13\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0411 - acc: 0.0000e+00\n",
      "Epoch: 14\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0408 - acc: 0.0000e+00\n",
      "Epoch: 15\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0405 - acc: 0.0000e+00\n",
      "Epoch: 16\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0403 - acc: 0.0000e+00\n",
      "Epoch: 17\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0401 - acc: 0.0000e+00\n",
      "Epoch: 18\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0399 - acc: 0.0000e+00\n",
      "Epoch: 19\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0397 - acc: 0.0000e+00\n",
      "Epoch: 20\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0396 - acc: 0.0000e+00\n",
      "Epoch: 21\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0394 - acc: 0.0000e+00\n",
      "Epoch: 22\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0393 - acc: 0.0000e+00\n",
      "Epoch: 23\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0392 - acc: 0.0000e+00\n",
      "Epoch: 24\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0391 - acc: 0.0000e+00\n",
      "Epoch: 25\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0390 - acc: 0.0000e+00\n",
      "Epoch: 26\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0389 - acc: 0.0000e+00\n",
      "Epoch: 27\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0388 - acc: 0.0000e+00\n",
      "Epoch: 28\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0387 - acc: 0.0000e+00\n",
      "Epoch: 29\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0386 - acc: 0.0000e+00\n",
      "Epoch: 30\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0386 - acc: 0.0000e+00\n",
      "Epoch: 31\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0385 - acc: 0.0056\n",
      "Epoch: 32\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0384 - acc: 0.0056\n",
      "Epoch: 33\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0384 - acc: 0.0056\n",
      "Epoch: 34\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0383 - acc: 0.0056\n",
      "Epoch: 35\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0383 - acc: 0.0111\n",
      "Epoch: 36\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0382 - acc: 0.0056\n",
      "Epoch: 37\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0382 - acc: 0.0000e+00\n",
      "Epoch: 38\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0381 - acc: 0.0056\n",
      "Epoch: 39\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0381 - acc: 0.0222\n",
      "Epoch: 40\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0381 - acc: 0.0278\n",
      "Epoch: 41\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0380 - acc: 0.0167\n",
      "Epoch: 42\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0380 - acc: 0.0111\n",
      "Epoch: 43\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0380 - acc: 0.0056\n",
      "Epoch: 44\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0379 - acc: 0.0000e+00\n",
      "Epoch: 45\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0379 - acc: 0.0000e+00\n",
      "Epoch: 46\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0379 - acc: 0.0000e+00\n",
      "Epoch: 47\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0378 - acc: 0.0000e+00\n",
      "Epoch: 48\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0378 - acc: 0.0000e+00\n",
      "Epoch: 49\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0378 - acc: 0.0000e+00\n",
      "Epoch: 50\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0377 - acc: 0.0000e+00\n",
      "Epoch: 51\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0377 - acc: 0.0000e+00\n",
      "Epoch: 52\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0377 - acc: 0.0000e+00\n",
      "Epoch: 53\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0377 - acc: 0.0000e+00\n",
      "Epoch: 54\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0376 - acc: 0.0000e+00\n",
      "Epoch: 55\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0376 - acc: 0.0000e+00\n",
      "Epoch: 56\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0376 - acc: 0.0000e+00\n",
      "Epoch: 57\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0376 - acc: 0.0000e+00\n",
      "Epoch: 58\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0375 - acc: 0.0000e+00\n",
      "Epoch: 59\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0375 - acc: 0.0000e+00\n",
      "Epoch: 60\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0375 - acc: 0.0000e+00\n",
      "Epoch: 61\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0375 - acc: 0.0000e+00\n",
      "Epoch: 62\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0375 - acc: 0.0000e+00\n",
      "Epoch: 63\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0374 - acc: 0.0000e+00\n",
      "Epoch: 64\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0374 - acc: 0.0000e+00\n",
      "Epoch: 65\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0374 - acc: 0.0000e+00\n",
      "Epoch: 66\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0374 - acc: 0.0000e+00\n",
      "Epoch: 67\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0373 - acc: 0.0000e+00\n",
      "Epoch: 68\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0373 - acc: 0.0000e+00\n",
      "Epoch: 69\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0373 - acc: 0.0000e+00\n",
      "Epoch: 70\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0372 - acc: 0.0000e+00\n",
      "Epoch: 71\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0372 - acc: 0.0000e+00\n",
      "Epoch: 72\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0371 - acc: 0.0000e+00\n",
      "Epoch: 73\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0371 - acc: 0.0000e+00\n",
      "Epoch: 74\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0370 - acc: 0.0000e+00\n",
      "Epoch: 75\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0370 - acc: 0.0000e+00\n",
      "Epoch: 76\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0370 - acc: 0.0000e+00\n",
      "Epoch: 77\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0370 - acc: 0.0000e+00\n",
      "Epoch: 78\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0369 - acc: 0.0000e+00\n",
      "Epoch: 79\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0369 - acc: 0.0000e+00\n",
      "Epoch: 80\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0369 - acc: 0.0056\n",
      "Epoch: 81\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0369 - acc: 0.0056\n",
      "Epoch: 82\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0369 - acc: 0.0000e+00\n",
      "Epoch: 83\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0369 - acc: 0.0000e+00\n",
      "Epoch: 84\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0369 - acc: 0.0056\n",
      "Epoch: 85\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0368 - acc: 0.0056\n",
      "Epoch: 86\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0368 - acc: 0.0056\n",
      "Epoch: 87\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0368 - acc: 0.0056\n",
      "Epoch: 88\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0368 - acc: 0.0056\n",
      "Epoch: 89\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0368 - acc: 0.0000e+00\n",
      "Epoch: 90\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0368 - acc: 0.0000e+00\n",
      "Epoch: 91\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0367 - acc: 0.0000e+00\n",
      "Epoch: 92\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0367 - acc: 0.0000e+00\n",
      "Epoch: 93\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0367 - acc: 0.0000e+00\n",
      "Epoch: 94\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0367 - acc: 0.0056\n",
      "Epoch: 95\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0367 - acc: 0.0056\n",
      "Epoch: 96\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0367 - acc: 0.0111\n",
      "Epoch: 97\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0366 - acc: 0.0111\n",
      "Epoch: 98\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0366 - acc: 0.0111\n",
      "Epoch: 99\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0366 - acc: 0.0222\n",
      "Epoch: 100\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0366 - acc: 0.0111\n",
      "Epoch: 101\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0366 - acc: 0.0056\n",
      "Epoch: 102\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0366 - acc: 0.0056\n",
      "Epoch: 103\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0366 - acc: 0.0056\n",
      "Epoch: 104\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0366 - acc: 0.0056\n",
      "Epoch: 105\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0366 - acc: 0.0056\n",
      "Epoch: 106\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 41ms/sample - loss: 0.0366 - acc: 0.0056\n",
      "Epoch: 107\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0366 - acc: 0.0056\n",
      "Epoch: 108\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 41ms/sample - loss: 0.0366 - acc: 0.0056\n",
      "Epoch: 109\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 44ms/sample - loss: 0.0366 - acc: 0.0000e+00\n",
      "Epoch: 110\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0365 - acc: 0.0000e+00\n",
      "Epoch: 111\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 11s 61ms/sample - loss: 0.0365 - acc: 0.0056\n",
      "Epoch: 112\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 11s 61ms/sample - loss: 0.0365 - acc: 0.0056\n",
      "Epoch: 113\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0365 - acc: 0.0056\n",
      "Epoch: 114\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 55ms/sample - loss: 0.0365 - acc: 0.0111\n",
      "Epoch: 115\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 44ms/sample - loss: 0.0365 - acc: 0.0111\n",
      "Epoch: 116\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0365 - acc: 0.0111\n",
      "Epoch: 117\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 44ms/sample - loss: 0.0365 - acc: 0.0167\n",
      "Epoch: 118\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0365 - acc: 0.0222\n",
      "Epoch: 119\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0365 - acc: 0.0222\n",
      "Epoch: 120\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 53ms/sample - loss: 0.0365 - acc: 0.0167\n",
      "Epoch: 121\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0364 - acc: 0.0167\n",
      "Epoch: 122\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0364 - acc: 0.0167\n",
      "Epoch: 123\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0364 - acc: 0.0222\n",
      "Epoch: 124\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0364 - acc: 0.0167\n",
      "Epoch: 125\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0364 - acc: 0.0167\n",
      "Epoch: 126\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0364 - acc: 0.0167\n",
      "Epoch: 127\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0364 - acc: 0.0167\n",
      "Epoch: 128\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0363 - acc: 0.0167\n",
      "Epoch: 129\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0363 - acc: 0.0167\n",
      "Epoch: 130\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0363 - acc: 0.0222\n",
      "Epoch: 131\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0363 - acc: 0.0167\n",
      "Epoch: 132\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0363 - acc: 0.0167\n",
      "Epoch: 133\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0363 - acc: 0.0111\n",
      "Epoch: 134\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0363 - acc: 0.0111\n",
      "Epoch: 135\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0362 - acc: 0.0111\n",
      "Epoch: 136\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0362 - acc: 0.0111\n",
      "Epoch: 137\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0362 - acc: 0.0111\n",
      "Epoch: 138\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 42ms/sample - loss: 0.0362 - acc: 0.0111\n",
      "Epoch: 139\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0362 - acc: 0.0111\n",
      "Epoch: 140\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 41ms/sample - loss: 0.0362 - acc: 0.0111\n",
      "Epoch: 141\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0362 - acc: 0.0111\n",
      "Epoch: 142\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0361 - acc: 0.0111\n",
      "Epoch: 143\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0361 - acc: 0.0111\n",
      "Epoch: 144\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0361 - acc: 0.0111\n",
      "Epoch: 145\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0361 - acc: 0.0056\n",
      "Epoch: 146\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0361 - acc: 0.0056\n",
      "Epoch: 147\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0360 - acc: 0.0056\n",
      "Epoch: 148\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0360 - acc: 0.0056\n",
      "Epoch: 149\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0360 - acc: 0.0111\n",
      "Epoch: 150\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0360 - acc: 0.0111\n",
      "Epoch: 151\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0360 - acc: 0.0111\n",
      "Epoch: 152\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0359 - acc: 0.0111\n",
      "Epoch: 153\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0359 - acc: 0.0056\n",
      "Epoch: 154\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0359 - acc: 0.0056\n",
      "Epoch: 155\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0359 - acc: 0.0056\n",
      "Epoch: 156\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0359 - acc: 0.0056\n",
      "Epoch: 157\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0358 - acc: 0.0056\n",
      "Epoch: 158\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0358 - acc: 0.0111\n",
      "Epoch: 159\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0358 - acc: 0.0111\n",
      "Epoch: 160\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0358 - acc: 0.0111\n",
      "Epoch: 161\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0358 - acc: 0.0111\n",
      "Epoch: 162\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0360 - acc: 0.0056\n",
      "Epoch: 163\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0364 - acc: 0.0056\n",
      "Epoch: 164\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0359 - acc: 0.0111\n",
      "Epoch: 165\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0356 - acc: 0.0056\n",
      "Epoch: 166\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0355 - acc: 0.0111\n",
      "Epoch: 167\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0355 - acc: 0.0056\n",
      "Epoch: 168\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0355 - acc: 0.0056\n",
      "Epoch: 169\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0355 - acc: 0.0056\n",
      "Epoch: 170\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0355 - acc: 0.0056\n",
      "Epoch: 171\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0355 - acc: 0.0056\n",
      "Epoch: 172\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0354 - acc: 0.0056\n",
      "Epoch: 173\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0354 - acc: 0.0056\n",
      "Epoch: 174\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0354 - acc: 0.0056\n",
      "Epoch: 175\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0354 - acc: 0.0167\n",
      "Epoch: 176\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0354 - acc: 0.0167\n",
      "Epoch: 177\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0354 - acc: 0.0167\n",
      "Epoch: 178\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0354 - acc: 0.0222\n",
      "Epoch: 179\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0353 - acc: 0.0278\n",
      "Epoch: 180\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0353 - acc: 0.0278\n",
      "Epoch: 181\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0353 - acc: 0.0278\n",
      "Epoch: 182\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0353 - acc: 0.0333\n",
      "Epoch: 183\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0353 - acc: 0.0333\n",
      "Epoch: 184\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0360 - acc: 0.0333\n",
      "Epoch: 185\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0368 - acc: 0.0056\n",
      "Epoch: 186\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0363 - acc: 0.0167\n",
      "Epoch: 187\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0359 - acc: 0.0333\n",
      "Epoch: 188\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0358 - acc: 0.0333\n",
      "Epoch: 189\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0357 - acc: 0.0278\n",
      "Epoch: 190\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0357 - acc: 0.0333\n",
      "Epoch: 191\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0356 - acc: 0.0389\n",
      "Epoch: 192\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0356 - acc: 0.0389\n",
      "Epoch: 193\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0355 - acc: 0.0389\n",
      "Epoch: 194\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0355 - acc: 0.0444\n",
      "Epoch: 195\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0354 - acc: 0.0444\n",
      "Epoch: 196\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0354 - acc: 0.0389\n",
      "Epoch: 197\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0353 - acc: 0.0389\n",
      "Epoch: 198\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0353 - acc: 0.0389\n",
      "Epoch: 199\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0353 - acc: 0.0389\n",
      "Epoch: 200\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0352 - acc: 0.0389\n",
      "Epoch: 201\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0352 - acc: 0.0444\n",
      "Epoch: 202\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0351 - acc: 0.0444\n",
      "Epoch: 203\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0351 - acc: 0.0444\n",
      "Epoch: 204\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0350 - acc: 0.0444\n",
      "Epoch: 205\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0350 - acc: 0.0389\n",
      "Epoch: 206\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0350 - acc: 0.0444\n",
      "Epoch: 207\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0350 - acc: 0.0389\n",
      "Epoch: 208\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0349 - acc: 0.0333\n",
      "Epoch: 209\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0350 - acc: 0.0333\n",
      "Epoch: 210\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0349 - acc: 0.0278\n",
      "Epoch: 211\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0348 - acc: 0.0278\n",
      "Epoch: 212\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0348 - acc: 0.0278\n",
      "Epoch: 213\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0347 - acc: 0.0167\n",
      "Epoch: 214\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0347 - acc: 0.0111\n",
      "Epoch: 215\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0347 - acc: 0.0056\n",
      "Epoch: 216\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0347 - acc: 0.0056\n",
      "Epoch: 217\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0346 - acc: 0.0056\n",
      "Epoch: 218\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0346 - acc: 0.0056\n",
      "Epoch: 219\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0346 - acc: 0.0056\n",
      "Epoch: 220\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0346 - acc: 0.0056\n",
      "Epoch: 221\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0346 - acc: 0.0056\n",
      "Epoch: 222\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0346 - acc: 0.0056\n",
      "Epoch: 223\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0345 - acc: 0.0056\n",
      "Epoch: 224\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0345 - acc: 0.0056\n",
      "Epoch: 225\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0345 - acc: 0.0167\n",
      "Epoch: 226\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0345 - acc: 0.0111\n",
      "Epoch: 227\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0345 - acc: 0.0056\n",
      "Epoch: 228\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0344 - acc: 0.0111\n",
      "Epoch: 229\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0344 - acc: 0.0111\n",
      "Epoch: 230\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0344 - acc: 0.0056\n",
      "Epoch: 231\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0344 - acc: 0.0111\n",
      "Epoch: 232\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0347 - acc: 0.0056\n",
      "Epoch: 233\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0345 - acc: 0.0000e+00\n",
      "Epoch: 234\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0346 - acc: 0.0333\n",
      "Epoch: 235\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0343 - acc: 0.0111\n",
      "Epoch: 236\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0342 - acc: 0.0056\n",
      "Epoch: 237\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0342 - acc: 0.0056\n",
      "Epoch: 238\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0341 - acc: 0.0056\n",
      "Epoch: 239\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0341 - acc: 0.0167\n",
      "Epoch: 240\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0342 - acc: 0.0056\n",
      "Epoch: 241\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0348 - acc: 0.0111\n",
      "Epoch: 242\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0343 - acc: 0.0000e+00\n",
      "Epoch: 243\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0056\n",
      "Epoch: 244\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0056\n",
      "Epoch: 245\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0000e+00\n",
      "Epoch: 246\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0111\n",
      "Epoch: 247\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0000e+00\n",
      "Epoch: 248\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0000e+00\n",
      "Epoch: 249\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0339 - acc: 0.0000e+00\n",
      "Epoch: 250\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0000e+00\n",
      "Epoch: 251\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0000e+00\n",
      "Epoch: 252\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0342 - acc: 0.0056\n",
      "Epoch: 253\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0343 - acc: 0.0000e+00\n",
      "Epoch: 254\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0357 - acc: 0.0000e+00\n",
      "Epoch: 255\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0351 - acc: 0.0000e+00\n",
      "Epoch: 256\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0344 - acc: 0.0111\n",
      "Epoch: 257\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0344 - acc: 0.0056\n",
      "Epoch: 258\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0339 - acc: 0.0111\n",
      "Epoch: 259\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0345 - acc: 0.0056\n",
      "Epoch: 260\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0056\n",
      "Epoch: 261\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0000e+00\n",
      "Epoch: 262\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0338 - acc: 0.0000e+00\n",
      "Epoch: 263\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0375 - acc: 0.1111\n",
      "Epoch: 264\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0346 - acc: 0.2556\n",
      "Epoch: 265\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.1056\n",
      "Epoch: 266\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0339 - acc: 0.0444\n",
      "Epoch: 267\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0333\n",
      "Epoch: 268\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0339 - acc: 0.0278\n",
      "Epoch: 269\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0340 - acc: 0.0222\n",
      "Epoch: 270\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0337 - acc: 0.0167\n",
      "Epoch: 271\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0337 - acc: 0.0111\n",
      "Epoch: 272\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0337 - acc: 0.0056\n",
      "Epoch: 273\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0111\n",
      "Epoch: 274\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0111\n",
      "Epoch: 275\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0222\n",
      "Epoch: 276\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0222\n",
      "Epoch: 277\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0222\n",
      "Epoch: 278\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0222\n",
      "Epoch: 279\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0335 - acc: 0.0278\n",
      "Epoch: 280\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0337 - acc: 0.0278\n",
      "Epoch: 281\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0222\n",
      "Epoch: 282\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0000e+00\n",
      "Epoch: 283\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0337 - acc: 0.0278\n",
      "Epoch: 284\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0352 - acc: 0.0111\n",
      "Epoch: 285\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0344 - acc: 0.0278\n",
      "Epoch: 286\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0337 - acc: 0.0222\n",
      "Epoch: 287\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0338 - acc: 0.0111\n",
      "Epoch: 288\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0056\n",
      "Epoch: 289\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0111\n",
      "Epoch: 290\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0111\n",
      "Epoch: 291\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0335 - acc: 0.0056\n",
      "Epoch: 292\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0337 - acc: 0.0056\n",
      "Epoch: 293\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0334 - acc: 0.0167\n",
      "Epoch: 294\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0335 - acc: 0.0056\n",
      "Epoch: 295\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0333 - acc: 0.0111\n",
      "Epoch: 296\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0334 - acc: 0.0333\n",
      "Epoch: 297\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0334 - acc: 0.0278\n",
      "Epoch: 298\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0334 - acc: 0.0167\n",
      "Epoch: 299\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0333 - acc: 0.0278\n",
      "Epoch: 300\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0334 - acc: 0.0111\n",
      "Epoch: 301\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0333 - acc: 0.0333\n",
      "Epoch: 302\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0333 - acc: 0.0111\n",
      "Epoch: 303\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0332 - acc: 0.0167\n",
      "Epoch: 304\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0331 - acc: 0.0167\n",
      "Epoch: 305\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0336 - acc: 0.0111\n",
      "Epoch: 306\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0334 - acc: 0.0056\n",
      "Epoch: 307\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0347 - acc: 0.0056\n",
      "Epoch: 308\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0345 - acc: 0.0000e+00\n",
      "Epoch: 309\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0333 - acc: 0.0000e+00\n",
      "Epoch: 310\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0334 - acc: 0.0000e+00\n",
      "Epoch: 311\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0333 - acc: 0.0000e+00\n",
      "Epoch: 312\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0333 - acc: 0.0000e+00\n",
      "Epoch: 313\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0333 - acc: 0.0056\n",
      "Epoch: 314\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0333 - acc: 0.0000e+00\n",
      "Epoch: 315\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0333 - acc: 0.0056\n",
      "Epoch: 316\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0332 - acc: 0.0000e+00\n",
      "Epoch: 317\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0332 - acc: 0.0000e+00\n",
      "Epoch: 318\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0331 - acc: 0.0056\n",
      "Epoch: 319\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0331 - acc: 0.0000e+00\n",
      "Epoch: 320\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0331 - acc: 0.0000e+00\n",
      "Epoch: 321\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0331 - acc: 0.0000e+00\n",
      "Epoch: 322\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0331 - acc: 0.0000e+00\n",
      "Epoch: 323\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0331 - acc: 0.0111\n",
      "Epoch: 324\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0331 - acc: 0.0000e+00\n",
      "Epoch: 325\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0332 - acc: 0.0167\n",
      "Epoch: 326\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0343 - acc: 0.0056\n",
      "Epoch: 327\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0338 - acc: 0.0056\n",
      "Epoch: 328\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0334 - acc: 0.0000e+00\n",
      "Epoch: 329\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0334 - acc: 0.0056\n",
      "Epoch: 330\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0333 - acc: 0.0000e+00\n",
      "Epoch: 331\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0331 - acc: 0.0000e+00\n",
      "Epoch: 332\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0330 - acc: 0.0111\n",
      "Epoch: 333\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0330 - acc: 0.0167\n",
      "Epoch: 334\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0330 - acc: 0.0222\n",
      "Epoch: 335\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0334 - acc: 0.0111\n",
      "Epoch: 336\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0331 - acc: 0.0167\n",
      "Epoch: 337\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0329 - acc: 0.0222\n",
      "Epoch: 338\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0329 - acc: 0.0167\n",
      "Epoch: 339\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0328 - acc: 0.0111\n",
      "Epoch: 340\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0328 - acc: 0.0111\n",
      "Epoch: 341\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0329 - acc: 0.0056\n",
      "Epoch: 342\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0338 - acc: 0.0111\n",
      "Epoch: 343\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0352 - acc: 0.0167\n",
      "Epoch: 344\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0331 - acc: 0.0222\n",
      "Epoch: 345\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0328 - acc: 0.0111\n",
      "Epoch: 346\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0327 - acc: 0.0167\n",
      "Epoch: 347\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.0111\n",
      "Epoch: 348\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.0111\n",
      "Epoch: 349\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.0167\n",
      "Epoch: 350\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.0056\n",
      "Epoch: 351\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.0111\n",
      "Epoch: 352\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.0167\n",
      "Epoch: 353\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0328 - acc: 0.0167\n",
      "Epoch: 354\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.0222\n",
      "Epoch: 355\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.0167\n",
      "Epoch: 356\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.0167\n",
      "Epoch: 357\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.0167\n",
      "Epoch: 358\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0326 - acc: 0.0056\n",
      "Epoch: 359\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0330 - acc: 0.0222\n",
      "Epoch: 360\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0330 - acc: 0.0111\n",
      "Epoch: 361\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.0111\n",
      "Epoch: 362\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0326 - acc: 0.0056\n",
      "Epoch: 363\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0326 - acc: 0.0167\n",
      "Epoch: 364\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0344 - acc: 0.0000e+00\n",
      "Epoch: 365\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0332 - acc: 0.0000e+00\n",
      "Epoch: 366\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0328 - acc: 0.0000e+00\n",
      "Epoch: 367\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0325 - acc: 0.0056\n",
      "Epoch: 368\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 88ms/sample - loss: 0.0327 - acc: 0.0056\n",
      "Epoch: 369\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 54ms/sample - loss: 0.0327 - acc: 0.0056\n",
      "Epoch: 370\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0327 - acc: 0.0167\n",
      "Epoch: 371\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0325 - acc: 0.0167\n",
      "Epoch: 372\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0325 - acc: 0.0167\n",
      "Epoch: 373\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0325 - acc: 0.0278\n",
      "Epoch: 374\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0325 - acc: 0.0111\n",
      "Epoch: 375\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0324 - acc: 0.0222\n",
      "Epoch: 376\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0325 - acc: 0.0056\n",
      "Epoch: 377\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0325 - acc: 0.0222\n",
      "Epoch: 378\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0326 - acc: 0.0111\n",
      "Epoch: 379\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0328 - acc: 0.0167\n",
      "Epoch: 380\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0326 - acc: 0.0167\n",
      "Epoch: 381\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0324 - acc: 0.0222\n",
      "Epoch: 382\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0324 - acc: 0.0222\n",
      "Epoch: 383\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 43ms/sample - loss: 0.0324 - acc: 0.0222\n",
      "Epoch: 384\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0323 - acc: 0.0167\n",
      "Epoch: 385\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0323 - acc: 0.0111\n",
      "Epoch: 386\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0323 - acc: 0.0167\n",
      "Epoch: 387\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0323 - acc: 0.0167\n",
      "Epoch: 388\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0323 - acc: 0.0167\n",
      "Epoch: 389\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0322 - acc: 0.0056\n",
      "Epoch: 390\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0323 - acc: 0.0111\n",
      "Epoch: 391\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0322 - acc: 0.0111\n",
      "Epoch: 392\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0321 - acc: 0.0056\n",
      "Epoch: 393\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0321 - acc: 0.0111\n",
      "Epoch: 394\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0321 - acc: 0.0056\n",
      "Epoch: 395\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0320 - acc: 0.0056\n",
      "Epoch: 396\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 52ms/sample - loss: 0.0321 - acc: 0.0056\n",
      "Epoch: 397\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0321 - acc: 0.0056\n",
      "Epoch: 398\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0322 - acc: 0.0056\n",
      "Epoch: 399\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0335 - acc: 0.0056\n",
      "Epoch: 400\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0323 - acc: 0.0056\n",
      "Epoch: 401\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0319 - acc: 0.0056\n",
      "Epoch: 402\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0321 - acc: 0.0111\n",
      "Epoch: 403\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0329 - acc: 0.0056\n",
      "Epoch: 404\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0321 - acc: 0.0056\n",
      "Epoch: 405\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0320 - acc: 0.0111\n",
      "Epoch: 406\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0319 - acc: 0.0167\n",
      "Epoch: 407\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0325 - acc: 0.0167\n",
      "Epoch: 408\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0321 - acc: 0.0056\n",
      "Epoch: 409\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 43ms/sample - loss: 0.0319 - acc: 0.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 410\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0319 - acc: 0.0167\n",
      "Epoch: 411\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0318 - acc: 0.0167\n",
      "Epoch: 412\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0320 - acc: 0.0111\n",
      "Epoch: 413\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0321 - acc: 0.0167\n",
      "Epoch: 414\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0326 - acc: 0.0056\n",
      "Epoch: 415\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 41ms/sample - loss: 0.0324 - acc: 0.0111\n",
      "Epoch: 416\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0321 - acc: 0.0111\n",
      "Epoch: 417\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0318 - acc: 0.0056\n",
      "Epoch: 418\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0316 - acc: 0.0167\n",
      "Epoch: 419\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0317 - acc: 0.0056\n",
      "Epoch: 420\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0000e+00\n",
      "Epoch: 421\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0056\n",
      "Epoch: 422\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0316 - acc: 0.0111\n",
      "Epoch: 423\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0319 - acc: 0.0111\n",
      "Epoch: 424\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0111\n",
      "Epoch: 425\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0056\n",
      "Epoch: 426\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0000e+00\n",
      "Epoch: 427\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0000e+00\n",
      "Epoch: 428\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0056\n",
      "Epoch: 429\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0319 - acc: 0.0056\n",
      "Epoch: 430\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0318 - acc: 0.0111\n",
      "Epoch: 431\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0335 - acc: 0.0111\n",
      "Epoch: 432\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0326 - acc: 0.0000e+00\n",
      "Epoch: 433\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0318 - acc: 0.0056\n",
      "Epoch: 434\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0316 - acc: 0.0111\n",
      "Epoch: 435\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0111\n",
      "Epoch: 436\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0111\n",
      "Epoch: 437\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0111\n",
      "Epoch: 438\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0111\n",
      "Epoch: 439\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0056\n",
      "Epoch: 440\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0111\n",
      "Epoch: 441\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0056\n",
      "Epoch: 442\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0000e+00\n",
      "Epoch: 443\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0056\n",
      "Epoch: 444\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0056\n",
      "Epoch: 445\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0316 - acc: 0.0000e+00\n",
      "Epoch: 446\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0318 - acc: 0.0000e+00\n",
      "Epoch: 447\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0319 - acc: 0.0000e+00\n",
      "Epoch: 448\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0332 - acc: 0.0111\n",
      "Epoch: 449\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0325 - acc: 0.0111\n",
      "Epoch: 450\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0329 - acc: 0.0056\n",
      "Epoch: 451\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0321 - acc: 0.0111\n",
      "Epoch: 452\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0316 - acc: 0.0111\n",
      "Epoch: 453\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0167\n",
      "Epoch: 454\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0167\n",
      "Epoch: 455\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0319 - acc: 0.0111\n",
      "Epoch: 456\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0167\n",
      "Epoch: 457\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0056\n",
      "Epoch: 458\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0167\n",
      "Epoch: 459\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.0056\n",
      "Epoch: 460\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0056\n",
      "Epoch: 461\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0056\n",
      "Epoch: 462\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0056\n",
      "Epoch: 463\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.0111\n",
      "Epoch: 464\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0000e+00\n",
      "Epoch: 465\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0056\n",
      "Epoch: 466\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0320 - acc: 0.0000e+00\n",
      "Epoch: 467\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0346 - acc: 0.0333\n",
      "Epoch: 468\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0332 - acc: 0.0167\n",
      "Epoch: 469\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0323 - acc: 0.0111\n",
      "Epoch: 470\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0323 - acc: 0.0000e+00\n",
      "Epoch: 471\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0319 - acc: 0.0056\n",
      "Epoch: 472\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0316 - acc: 0.0167\n",
      "Epoch: 473\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0167\n",
      "Epoch: 474\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.0056\n",
      "Epoch: 475\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0318 - acc: 0.0056\n",
      "Epoch: 476\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0323 - acc: 0.0056\n",
      "Epoch: 477\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0328 - acc: 0.0222\n",
      "Epoch: 478\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0317 - acc: 0.0278\n",
      "Epoch: 479\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0314 - acc: 0.0000e+00\n",
      "Epoch: 480\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0313 - acc: 0.0000e+00\n",
      "Epoch: 481\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0315 - acc: 0.0000e+00\n",
      "Epoch: 482\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0312 - acc: 0.0000e+00\n",
      "Epoch: 483\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0312 - acc: 0.0000e+00\n",
      "Epoch: 484\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0311 - acc: 0.0000e+00\n",
      "Epoch: 485\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0319 - acc: 0.0056\n",
      "Epoch: 486\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0330 - acc: 0.0111\n",
      "Epoch: 487\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0336 - acc: 0.0389\n",
      "Epoch: 488\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0328 - acc: 0.0222\n",
      "Epoch: 489\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0328 - acc: 0.0278\n",
      "Epoch: 490\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0325 - acc: 0.0222\n",
      "Epoch: 491\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0327 - acc: 0.0167\n",
      "Epoch: 492\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0324 - acc: 0.0167\n",
      "Epoch: 493\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0324 - acc: 0.0111\n",
      "Epoch: 494\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0321 - acc: 0.0056\n",
      "Epoch: 495\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0321 - acc: 0.0111\n",
      "Epoch: 496\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0321 - acc: 0.0167\n",
      "Epoch: 497\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0320 - acc: 0.0056\n",
      "Epoch: 498\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0321 - acc: 0.0167\n",
      "Epoch: 499\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0320 - acc: 0.0167\n",
      "Epoch: 500\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0319 - acc: 0.0056\n",
      "Epoch: 501\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0320 - acc: 0.0000e+00\n",
      "Epoch: 502\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0325 - acc: 0.0333\n",
      "Epoch: 503\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0346 - acc: 0.0333\n",
      "Epoch: 504\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0328 - acc: 0.0056\n",
      "Epoch: 505\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0319 - acc: 0.0167\n",
      "Epoch: 506\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0315 - acc: 0.0000e+00\n",
      "Epoch: 507\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.0000e+00\n",
      "Epoch: 508\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0312 - acc: 0.0000e+00\n",
      "Epoch: 509\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0312 - acc: 0.0000e+00\n",
      "Epoch: 510\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0312 - acc: 0.0056\n",
      "Epoch: 511\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0311 - acc: 0.0056\n",
      "Epoch: 512\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0312 - acc: 0.0056\n",
      "Epoch: 513\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0313 - acc: 0.0000e+00\n",
      "Epoch: 514\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0316 - acc: 0.0111\n",
      "Epoch: 515\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0000e+00\n",
      "Epoch: 516\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0329 - acc: 0.0000e+00\n",
      "Epoch: 517\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0323 - acc: 0.0167\n",
      "Epoch: 518\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0315 - acc: 0.0000e+00\n",
      "Epoch: 519\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0312 - acc: 0.0000e+00\n",
      "Epoch: 520\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.0056\n",
      "Epoch: 521\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0312 - acc: 0.0000e+00\n",
      "Epoch: 522\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0056\n",
      "Epoch: 523\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0317 - acc: 0.0056\n",
      "Epoch: 524\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0311 - acc: 0.0000e+00\n",
      "Epoch: 525\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0222\n",
      "Epoch: 526\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0056\n",
      "Epoch: 527\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0314 - acc: 0.0056\n",
      "Epoch: 528\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0327 - acc: 0.0000e+00\n",
      "Epoch: 529\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0318 - acc: 0.0000e+00\n",
      "Epoch: 530\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0056\n",
      "Epoch: 531\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.0000e+00\n",
      "Epoch: 532\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0311 - acc: 0.0111\n",
      "Epoch: 533\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0312 - acc: 0.0167\n",
      "Epoch: 534\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0310 - acc: 0.0056\n",
      "Epoch: 535\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0111\n",
      "Epoch: 536\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0056\n",
      "Epoch: 537\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0056\n",
      "Epoch: 538\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0307 - acc: 0.0056\n",
      "Epoch: 539\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0308 - acc: 0.0056\n",
      "Epoch: 540\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0307 - acc: 0.0000e+00\n",
      "Epoch: 541\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0308 - acc: 0.0056\n",
      "Epoch: 542\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0308 - acc: 0.0111\n",
      "Epoch: 543\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0310 - acc: 0.0056\n",
      "Epoch: 544\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0308 - acc: 0.0000e+00\n",
      "Epoch: 545\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0307 - acc: 0.0056\n",
      "Epoch: 546\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0305 - acc: 0.0056\n",
      "Epoch: 547\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0309 - acc: 0.0000e+00\n",
      "Epoch: 548\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0309 - acc: 0.0056\n",
      "Epoch: 549\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0309 - acc: 0.0000e+00\n",
      "Epoch: 550\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0321 - acc: 0.0000e+00\n",
      "Epoch: 551\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0314 - acc: 0.0000e+00\n",
      "Epoch: 552\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0314 - acc: 0.0167\n",
      "Epoch: 553\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0311 - acc: 0.0056\n",
      "Epoch: 554\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0312 - acc: 0.0056\n",
      "Epoch: 555\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0308 - acc: 0.0167\n",
      "Epoch: 556\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0304 - acc: 0.0056\n",
      "Epoch: 557\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0308 - acc: 0.0000e+00\n",
      "Epoch: 558\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0308 - acc: 0.0056\n",
      "Epoch: 559\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0306 - acc: 0.0056\n",
      "Epoch: 560\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0305 - acc: 0.0000e+00\n",
      "Epoch: 561\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0305 - acc: 0.0056\n",
      "Epoch: 562\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0000e+00\n",
      "Epoch: 563\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0304 - acc: 0.0000e+00\n",
      "Epoch: 564\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0305 - acc: 0.0000e+00\n",
      "Epoch: 565\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0306 - acc: 0.0056\n",
      "Epoch: 566\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0307 - acc: 0.0056\n",
      "Epoch: 567\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0307 - acc: 0.0000e+00\n",
      "Epoch: 568\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0305 - acc: 0.0111\n",
      "Epoch: 569\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0307 - acc: 0.0111\n",
      "Epoch: 570\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0304 - acc: 0.0056\n",
      "Epoch: 571\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0304 - acc: 0.0167\n",
      "Epoch: 572\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0304 - acc: 0.0222\n",
      "Epoch: 573\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0307 - acc: 0.0111\n",
      "Epoch: 574\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0309 - acc: 0.0167\n",
      "Epoch: 575\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0312 - acc: 0.0000e+00\n",
      "Epoch: 576\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0319 - acc: 0.0000e+00\n",
      "Epoch: 577\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0310 - acc: 0.0167\n",
      "Epoch: 578\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0312 - acc: 0.0056\n",
      "Epoch: 579\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0315 - acc: 0.0056\n",
      "Epoch: 580\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0311 - acc: 0.0056\n",
      "Epoch: 581\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0306 - acc: 0.0167\n",
      "Epoch: 582\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0000e+00\n",
      "Epoch: 583\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0304 - acc: 0.0000e+00\n",
      "Epoch: 584\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0311 - acc: 0.0056\n",
      "Epoch: 585\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0311 - acc: 0.0000e+00\n",
      "Epoch: 586\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0000e+00\n",
      "Epoch: 587\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0303 - acc: 0.0056\n",
      "Epoch: 588\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0167\n",
      "Epoch: 589\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0167\n",
      "Epoch: 590\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0222\n",
      "Epoch: 591\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0056\n",
      "Epoch: 592\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0111\n",
      "Epoch: 593\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0000e+00\n",
      "Epoch: 594\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0310 - acc: 0.0278\n",
      "Epoch: 595\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0319 - acc: 0.0111\n",
      "Epoch: 596\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0167\n",
      "Epoch: 597\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.0056\n",
      "Epoch: 598\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.0000e+00\n",
      "Epoch: 599\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0056\n",
      "Epoch: 600\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.0111\n",
      "Epoch: 601\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0310 - acc: 0.0167\n",
      "Epoch: 602\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0056\n",
      "Epoch: 603\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0111\n",
      "Epoch: 604\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0000e+00\n",
      "Epoch: 605\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0000e+00\n",
      "Epoch: 606\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0056\n",
      "Epoch: 607\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0167\n",
      "Epoch: 608\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0111\n",
      "Epoch: 609\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0056\n",
      "Epoch: 610\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0303 - acc: 0.0111\n",
      "Epoch: 611\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0315 - acc: 0.0056\n",
      "Epoch: 612\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0056\n",
      "Epoch: 613\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0299 - acc: 0.0056\n",
      "Epoch: 614\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0308 - acc: 0.0111\n",
      "Epoch: 615\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0308 - acc: 0.0111\n",
      "Epoch: 616\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 11s 63ms/sample - loss: 0.0308 - acc: 0.0278\n",
      "Epoch: 617\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 54ms/sample - loss: 0.0303 - acc: 0.0111\n",
      "Epoch: 618\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 55ms/sample - loss: 0.0309 - acc: 0.0222\n",
      "Epoch: 619\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0305 - acc: 0.0167\n",
      "Epoch: 620\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0306 - acc: 0.0056\n",
      "Epoch: 621\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 43ms/sample - loss: 0.0306 - acc: 0.0278\n",
      "Epoch: 622\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0305 - acc: 0.0111\n",
      "Epoch: 623\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0305 - acc: 0.0167\n",
      "Epoch: 624\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0304 - acc: 0.0444\n",
      "Epoch: 625\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0304 - acc: 0.0167\n",
      "Epoch: 626\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0302 - acc: 0.0278\n",
      "Epoch: 627\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0302 - acc: 0.0222\n",
      "Epoch: 628\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0302 - acc: 0.0167\n",
      "Epoch: 629\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 57ms/sample - loss: 0.0311 - acc: 0.0167\n",
      "Epoch: 630\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 43ms/sample - loss: 0.0311 - acc: 0.0333\n",
      "Epoch: 631\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0302 - acc: 0.0333\n",
      "Epoch: 632\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0305 - acc: 0.0389\n",
      "Epoch: 633\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0300 - acc: 0.0389\n",
      "Epoch: 634\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 41ms/sample - loss: 0.0299 - acc: 0.0278\n",
      "Epoch: 635\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0298 - acc: 0.0278\n",
      "Epoch: 636\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0315 - acc: 0.0167\n",
      "Epoch: 637\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0319 - acc: 0.0167\n",
      "Epoch: 638\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 41ms/sample - loss: 0.0325 - acc: 0.0167\n",
      "Epoch: 639\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0308 - acc: 0.0222\n",
      "Epoch: 640\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0311 - acc: 0.0333\n",
      "Epoch: 641\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0301 - acc: 0.0389\n",
      "Epoch: 642\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0222\n",
      "Epoch: 643\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0278\n",
      "Epoch: 644\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0167\n",
      "Epoch: 645\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0299 - acc: 0.0278\n",
      "Epoch: 646\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0298 - acc: 0.0278\n",
      "Epoch: 647\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0333\n",
      "Epoch: 648\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0278\n",
      "Epoch: 649\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0309 - acc: 0.0278\n",
      "Epoch: 650\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0389\n",
      "Epoch: 651\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0299 - acc: 0.0167\n",
      "Epoch: 652\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0278\n",
      "Epoch: 653\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0318 - acc: 0.0111\n",
      "Epoch: 654\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0319 - acc: 0.0111\n",
      "Epoch: 655\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0317 - acc: 0.0389\n",
      "Epoch: 656\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0320 - acc: 0.0333\n",
      "Epoch: 657\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0316 - acc: 0.0111\n",
      "Epoch: 658\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0111\n",
      "Epoch: 659\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.0111\n",
      "Epoch: 660\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0312 - acc: 0.0056\n",
      "Epoch: 661\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0312 - acc: 0.0056\n",
      "Epoch: 662\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0312 - acc: 0.0000e+00\n",
      "Epoch: 663\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0312 - acc: 0.0056\n",
      "Epoch: 664\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0312 - acc: 0.0056\n",
      "Epoch: 665\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 41ms/sample - loss: 0.0312 - acc: 0.0111\n",
      "Epoch: 666\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0312 - acc: 0.0278\n",
      "Epoch: 667\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0311 - acc: 0.0056\n",
      "Epoch: 668\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0311 - acc: 0.0222\n",
      "Epoch: 669\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0310 - acc: 0.0167\n",
      "Epoch: 670\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0312 - acc: 0.0222\n",
      "Epoch: 671\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0317 - acc: 0.0278\n",
      "Epoch: 672\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0056\n",
      "Epoch: 673\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0311 - acc: 0.0222\n",
      "Epoch: 674\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0309 - acc: 0.0167\n",
      "Epoch: 675\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0309 - acc: 0.0222\n",
      "Epoch: 676\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0309 - acc: 0.0167\n",
      "Epoch: 677\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0310 - acc: 0.0111\n",
      "Epoch: 678\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0309 - acc: 0.0167\n",
      "Epoch: 679\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0307 - acc: 0.0278\n",
      "Epoch: 680\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0306 - acc: 0.0389\n",
      "Epoch: 681\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0056\n",
      "Epoch: 682\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0167\n",
      "Epoch: 683\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0309 - acc: 0.0056\n",
      "Epoch: 684\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0310 - acc: 0.0056\n",
      "Epoch: 685\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0309 - acc: 0.0167\n",
      "Epoch: 686\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0315 - acc: 0.0278\n",
      "Epoch: 687\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0318 - acc: 0.0278\n",
      "Epoch: 688\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0310 - acc: 0.0000e+00\n",
      "Epoch: 689\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0308 - acc: 0.0167\n",
      "Epoch: 690\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0222\n",
      "Epoch: 691\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0305 - acc: 0.0222\n",
      "Epoch: 692\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0333\n",
      "Epoch: 693\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0167\n",
      "Epoch: 694\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0167\n",
      "Epoch: 695\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0167\n",
      "Epoch: 696\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0222\n",
      "Epoch: 697\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0333\n",
      "Epoch: 698\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0111\n",
      "Epoch: 699\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0222\n",
      "Epoch: 700\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0278\n",
      "Epoch: 701\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0389\n",
      "Epoch: 702\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0311 - acc: 0.0278\n",
      "Epoch: 703\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0310 - acc: 0.0278\n",
      "Epoch: 704\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0111\n",
      "Epoch: 705\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0167\n",
      "Epoch: 706\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.0278\n",
      "Epoch: 707\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0311 - acc: 0.0333\n",
      "Epoch: 708\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0222\n",
      "Epoch: 709\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0056\n",
      "Epoch: 710\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0278\n",
      "Epoch: 711\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0222\n",
      "Epoch: 712\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0222\n",
      "Epoch: 713\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0310 - acc: 0.0000e+00\n",
      "Epoch: 714\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0316 - acc: 0.0111\n",
      "Epoch: 715\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0316 - acc: 0.0167\n",
      "Epoch: 716\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0111\n",
      "Epoch: 717\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0167\n",
      "Epoch: 718\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0333\n",
      "Epoch: 719\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0278\n",
      "Epoch: 720\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0000e+00\n",
      "Epoch: 721\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0333\n",
      "Epoch: 722\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0167\n",
      "Epoch: 723\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0302 - acc: 0.0111\n",
      "Epoch: 724\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0222\n",
      "Epoch: 725\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0278\n",
      "Epoch: 726\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0167\n",
      "Epoch: 727\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0333\n",
      "Epoch: 728\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0222\n",
      "Epoch: 729\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0305 - acc: 0.0056\n",
      "Epoch: 730\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0278\n",
      "Epoch: 731\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0222\n",
      "Epoch: 732\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0389\n",
      "Epoch: 733\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0167\n",
      "Epoch: 734\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0111\n",
      "Epoch: 735\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0303 - acc: 0.0278\n",
      "Epoch: 736\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0056\n",
      "Epoch: 737\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0444\n",
      "Epoch: 738\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0333\n",
      "Epoch: 739\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0278\n",
      "Epoch: 740\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0389\n",
      "Epoch: 741\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0444\n",
      "Epoch: 742\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0444\n",
      "Epoch: 743\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0278\n",
      "Epoch: 744\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0333\n",
      "Epoch: 745\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0222\n",
      "Epoch: 746\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0333\n",
      "Epoch: 747\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0167\n",
      "Epoch: 748\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0389\n",
      "Epoch: 749\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0500\n",
      "Epoch: 750\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0389\n",
      "Epoch: 751\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0444\n",
      "Epoch: 752\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0302 - acc: 0.0222\n",
      "Epoch: 753\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0304 - acc: 0.0389\n",
      "Epoch: 754\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0333\n",
      "Epoch: 755\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0302 - acc: 0.0278\n",
      "Epoch: 756\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0305 - acc: 0.0278\n",
      "Epoch: 757\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0778\n",
      "Epoch: 758\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0306 - acc: 0.0556\n",
      "Epoch: 759\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0389\n",
      "Epoch: 760\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0303 - acc: 0.0944\n",
      "Epoch: 761\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0300 - acc: 0.0667\n",
      "Epoch: 762\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0389\n",
      "Epoch: 763\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0611\n",
      "Epoch: 764\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0667\n",
      "Epoch: 765\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0833\n",
      "Epoch: 766\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0556\n",
      "Epoch: 767\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0889\n",
      "Epoch: 768\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0833\n",
      "Epoch: 769\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0889\n",
      "Epoch: 770\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0667\n",
      "Epoch: 771\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0722\n",
      "Epoch: 772\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0556\n",
      "Epoch: 773\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0833\n",
      "Epoch: 774\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0556\n",
      "Epoch: 775\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0500\n",
      "Epoch: 776\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0833\n",
      "Epoch: 777\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0611\n",
      "Epoch: 778\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0778\n",
      "Epoch: 779\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0667\n",
      "Epoch: 780\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0556\n",
      "Epoch: 781\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0722\n",
      "Epoch: 782\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0833\n",
      "Epoch: 783\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0611\n",
      "Epoch: 784\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0444\n",
      "Epoch: 785\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0500\n",
      "Epoch: 786\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0444\n",
      "Epoch: 787\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0611\n",
      "Epoch: 788\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0333\n",
      "Epoch: 789\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0278\n",
      "Epoch: 790\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0444\n",
      "Epoch: 791\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0389\n",
      "Epoch: 792\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0299 - acc: 0.0444\n",
      "Epoch: 793\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0298 - acc: 0.0444\n",
      "Epoch: 794\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0333\n",
      "Epoch: 795\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0167\n",
      "Epoch: 796\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0889\n",
      "Epoch: 797\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0389\n",
      "Epoch: 798\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0333\n",
      "Epoch: 799\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0389\n",
      "Epoch: 800\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0333\n",
      "Epoch: 801\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0167\n",
      "Epoch: 802\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0333\n",
      "Epoch: 803\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0167\n",
      "Epoch: 804\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0111\n",
      "Epoch: 805\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0667\n",
      "Epoch: 806\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0222\n",
      "Epoch: 807\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0222\n",
      "Epoch: 808\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0278\n",
      "Epoch: 809\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0278\n",
      "Epoch: 810\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0309 - acc: 0.0444\n",
      "Epoch: 811\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0278\n",
      "Epoch: 812\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0372 - acc: 0.0056\n",
      "Epoch: 813\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0351 - acc: 0.0167\n",
      "Epoch: 814\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0334 - acc: 0.0111\n",
      "Epoch: 815\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0329 - acc: 0.0056\n",
      "Epoch: 816\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0321 - acc: 0.0111\n",
      "Epoch: 817\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0316 - acc: 0.0056\n",
      "Epoch: 818\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0056\n",
      "Epoch: 819\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0313 - acc: 0.0056\n",
      "Epoch: 820\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0310 - acc: 0.0056\n",
      "Epoch: 821\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0310 - acc: 0.0167\n",
      "Epoch: 822\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0311 - acc: 0.0167\n",
      "Epoch: 823\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0311 - acc: 0.0111\n",
      "Epoch: 824\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0312 - acc: 0.0222\n",
      "Epoch: 825\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0312 - acc: 0.0111\n",
      "Epoch: 826\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0056\n",
      "Epoch: 827\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0056\n",
      "Epoch: 828\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0111\n",
      "Epoch: 829\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0056\n",
      "Epoch: 830\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0111\n",
      "Epoch: 831\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0111\n",
      "Epoch: 832\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0278\n",
      "Epoch: 833\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0312 - acc: 0.0111\n",
      "Epoch: 834\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0323 - acc: 0.0056\n",
      "Epoch: 835\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0310 - acc: 0.0056\n",
      "Epoch: 836\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0222\n",
      "Epoch: 837\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0278\n",
      "Epoch: 838\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0056\n",
      "Epoch: 839\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0167\n",
      "Epoch: 840\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0000e+00\n",
      "Epoch: 841\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0167\n",
      "Epoch: 842\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0167\n",
      "Epoch: 843\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0111\n",
      "Epoch: 844\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0000e+00\n",
      "Epoch: 845\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0307 - acc: 0.0167\n",
      "Epoch: 846\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0303 - acc: 0.0167\n",
      "Epoch: 847\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0000e+00\n",
      "Epoch: 848\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0000e+00\n",
      "Epoch: 849\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0000e+00\n",
      "Epoch: 850\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0111\n",
      "Epoch: 851\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0299 - acc: 0.0111\n",
      "Epoch: 852\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0056\n",
      "Epoch: 853\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0222\n",
      "Epoch: 854\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0111\n",
      "Epoch: 855\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0111\n",
      "Epoch: 856\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0307 - acc: 0.0000e+00\n",
      "Epoch: 857\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0000e+00\n",
      "Epoch: 858\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0299 - acc: 0.0222\n",
      "Epoch: 859\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0298 - acc: 0.0111\n",
      "Epoch: 860\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0056\n",
      "Epoch: 861\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0333\n",
      "Epoch: 862\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0167\n",
      "Epoch: 863\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0222\n",
      "Epoch: 864\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0303 - acc: 0.0278\n",
      "Epoch: 865\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0300 - acc: 0.0333\n",
      "Epoch: 866\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0298 - acc: 0.0056\n",
      "Epoch: 867\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 42ms/sample - loss: 0.0300 - acc: 0.0056\n",
      "Epoch: 868\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0299 - acc: 0.0389\n",
      "Epoch: 869\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 43ms/sample - loss: 0.0305 - acc: 0.0222\n",
      "Epoch: 870\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0299 - acc: 0.0333\n",
      "Epoch: 871\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 53ms/sample - loss: 0.0299 - acc: 0.0222\n",
      "Epoch: 872\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 58ms/sample - loss: 0.0295 - acc: 0.0500\n",
      "Epoch: 873\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0301 - acc: 0.0333\n",
      "Epoch: 874\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 72ms/sample - loss: 0.0298 - acc: 0.0278\n",
      "Epoch: 875\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 71ms/sample - loss: 0.0299 - acc: 0.0111\n",
      "Epoch: 876\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 67ms/sample - loss: 0.0296 - acc: 0.0500\n",
      "Epoch: 877\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 53ms/sample - loss: 0.0302 - acc: 0.0333\n",
      "Epoch: 878\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 58ms/sample - loss: 0.0297 - acc: 0.0222\n",
      "Epoch: 879\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0295 - acc: 0.0389\n",
      "Epoch: 880\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0298 - acc: 0.0556\n",
      "Epoch: 881\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 44ms/sample - loss: 0.0305 - acc: 0.0222\n",
      "Epoch: 882\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0301 - acc: 0.0111\n",
      "Epoch: 883\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0299 - acc: 0.0111\n",
      "Epoch: 884\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0305 - acc: 0.0444\n",
      "Epoch: 885\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0298 - acc: 0.0389\n",
      "Epoch: 886\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0299 - acc: 0.0167\n",
      "Epoch: 887\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0297 - acc: 0.0222\n",
      "Epoch: 888\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0296 - acc: 0.0278\n",
      "Epoch: 889\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0299 - acc: 0.0111\n",
      "Epoch: 890\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0302 - acc: 0.0000e+00\n",
      "Epoch: 891\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0294 - acc: 0.0111\n",
      "Epoch: 892\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0297 - acc: 0.0000e+00\n",
      "Epoch: 893\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0299 - acc: 0.0333\n",
      "Epoch: 894\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0300 - acc: 0.0111\n",
      "Epoch: 895\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0301 - acc: 0.0278\n",
      "Epoch: 896\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0295 - acc: 0.0278\n",
      "Epoch: 897\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0301 - acc: 0.0111\n",
      "Epoch: 898\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0301 - acc: 0.0222\n",
      "Epoch: 899\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 43ms/sample - loss: 0.0298 - acc: 0.0222\n",
      "Epoch: 900\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0296 - acc: 0.0222\n",
      "Epoch: 901\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0299 - acc: 0.0167\n",
      "Epoch: 902\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0300 - acc: 0.0222\n",
      "Epoch: 903\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0298 - acc: 0.0278\n",
      "Epoch: 904\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0297 - acc: 0.0278\n",
      "Epoch: 905\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0296 - acc: 0.0222\n",
      "Epoch: 906\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 42ms/sample - loss: 0.0294 - acc: 0.0167\n",
      "Epoch: 907\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 41ms/sample - loss: 0.0294 - acc: 0.0278\n",
      "Epoch: 908\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 41ms/sample - loss: 0.0295 - acc: 0.0278\n",
      "Epoch: 909\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0298 - acc: 0.0278\n",
      "Epoch: 910\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0296 - acc: 0.0167\n",
      "Epoch: 911\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0298 - acc: 0.0111\n",
      "Epoch: 912\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0222\n",
      "Epoch: 913\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0278\n",
      "Epoch: 914\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0298 - acc: 0.0167\n",
      "Epoch: 915\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0309 - acc: 0.0111\n",
      "Epoch: 916\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0000e+00\n",
      "Epoch: 917\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0222\n",
      "Epoch: 918\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0056\n",
      "Epoch: 919\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0295 - acc: 0.0000e+00\n",
      "Epoch: 920\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0294 - acc: 0.0056\n",
      "Epoch: 921\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0296 - acc: 0.0000e+00\n",
      "Epoch: 922\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0295 - acc: 0.0056\n",
      "Epoch: 923\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0295 - acc: 0.0278\n",
      "Epoch: 924\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0293 - acc: 0.0167\n",
      "Epoch: 925\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0297 - acc: 0.0167\n",
      "Epoch: 926\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0294 - acc: 0.0111\n",
      "Epoch: 927\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0293 - acc: 0.0167\n",
      "Epoch: 928\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0299 - acc: 0.0333\n",
      "Epoch: 929\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0296 - acc: 0.0111\n",
      "Epoch: 930\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0295 - acc: 0.0389\n",
      "Epoch: 931\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0295 - acc: 0.0111\n",
      "Epoch: 932\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0056\n",
      "Epoch: 933\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0278\n",
      "Epoch: 934\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0297 - acc: 0.0056\n",
      "Epoch: 935\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0295 - acc: 0.0111\n",
      "Epoch: 936\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0293 - acc: 0.0111\n",
      "Epoch: 937\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0295 - acc: 0.0111\n",
      "Epoch: 938\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0296 - acc: 0.0111\n",
      "Epoch: 939\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0056\n",
      "Epoch: 940\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0296 - acc: 0.0222\n",
      "Epoch: 941\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0111\n",
      "Epoch: 942\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0295 - acc: 0.0222\n",
      "Epoch: 943\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0333\n",
      "Epoch: 944\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0000e+00\n",
      "Epoch: 945\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0293 - acc: 0.0056\n",
      "Epoch: 946\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0297 - acc: 0.0111\n",
      "Epoch: 947\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0294 - acc: 0.0111\n",
      "Epoch: 948\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0291 - acc: 0.0111\n",
      "Epoch: 949\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0291 - acc: 0.0111\n",
      "Epoch: 950\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0292 - acc: 0.0111\n",
      "Epoch: 951\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0292 - acc: 0.0167\n",
      "Epoch: 952\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0294 - acc: 0.0167\n",
      "Epoch: 953\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0293 - acc: 0.0000e+00\n",
      "Epoch: 954\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0000e+00\n",
      "Epoch: 955\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0295 - acc: 0.0167\n",
      "Epoch: 956\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0293 - acc: 0.0222\n",
      "Epoch: 957\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0295 - acc: 0.0222\n",
      "Epoch: 958\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0315 - acc: 0.0167\n",
      "Epoch: 959\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0305 - acc: 0.0500\n",
      "Epoch: 960\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0298 - acc: 0.0111\n",
      "Epoch: 961\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0295 - acc: 0.0333\n",
      "Epoch: 962\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0293 - acc: 0.0222\n",
      "Epoch: 963\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0293 - acc: 0.0222\n",
      "Epoch: 964\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0293 - acc: 0.0278\n",
      "Epoch: 965\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0299 - acc: 0.0222\n",
      "Epoch: 966\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0315 - acc: 0.0056\n",
      "Epoch: 967\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0299 - acc: 0.0167\n",
      "Epoch: 968\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0295 - acc: 0.0167\n",
      "Epoch: 969\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0293 - acc: 0.0444\n",
      "Epoch: 970\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0295 - acc: 0.0222\n",
      "Epoch: 971\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0293 - acc: 0.0222\n",
      "Epoch: 972\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0292 - acc: 0.0167\n",
      "Epoch: 973\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0298 - acc: 0.0167\n",
      "Epoch: 974\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0293 - acc: 0.0167\n",
      "Epoch: 975\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0292 - acc: 0.0278\n",
      "Epoch: 976\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0000e+00\n",
      "Epoch: 977\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0308 - acc: 0.0111\n",
      "Epoch: 978\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0309 - acc: 0.0000e+00\n",
      "Epoch: 979\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0294 - acc: 0.0056\n",
      "Epoch: 980\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0295 - acc: 0.0167\n",
      "Epoch: 981\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 41ms/sample - loss: 0.0291 - acc: 0.0167\n",
      "Epoch: 982\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 42ms/sample - loss: 0.0292 - acc: 0.0333\n",
      "Epoch: 983\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 42ms/sample - loss: 0.0295 - acc: 0.0111\n",
      "Epoch: 984\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 44ms/sample - loss: 0.0292 - acc: 0.0222\n",
      "Epoch: 985\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0289 - acc: 0.0278\n",
      "Epoch: 986\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0290 - acc: 0.0167\n",
      "Epoch: 987\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0295 - acc: 0.0167\n",
      "Epoch: 988\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 56ms/sample - loss: 0.0295 - acc: 0.0167\n",
      "Epoch: 989\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 11s 59ms/sample - loss: 0.0294 - acc: 0.0111\n",
      "Epoch: 990\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 11s 62ms/sample - loss: 0.0295 - acc: 0.0222\n",
      "Epoch: 991\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 65ms/sample - loss: 0.0296 - acc: 0.0167\n",
      "Epoch: 992\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 73ms/sample - loss: 0.0293 - acc: 0.0222\n",
      "Epoch: 993\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 13s 75ms/sample - loss: 0.0296 - acc: 0.0278\n",
      "Epoch: 994\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 77ms/sample - loss: 0.0295 - acc: 0.0222\n",
      "Epoch: 995\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 14s 79ms/sample - loss: 0.0298 - acc: 0.0056\n",
      "Epoch: 996\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 86ms/sample - loss: 0.0295 - acc: 0.0056\n",
      "Epoch: 997\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 86ms/sample - loss: 0.0290 - acc: 0.0167\n",
      "Epoch: 998\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 87ms/sample - loss: 0.0292 - acc: 0.0111\n",
      "Epoch: 999\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 85ms/sample - loss: 0.0292 - acc: 0.0111\n",
      "Epoch: 1000\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 85ms/sample - loss: 0.0292 - acc: 0.0222\n",
      "Epoch: 1001\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 87ms/sample - loss: 0.0304 - acc: 0.0111\n",
      "Epoch: 1002\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 92ms/sample - loss: 0.0305 - acc: 0.0000e+00\n",
      "Epoch: 1003\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 92ms/sample - loss: 0.0296 - acc: 0.0111\n",
      "Epoch: 1004\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 93ms/sample - loss: 0.0299 - acc: 0.0056\n",
      "Epoch: 1005\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 91ms/sample - loss: 0.0295 - acc: 0.0111\n",
      "Epoch: 1006\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 16s 92ms/sample - loss: 0.0292 - acc: 0.0000e+00\n",
      "Epoch: 1007\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 17s 97ms/sample - loss: 0.0292 - acc: 0.0222\n",
      "Epoch: 1008\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 12s 68ms/sample - loss: 0.0291 - acc: 0.0111\n",
      "Epoch: 1009\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0290 - acc: 0.0056\n",
      "Epoch: 1010\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 43ms/sample - loss: 0.0292 - acc: 0.0167\n",
      "Epoch: 1011\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0294 - acc: 0.0167\n",
      "Epoch: 1012\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0297 - acc: 0.0111\n",
      "Epoch: 1013\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0296 - acc: 0.0222\n",
      "Epoch: 1014\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0295 - acc: 0.0222\n",
      "Epoch: 1015\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0444\n",
      "Epoch: 1016\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0312 - acc: 0.0111\n",
      "Epoch: 1017\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0304 - acc: 0.0111\n",
      "Epoch: 1018\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0299 - acc: 0.0000e+00\n",
      "Epoch: 1019\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0298 - acc: 0.0111\n",
      "Epoch: 1020\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0293 - acc: 0.0111\n",
      "Epoch: 1021\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0294 - acc: 0.0056\n",
      "Epoch: 1022\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0292 - acc: 0.0111\n",
      "Epoch: 1023\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0297 - acc: 0.0111\n",
      "Epoch: 1024\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0303 - acc: 0.0167\n",
      "Epoch: 1025\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0222\n",
      "Epoch: 1026\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0296 - acc: 0.0222\n",
      "Epoch: 1027\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0294 - acc: 0.0111\n",
      "Epoch: 1028\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0294 - acc: 0.0278\n",
      "Epoch: 1029\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0297 - acc: 0.0444\n",
      "Epoch: 1030\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 37ms/sample - loss: 0.0297 - acc: 0.0222\n",
      "Epoch: 1031\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0293 - acc: 0.0111\n",
      "Epoch: 1032\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0295 - acc: 0.0222\n",
      "Epoch: 1033\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0295 - acc: 0.0167\n",
      "Epoch: 1034\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0298 - acc: 0.0222\n",
      "Epoch: 1035\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0297 - acc: 0.0167\n",
      "Epoch: 1036\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0335 - acc: 0.0111\n",
      "Epoch: 1037\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0397 - acc: 0.0000e+00\n",
      "Epoch: 1038\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0402 - acc: 0.0000e+00\n",
      "Epoch: 1039\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0360 - acc: 0.0111\n",
      "Epoch: 1040\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0345 - acc: 0.0111\n",
      "Epoch: 1041\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0337 - acc: 0.0167\n",
      "Epoch: 1042\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0331 - acc: 0.0111\n",
      "Epoch: 1043\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0324 - acc: 0.0111\n",
      "Epoch: 1044\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0317 - acc: 0.0111\n",
      "Epoch: 1045\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0314 - acc: 0.0222\n",
      "Epoch: 1046\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0311 - acc: 0.0278\n",
      "Epoch: 1047\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0309 - acc: 0.0222\n",
      "Epoch: 1048\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 39ms/sample - loss: 0.0307 - acc: 0.0278\n",
      "Epoch: 1049\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0278\n",
      "Epoch: 1050\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0305 - acc: 0.0222\n",
      "Epoch: 1051\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0278\n",
      "Epoch: 1052\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0315 - acc: 0.0167\n",
      "Epoch: 1053\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0306 - acc: 0.0111\n",
      "Epoch: 1054\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0278\n",
      "Epoch: 1055\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0389\n",
      "Epoch: 1056\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0222\n",
      "Epoch: 1057\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0222\n",
      "Epoch: 1058\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0324 - acc: 0.0111\n",
      "Epoch: 1059\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0056\n",
      "Epoch: 1060\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0314 - acc: 0.0111\n",
      "Epoch: 1061\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0056\n",
      "Epoch: 1062\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0056\n",
      "Epoch: 1063\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0056\n",
      "Epoch: 1064\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0444\n",
      "Epoch: 1065\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0556\n",
      "Epoch: 1066\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0311 - acc: 0.0111\n",
      "Epoch: 1067\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0302 - acc: 0.0167\n",
      "Epoch: 1068\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0309 - acc: 0.0167\n",
      "Epoch: 1069\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0111\n",
      "Epoch: 1070\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0312 - acc: 0.0222\n",
      "Epoch: 1071\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0334 - acc: 0.0000e+00\n",
      "Epoch: 1072\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0056\n",
      "Epoch: 1073\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0297 - acc: 0.0111\n",
      "Epoch: 1074\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0296 - acc: 0.0167\n",
      "Epoch: 1075\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0294 - acc: 0.0000e+00\n",
      "Epoch: 1076\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0000e+00\n",
      "Epoch: 1077\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0294 - acc: 0.0000e+00\n",
      "Epoch: 1078\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0300 - acc: 0.0278\n",
      "Epoch: 1079\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0301 - acc: 0.0389\n",
      "Epoch: 1080\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0294 - acc: 0.0056\n",
      "Epoch: 1081\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0291 - acc: 0.0222\n",
      "Epoch: 1082\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0293 - acc: 0.0056\n",
      "Epoch: 1083\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0297 - acc: 0.0056\n",
      "Epoch: 1084\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0299 - acc: 0.0111\n",
      "Epoch: 1085\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0293 - acc: 0.0056\n",
      "Epoch: 1086\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0309 - acc: 0.0222\n",
      "Epoch: 1087\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0298 - acc: 0.0056\n",
      "Epoch: 1088\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0296 - acc: 0.0000e+00\n",
      "Epoch: 1089\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0294 - acc: 0.0056\n",
      "Epoch: 1090\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0293 - acc: 0.0111\n",
      "Epoch: 1091\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0292 - acc: 0.0111\n",
      "Epoch: 1092\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0296 - acc: 0.0111\n",
      "Epoch: 1093\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0304 - acc: 0.0111\n",
      "Epoch: 1094\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0339 - acc: 0.0000e+00\n",
      "Epoch: 1095\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0344 - acc: 0.0000e+00\n",
      "Epoch: 1096\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 38ms/sample - loss: 0.0308 - acc: 0.0056\n",
      "Epoch: 1097\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 7s 40ms/sample - loss: 0.0301 - acc: 0.0000e+00\n",
      "Epoch: 1098\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 43ms/sample - loss: 0.0299 - acc: 0.0167\n",
      "Epoch: 1099\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 56ms/sample - loss: 0.0296 - acc: 0.0056\n",
      "Epoch: 1100\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 15s 83ms/sample - loss: 0.0292 - acc: 0.0056\n",
      "Epoch: 1101\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 57ms/sample - loss: 0.0293 - acc: 0.0056\n",
      "Epoch: 1102\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0293 - acc: 0.0056\n",
      "Epoch: 1103\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 54ms/sample - loss: 0.0293 - acc: 0.0167\n",
      "Epoch: 1104\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0296 - acc: 0.0500\n",
      "Epoch: 1105\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0292 - acc: 0.0167\n",
      "Epoch: 1106\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0293 - acc: 0.0222\n",
      "Epoch: 1107\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0296 - acc: 0.0111\n",
      "Epoch: 1108\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0298 - acc: 0.0167\n",
      "Epoch: 1109\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0317 - acc: 0.0167\n",
      "Epoch: 1110\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 54ms/sample - loss: 0.0302 - acc: 0.0222\n",
      "Epoch: 1111\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0300 - acc: 0.0167\n",
      "Epoch: 1112\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0294 - acc: 0.0056\n",
      "Epoch: 1113\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0289 - acc: 0.0056\n",
      "Epoch: 1114\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0291 - acc: 0.0167\n",
      "Epoch: 1115\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0288 - acc: 0.0389\n",
      "Epoch: 1116\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0291 - acc: 0.0222\n",
      "Epoch: 1117\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0296 - acc: 0.0222\n",
      "Epoch: 1118\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0303 - acc: 0.0056\n",
      "Epoch: 1119\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0298 - acc: 0.0167\n",
      "Epoch: 1120\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0298 - acc: 0.0000e+00\n",
      "Epoch: 1121\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0313 - acc: 0.0167\n",
      "Epoch: 1122\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0297 - acc: 0.0111\n",
      "Epoch: 1123\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0305 - acc: 0.0167\n",
      "Epoch: 1124\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0301 - acc: 0.0000e+00\n",
      "Epoch: 1125\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0290 - acc: 0.0222\n",
      "Epoch: 1126\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0302 - acc: 0.0056\n",
      "Epoch: 1127\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0300 - acc: 0.0556\n",
      "Epoch: 1128\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0292 - acc: 0.0222\n",
      "Epoch: 1129\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0291 - acc: 0.0000e+00\n",
      "Epoch: 1130\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0322 - acc: 0.0389\n",
      "Epoch: 1131\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0310 - acc: 0.0111\n",
      "Epoch: 1132\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0303 - acc: 0.0278\n",
      "Epoch: 1133\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0298 - acc: 0.0111\n",
      "Epoch: 1134\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0292 - acc: 0.0222\n",
      "Epoch: 1135\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0290 - acc: 0.0167\n",
      "Epoch: 1136\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0291 - acc: 0.0056\n",
      "Epoch: 1137\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0289 - acc: 0.0333\n",
      "Epoch: 1138\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0290 - acc: 0.0111\n",
      "Epoch: 1139\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0289 - acc: 0.0167\n",
      "Epoch: 1140\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0293 - acc: 0.0278\n",
      "Epoch: 1141\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0306 - acc: 0.0222\n",
      "Epoch: 1142\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0298 - acc: 0.0111\n",
      "Epoch: 1143\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0301 - acc: 0.0222\n",
      "Epoch: 1144\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0297 - acc: 0.0444\n",
      "Epoch: 1145\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0300 - acc: 0.0056\n",
      "Epoch: 1146\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 52ms/sample - loss: 0.0297 - acc: 0.0889\n",
      "Epoch: 1147\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0291 - acc: 0.0389\n",
      "Epoch: 1148\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0294 - acc: 0.0444\n",
      "Epoch: 1149\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0298 - acc: 0.0278\n",
      "Epoch: 1150\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0296 - acc: 0.0167\n",
      "Epoch: 1151\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 52ms/sample - loss: 0.0295 - acc: 0.0333\n",
      "Epoch: 1152\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0299 - acc: 0.0444\n",
      "Epoch: 1153\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0292 - acc: 0.0111\n",
      "Epoch: 1154\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0289 - acc: 0.0111\n",
      "Epoch: 1155\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0288 - acc: 0.0278\n",
      "Epoch: 1156\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0289 - acc: 0.0222\n",
      "Epoch: 1157\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0291 - acc: 0.0222\n",
      "Epoch: 1158\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0293 - acc: 0.0056\n",
      "Epoch: 1159\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0301 - acc: 0.0111\n",
      "Epoch: 1160\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0323 - acc: 0.0111\n",
      "Epoch: 1161\n",
      "Train on 180 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0299 - acc: 0.0222\n",
      "Epoch: 1162\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0289 - acc: 0.0111\n",
      "Epoch: 1163\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0287 - acc: 0.0389\n",
      "Epoch: 1164\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 54ms/sample - loss: 0.0288 - acc: 0.0111\n",
      "Epoch: 1165\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0287 - acc: 0.0278\n",
      "Epoch: 1166\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0298 - acc: 0.0333\n",
      "Epoch: 1167\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0289 - acc: 0.0167\n",
      "Epoch: 1168\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0287 - acc: 0.0222\n",
      "Epoch: 1169\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0288 - acc: 0.0111\n",
      "Epoch: 1170\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0287 - acc: 0.0167\n",
      "Epoch: 1171\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0286 - acc: 0.0278\n",
      "Epoch: 1172\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0288 - acc: 0.0167\n",
      "Epoch: 1173\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 52ms/sample - loss: 0.0290 - acc: 0.0056\n",
      "Epoch: 1174\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 43ms/sample - loss: 0.0362 - acc: 0.0167\n",
      "Epoch: 1175\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 47ms/sample - loss: 0.0321 - acc: 0.0278\n",
      "Epoch: 1176\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0320 - acc: 0.0000e+00\n",
      "Epoch: 1177\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 44ms/sample - loss: 0.0297 - acc: 0.0111\n",
      "Epoch: 1178\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0291 - acc: 0.0222\n",
      "Epoch: 1179\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0291 - acc: 0.0111\n",
      "Epoch: 1180\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 47ms/sample - loss: 0.0290 - acc: 0.0056\n",
      "Epoch: 1181\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0289 - acc: 0.0111\n",
      "Epoch: 1182\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0295 - acc: 0.0000e+00\n",
      "Epoch: 1183\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0290 - acc: 0.0000e+00\n",
      "Epoch: 1184\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0286 - acc: 0.0056\n",
      "Epoch: 1185\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0284 - acc: 0.0056\n",
      "Epoch: 1186\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0288 - acc: 0.0000e+00\n",
      "Epoch: 1187\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0293 - acc: 0.0111\n",
      "Epoch: 1188\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0295 - acc: 0.0000e+00\n",
      "Epoch: 1189\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0298 - acc: 0.0000e+00\n",
      "Epoch: 1190\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 49ms/sample - loss: 0.0289 - acc: 0.0111\n",
      "Epoch: 1191\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 51ms/sample - loss: 0.0320 - acc: 0.0389\n",
      "Epoch: 1192\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0305 - acc: 0.0056\n",
      "Epoch: 1193\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0296 - acc: 0.0111\n",
      "Epoch: 1194\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 45ms/sample - loss: 0.0294 - acc: 0.0056\n",
      "Epoch: 1195\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 50ms/sample - loss: 0.0290 - acc: 0.0222\n",
      "Epoch: 1196\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0294 - acc: 0.0111\n",
      "Epoch: 1197\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 8s 46ms/sample - loss: 0.0296 - acc: 0.0111\n",
      "Epoch: 1198\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 9s 48ms/sample - loss: 0.0302 - acc: 0.0056\n",
      "Epoch: 1199\n",
      "Train on 180 samples\n",
      "180/180 [==============================] - 10s 53ms/sample - loss: 0.0301 - acc: 0.0111\n",
      "Forecasting Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaitanya_kr_01/tensorflow-test/env/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2022-04-20 00:51:42.800439: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=1, Predicted=10.185080, Expected=9.510000\n",
      "Month=2, Predicted=9.792234, Expected=9.796000\n",
      "Month=3, Predicted=9.631711, Expected=9.468500\n",
      "Month=4, Predicted=9.662391, Expected=9.672000\n",
      "Month=5, Predicted=9.592472, Expected=9.610000\n",
      "Month=6, Predicted=9.484620, Expected=9.240000\n",
      "Month=7, Predicted=9.611415, Expected=10.318300\n",
      "Month=8, Predicted=10.153664, Expected=8.974800\n",
      "Month=9, Predicted=9.358297, Expected=9.114000\n",
      "Month=10, Predicted=9.482252, Expected=9.300000\n",
      "Month=11, Predicted=9.150344, Expected=8.400000\n",
      "Month=12, Predicted=8.783471, Expected=9.300000\n",
      "Month=13, Predicted=9.132126, Expected=9.000000\n",
      "Month=14, Predicted=9.375132, Expected=9.300000\n",
      "Month=15, Predicted=9.618020, Expected=9.460000\n",
      "Month=16, Predicted=9.293428, Expected=9.145000\n",
      "Month=17, Predicted=9.186658, Expected=9.021000\n",
      "Month=18, Predicted=8.856647, Expected=8.750000\n",
      "Month=19, Predicted=9.075768, Expected=8.710000\n",
      "Month=20, Predicted=8.553813, Expected=8.370000\n",
      "Month=21, Predicted=8.720698, Expected=8.504000\n",
      "Month=22, Predicted=8.548256, Expected=9.819700\n",
      "Month=23, Predicted=9.653701, Expected=9.827300\n",
      "Month=24, Predicted=9.897521, Expected=9.929800\n",
      "Month=25, Predicted=9.776946, Expected=9.288000\n",
      "Month=26, Predicted=9.664200, Expected=9.300000\n",
      "Month=27, Predicted=9.142893, Expected=9.060000\n",
      "Month=28, Predicted=9.050457, Expected=8.835000\n",
      "Month=29, Predicted=8.674657, Expected=8.388600\n",
      "Month=30, Predicted=8.499224, Expected=8.400000\n",
      "Month=31, Predicted=8.430977, Expected=8.525000\n",
      "Month=32, Predicted=8.384621, Expected=8.250000\n",
      "Month=33, Predicted=8.385603, Expected=8.419000\n",
      "Month=34, Predicted=8.434657, Expected=9.455000\n",
      "Month=35, Predicted=9.288963, Expected=8.540000\n",
      "Month=36, Predicted=8.923423, Expected=9.455000\n",
      "Month=37, Predicted=9.287165, Expected=9.000000\n",
      "Month=38, Predicted=9.376421, Expected=9.599000\n",
      "Month=39, Predicted=9.444802, Expected=9.436000\n",
      "Month=40, Predicted=9.744837, Expected=9.539800\n",
      "Month=41, Predicted=9.750637, Expected=9.028600\n",
      "Month=42, Predicted=9.235924, Expected=8.932000\n",
      "Month=43, Predicted=8.784805, Expected=8.993000\n",
      "Month=44, Predicted=8.828492, Expected=8.678400\n",
      "Month=45, Predicted=9.006572, Expected=9.011100\n",
      "Month=46, Predicted=9.342643, Expected=9.630000\n",
      "Month=47, Predicted=9.473665, Expected=8.590400\n",
      "Month=48, Predicted=8.973874, Expected=9.736300\n",
      "Month=49, Predicted=9.568424, Expected=9.384500\n",
      "Month=50, Predicted=9.767063, Expected=9.947200\n",
      "Month=51, Predicted=9.785187, Expected=9.577100\n",
      "Month=52, Predicted=9.416603, Expected=9.117200\n",
      "Month=53, Predicted=9.200441, Expected=9.122500\n",
      "Month=54, Predicted=9.113410, Expected=8.880000\n",
      "Month=55, Predicted=8.916766, Expected=8.709200\n",
      "Month=56, Predicted=8.548909, Expected=8.428200\n",
      "Month=57, Predicted=8.804763, Expected=9.907600\n",
      "Month=58, Predicted=9.745217, Expected=9.145000\n",
      "Month=59, Predicted=8.980307, Expected=8.498000\n",
      "Month=60, Predicted=8.879763, Expected=9.362000\n",
      "Month=61, Predicted=9.196282, Expected=9.000000\n",
      "Month=62, Predicted=9.380081, Expected=9.455000\n",
      "Month=63, Predicted=9.305238, Expected=9.300000\n",
      "Month=64, Predicted=9.160182, Expected=8.990000\n",
      "Month=65, Predicted=9.322138, Expected=8.990000\n",
      "Month=66, Predicted=8.916525, Expected=8.790000\n",
      "Month=67, Predicted=8.825628, Expected=8.835000\n",
      "Month=68, Predicted=9.041228, Expected=8.700000\n",
      "Month=69, Predicted=8.726682, Expected=8.935000\n",
      "Month=70, Predicted=8.947160, Expected=8.835000\n",
      "Month=71, Predicted=8.688332, Expected=8.265000\n",
      "Month=72, Predicted=8.593803, Expected=8.835000\n",
      "Month=73, Predicted=8.667417, Expected=8.550000\n",
      "Month=74, Predicted=8.656832, Expected=8.680000\n",
      "Month=75, Predicted=8.995415, Expected=8.400000\n",
      "Month=76, Predicted=8.529702, Expected=8.525000\n",
      "Month=77, Predicted=8.857357, Expected=8.370000\n",
      "Month=78, Predicted=8.388422, Expected=7.890000\n",
      "Month=79, Predicted=7.994839, Expected=7.812000\n",
      "Month=80, Predicted=7.657885, Expected=7.620000\n",
      "Month=81, Predicted=7.981403, Expected=7.718000\n",
      "Month=82, Predicted=7.689881, Expected=8.323500\n",
      "Month=83, Predicted=8.160233, Expected=6.860000\n",
      "Month=84, Predicted=7.243498, Expected=8.308000\n",
      "Month=85, Predicted=8.143074, Expected=8.100000\n",
      "Month=86, Predicted=8.483210, Expected=8.525000\n",
      "Month=87, Predicted=8.454625, Expected=8.250000\n",
      "Month=88, Predicted=8.358632, Expected=8.215000\n",
      "Month=89, Predicted=8.061510, Expected=8.122600\n",
      "Month=90, Predicted=7.964231, Expected=7.778100\n",
      "Month=91, Predicted=8.053182, Expected=7.954600\n",
      "Month=92, Predicted=7.941774, Expected=7.420000\n",
      "Month=93, Predicted=7.492932, Expected=7.538300\n",
      "Month=94, Predicted=7.578452, Expected=7.905000\n",
      "Month=95, Predicted=7.758539, Expected=7.140000\n",
      "Month=96, Predicted=7.523444, Expected=8.432000\n",
      "Month=97, Predicted=8.268449, Expected=7.710000\n",
      "Month=98, Predicted=7.583573, Expected=7.967000\n",
      "Month=99, Predicted=7.800367, Expected=7.320000\n",
      "Month=100, Predicted=7.506458, Expected=7.502000\n",
      "Month=101, Predicted=7.354859, Expected=7.409000\n",
      "Month=102, Predicted=7.296423, Expected=7.200600\n",
      "Month=103, Predicted=7.571652, Expected=7.865000\n",
      "Month=104, Predicted=7.711517, Expected=6.690000\n",
      "Month=105, Predicted=7.073489, Expected=6.879400\n",
      "Month=106, Predicted=7.263572, Expected=7.440000\n",
      "Month=107, Predicted=7.278450, Expected=6.860000\n",
      "Month=108, Predicted=7.242209, Expected=7.595000\n",
      "Month=109, Predicted=7.430665, Expected=7.200000\n",
      "Month=110, Predicted=7.108865, Expected=7.130000\n",
      "Month=111, Predicted=6.962735, Expected=6.900000\n",
      "Month=112, Predicted=7.189108, Expected=7.130000\n",
      "Month=113, Predicted=7.196277, Expected=7.130000\n",
      "Month=114, Predicted=6.967586, Expected=6.840000\n",
      "Month=115, Predicted=7.014055, Expected=7.006000\n",
      "Month=116, Predicted=6.929207, Expected=6.780000\n",
      "Month=117, Predicted=6.925493, Expected=7.089600\n",
      "Month=118, Predicted=7.029975, Expected=6.882000\n",
      "Month=119, Predicted=6.734381, Expected=6.446700\n",
      "Month=120, Predicted=6.735886, Expected=6.882000\n",
      "Month=121, Predicted=6.734511, Expected=6.600000\n",
      "Month=122, Predicted=6.695333, Expected=6.820000\n",
      "Month=123, Predicted=6.815890, Expected=6.600000\n",
      "Month=124, Predicted=6.649657, Expected=6.820000\n",
      "Month=125, Predicted=6.864978, Expected=6.665000\n",
      "Month=126, Predicted=6.516320, Expected=6.450000\n",
      "Month=127, Predicted=6.665501, Expected=6.665000\n",
      "Month=128, Predicted=6.695784, Expected=6.450000\n",
      "Month=129, Predicted=6.539453, Expected=6.722100\n",
      "Month=130, Predicted=6.777365, Expected=6.820000\n",
      "Month=131, Predicted=6.653072, Expected=6.160000\n",
      "Month=132, Predicted=6.534284, Expected=6.820000\n",
      "Month=133, Predicted=6.653518, Expected=6.480000\n",
      "Month=134, Predicted=6.511275, Expected=6.596900\n",
      "Month=135, Predicted=6.928060, Expected=6.492000\n",
      "Month=136, Predicted=6.539566, Expected=6.510000\n",
      "Month=137, Predicted=6.344856, Expected=6.339500\n",
      "Month=138, Predicted=6.209838, Expected=6.001600\n",
      "Month=139, Predicted=6.299016, Expected=6.107000\n",
      "Month=140, Predicted=6.465315, Expected=5.790000\n",
      "Month=141, Predicted=6.105341, Expected=5.885000\n",
      "Month=142, Predicted=6.243288, Expected=7.280000\n",
      "Month=143, Predicted=7.113040, Expected=5.941600\n",
      "Month=144, Predicted=6.325096, Expected=6.810000\n",
      "Month=145, Predicted=6.642338, Expected=6.182000\n",
      "Month=146, Predicted=6.301984, Expected=6.293000\n",
      "Month=147, Predicted=6.137396, Expected=6.118600\n",
      "Month=148, Predicted=6.191339, Expected=6.138000\n",
      "Month=149, Predicted=6.005618, Expected=6.107000\n",
      "Month=150, Predicted=5.977155, Expected=5.913000\n",
      "Month=151, Predicted=6.175957, Expected=6.141100\n",
      "Month=152, Predicted=6.173812, Expected=6.248000\n",
      "Month=153, Predicted=6.080505, Expected=5.829700\n",
      "Month=154, Predicted=6.203174, Expected=6.829300\n",
      "Month=155, Predicted=6.665511, Expected=6.694400\n",
      "Month=156, Predicted=7.077572, Expected=7.726200\n",
      "Month=157, Predicted=7.559268, Expected=7.054400\n",
      "Month=158, Predicted=7.271680, Expected=7.268900\n",
      "Month=159, Predicted=7.106999, Expected=7.020000\n",
      "Month=160, Predicted=6.911960, Expected=6.510000\n",
      "Month=161, Predicted=6.515908, Expected=6.370500\n",
      "Month=162, Predicted=6.204095, Expected=5.730000\n",
      "Month=163, Predicted=5.849445, Expected=5.828000\n",
      "Month=164, Predicted=5.665516, Expected=5.580000\n",
      "Month=165, Predicted=5.679939, Expected=5.709900\n",
      "Month=166, Predicted=6.021035, Expected=6.696000\n",
      "Month=167, Predicted=6.529032, Expected=6.248000\n",
      "Month=168, Predicted=6.627747, Expected=6.711600\n",
      "Month=169, Predicted=6.560455, Expected=6.600100\n",
      "Month=170, Predicted=6.982207, Expected=7.508200\n",
      "Month=171, Predicted=7.593251, Expected=7.765000\n",
      "Month=172, Predicted=7.597383, Expected=7.285000\n",
      "Month=173, Predicted=7.122783, Expected=6.959500\n",
      "Month=174, Predicted=6.792825, Expected=6.450000\n",
      "Month=175, Predicted=6.539304, Expected=6.572000\n",
      "Month=176, Predicted=6.614914, Expected=6.600000\n",
      "Month=177, Predicted=6.432343, Expected=4.265300\n",
      "Month=178, Predicted=4.648790, Expected=7.367000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month=179, Predicted=7.199240, Expected=6.544000\n",
      "Month=180, Predicted=6.925963, Expected=6.940800\n",
      "Train RMSE: 0.47629\n",
      "Train RMSPE: 6.95605\n",
      "Train MAE: 0.30780\n",
      "Train MAPE: 4.08386\n",
      "Forecasting Testing Data\n",
      "Month=1, Predicted=6.798157, Expected=6.786000\n",
      "Month=2, Predicted=6.670634, Expected=6.981200\n",
      "Month=3, Predicted=6.926765, Expected=6.756000\n",
      "Month=4, Predicted=6.781712, Expected=6.733200\n",
      "Month=5, Predicted=6.592599, Expected=6.671200\n",
      "Month=6, Predicted=6.527202, Expected=6.295600\n",
      "Month=7, Predicted=6.669382, Expected=6.432500\n",
      "Month=8, Predicted=6.480776, Expected=6.153000\n",
      "Month=9, Predicted=6.286453, Expected=6.389500\n",
      "Month=10, Predicted=6.407813, Expected=7.192000\n",
      "Month=11, Predicted=7.027386, Expected=6.524000\n",
      "Month=12, Predicted=6.907028, Expected=7.238500\n",
      "Month=13, Predicted=7.073020, Expected=6.990000\n",
      "Month=14, Predicted=7.064592, Expected=7.254000\n",
      "Month=15, Predicted=7.325483, Expected=6.720000\n",
      "Month=16, Predicted=6.836428, Expected=6.944000\n",
      "Month=17, Predicted=6.781039, Expected=7.052500\n",
      "Month=18, Predicted=6.884970, Expected=6.690000\n",
      "Month=19, Predicted=7.053145, Expected=6.909900\n",
      "Month=20, Predicted=6.747817, Expected=6.819000\n",
      "Month=21, Predicted=6.687127, Expected=7.167200\n",
      "Month=22, Predicted=7.097568, Expected=7.254000\n",
      "Month=23, Predicted=7.089907, Expected=6.664000\n",
      "Month=24, Predicted=7.036658, Expected=7.393500\n",
      "Month=25, Predicted=7.228658, Expected=7.125000\n",
      "Month=26, Predicted=7.239605, Expected=7.347000\n",
      "Month=27, Predicted=7.350459, Expected=7.216500\n",
      "Month=28, Predicted=7.062811, Expected=7.254000\n",
      "Month=29, Predicted=7.088730, Expected=7.238500\n",
      "Month=30, Predicted=7.118419, Expected=6.990000\n",
      "Month=31, Predicted=7.094539, Expected=7.192000\n",
      "Month=32, Predicted=7.173591, Expected=6.900000\n",
      "Month=33, Predicted=6.782596, Expected=7.427300\n",
      "Month=34, Predicted=7.273209, Expected=7.300500\n",
      "Month=35, Predicted=7.682305, Expected=6.902000\n",
      "Month=36, Predicted=7.207562, Expected=7.409000\n",
      "Month=37, Predicted=7.256985, Expected=7.179000\n",
      "Month=38, Predicted=7.212873, Expected=7.424500\n",
      "Month=39, Predicted=7.505027, Expected=7.275000\n",
      "Month=40, Predicted=7.118879, Expected=7.316000\n",
      "Month=41, Predicted=7.161555, Expected=7.086300\n",
      "Month=42, Predicted=6.963326, Expected=7.020000\n",
      "Month=43, Predicted=6.856892, Expected=7.270500\n",
      "Month=44, Predicted=7.173383, Expected=7.168800\n",
      "Month=45, Predicted=7.019999, Expected=7.448600\n",
      "Month=46, Predicted=7.386015, Expected=7.440200\n",
      "Test RMSE: 0.30351\n",
      "Test RMSPE: 4.33553\n",
      "Test MAE: 0.23507\n",
      "Test MAPE: 3.35816\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAELCAYAAADHksFtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABp30lEQVR4nO2dd3hcxfW/39lV7122iiX33o2NC8bGdFNCCxAglBBCaCEQCCRACKRAQgiEYH4hFPNNqMGYjummGdwL7k1dsnpbtW3z+2Puqq+0u1r1eZ9nH0m3zD17vb6fPXPOnCOklGg0Go1G4w5Tfxug0Wg0moGNFgqNRqPRdIkWCo1Go9F0iRYKjUaj0XSJFgqNRqPRdElAfxvQGyQkJMjMzMz+NkOj0fQjBw4cAGDixIn9bMngYOvWrWVSysTO9g1JocjMzGTLli39bYZGo+lHli1bBsD69ev71Y7BghAix90+PfWk0Wg0mi4Zkh6FRqPR3HPPPf1twpBBC4VGoxmSnHzyyf1twpBBC4VGoxkQ2Gw28vPzaWxs9Mt4VqsVgKCgIL+MN1QICQkhLS2NwMBAj8/RQqHRaAYE+fn5REZGkpmZiRCix+PprKeOSCkpLy8nPz+f0aNHe3yeDmZrNJoBQWNjI/Hx8X4RCU3nCCGIj4/32mvTQqHRaAYMWiR6H1/usRYKLykthTVr+tsKjUaj6Tu0ULRiyRL49a+7PuaFF+DCC6G2tm9s0mg0A48zzzyTqqqqLo+57777+OSTT3waf/369Zx11lk+ndsb6GB2K4qLITe362NcAtHQAJGRvW+TRqPxjdTUVL+PKaVESsn777/f7bEPPPCA36/fX2iPohWRkd17CvX16mdTU+/bo9FofCciIoKIiAivz3v00UeZNm0a06ZN47HHHiM7O5vJkydzww03MGfOHPLy8sjMzKSsrAyABx98kEmTJnHKKadw6aWX8sgjjwBw1VVX8frrrwOqrNDvfvc75syZw/Tp09m/fz8AmzZtYtGiRcyePZtFixY1Z2oNNLRH0YrxQTk4Sk1AuttjXELhp1RvjUbTCbfeCjt29GwMh8MBgNlsBmDWLHjssa7P2bp1K88//zwbN25ESsmCBQs48cQTOXDgAM8//zyrVq1qc/yWLVtYs2YN27dvx263M2fOHObOndvp2AkJCWzbto1Vq1bxyCOP8MwzzzBp0iS+/PJLAgIC+OSTT/jNb37DmgEYBNVC0YqndhzPl+FnAs+6Paa+ThKElcbG4L4zTKPReE2T4faHhYV5fM7XX3/NeeedR3h4OADnn38+X331FRkZGRx//PGdHn/uuecSGhoKwNlnn+127PPPPx+AuXPn8sYbbwBQXV3NlVdeyaFDhxBCYLPZPLa1L9FC0Yqq8FRiGwq7PGbu/hf5K7eSXVMAaLHQaHqD7r75e8KBA3mAdwvupJSdbncJh6fHd0ZwsHpemM1m7HY7APfeey/Lly9n7dq1ZGdnN1e8HWjoGEUraiNTSbQWdHnMiPI9JFCOvayqb4zSaDR9xtKlS3nzzTepr6+nrq6OtWvXcsIJJ7g9fsmSJbzzzjs0NjZisVh47733vLpedXV1c9B99erVPTG9VxkwQiGEeE4IUSKE2N1qW5wQ4mMhxCHjZ2xv2lAXk0qyo2uhCK0vB8BeqfNjNZqhxpw5c7jqqquYP38+CxYs4NprryU21v1j57jjjuOcc85h5syZnH/++cybN4/o6GiPr3fnnXdy9913s3jx4uaYyoDEle7V3y9gKTAH2N1q21+Au4zf7wIe9mSsuXPnSl/4bMUfpARpq6l3e8zncedJCfKLv2/16RoajaZz9u7d69fx9u/fL/fv3+/XMTujtrZWSillXV2dnDt3rty6deA/Gzq718AW6eaZOmBiFFLKL4UQme02nwssM35/AVgPdLMkzndsScoFrDtUSPScsZ0eE9GkPApntfYoNJqBTHq6++xFf3Ldddexd+9eGhsbufLKK5kzZ06fXLcvGTBC4YZkKWURgJSySAiR1JsXc4xQQtFwuMCtUETbVO60rNFCodEMZLzJduoJL730Up9cpz8ZMDGKniKEuE4IsUUIsaW0tNS3MdKVUNhy3Gc+RduVRzHUhaKsDLZu7W8rNBrfqampoaampr/NGBL4JBRCiOOFEPcLIdYJIXYZweZvhRCrhRBX+zHoXCyEGGlccyRQ4u5AKeXTUsp5Usp5iYmJPl0sYJQSCkeum4C2lMQ6lVCIWv9/ANeuhRtu8PuwPvHII7BsGXSX/edFdqBG06cUFRVRVFTU32YMCbwSCiHElUKI74ENwK1AGHAI2AhUAguAZ4ACQzQ874zROW8DVxq/Xwm81cPxuiRsRBR1hEGBG6GoqSEQlf8sLP71KORv7+Hjm97imWcGxsO3sBAsFlUt1x3V1RATAz7WPdNoNIMEj4VCCLETeAh4H5gLxEopl0opL5BSXi6lPFNKORmIA34KJAF7hBAXezj+y8C3wEQhRL4Q4ifG9U4RQhwCTjH+7jUiowQFpGI+1rlQOEvKmn831flRKJqakA89xPWF92KzqYKD/U25cpzIz3d/TEkJ1NTA3r19Y5NGo+kfvPEongdGSyl/LaXcbqRTdUBKWS2lfFFKeSawEKjyZHAp5aVSypFSykApZZqU8lkpZbmUcoWUcrzxs8ILe70mMhIKSCWotHOhsBaVN/9urvePUEgJu14/iMnpYAbfM43vqaz0y9A9wiUUeXnuj3EVRtTTwBpNR1qXCn/77bd56CH333Orqqra1JEqLCzkwgsv7HUbPcVjoZBSPial9KoUnpRyp5TyQ+/N6h+iopRQhFQU8Prr0L7sSlNBi0cR0OCfp+PmzfCny/c0//0jXqKbMvd9QmW5E4GzS4/CJRS6N4dmOOHLwrhzzjmHu+66y+3+9kKRkpLSXHl2IDBksp78QWQk5JBBeGU+V1zUwJtvtt1vK1Zfs60EEtjgn6djWRlMYzdOk5nyWSdxKS9TWe70y9g+88YbvHd0EgeYqD0KzaAlIyODjIwMr87Jzs5m0qRJXHnllcyYMYMLL7yQ+vp6MjMzeeCBB1iyZAn/+9//+Oijj1i4cCFz5szhoosuwmKxALBu3TomTZrEkiVLmgv/gSrPcdNNNwFQXFzMeeedx8yZM5k5cyYbNmzgrrvu4siRI8yaNYs77riD7Oxspk2bBqhe4ldffTXTp09n9uzZfP75581jnn/++Zx++umMHz+eO++8E1BCdtVVVzFt2jSmT5/O3//+9x7fS5/WUQghYqWUA2CCxL8EBsKmwCUE2P7EIjZw9OiKNvsdx5RHkUMGgY3+EYrGRpjKHqwZ46k+72rG7LiCgm83wNIlPR983z648krIyoKnnlKt+brA4YD/rHZw5a1XkuFsJBA75Vk1QFSnxzfVWvkP17A9/z5gQs/t1Whc+KHOeEj7DZ7UGQcOHDjAs88+y+LFi7nmmmuav+mHhITw9ddfU1ZWxvnnn88nn3xCeHg4Dz/8MI8++ih33nknP/3pT/nss88YN24cF1/ceXj2lltu4cQTT2Tt2rU4HA4sFgsPPfQQu3fvZofxnrOzs5uPf/LJJwH4/vvv2b9/P6eeeioHDx4EYMeOHWzfvp3g4GAmTpzIzTffTElJCQUFBezeraohddeJzxO69SiEEDOFENuFENuEEFOEEO8Cx4QQuUKIGT22YICxK2oJNgI4ic/Iymq7z1lWjh0z+aQR1OSfr9EuobCNn4rznB9QTygJH/lpAc+6dWpuq6ICvvuu28M3bIBHrt2HsFj4mFMAaDrifu7JlJfD5bzIuGyd9qQZeNjt9uYqrd6Qnp7O4sWLAbj88sv5+uuvAZof/N999x179+5l8eLFzJo1ixdeeIGcnBz279/P6NGjGT9+PEIILr/88k7H/+yzz/j5z38OqEqy3dWG+vrrr7niiisAmDRpEhkZGc1CsWLFCqKjowkJCWHKlCnk5OQwZswYjh49ys0338y6deuIiur8i543eOJR/AP4PRCNynh6QEp5lhDiQuCvwGk9tmIAYYqOZFP5fE7iMx7IclJeCt/vMbFsGVBWRgVxVBPNaGtWd0N5hK2mgbEcoXbSpcSkRfAW5/KDja+B7XHl4vSEI0dU4CU6Ws1xdUNtLRzHZgDe4HzO5ANMBXnAlE6Pd9Yod1v4MwNMowG/1Bk/YnSL86bMOIAQotO/XaXGpZSccsopvPzyy22O27FjR4dz/YGbvCGgpXQ5tJQvj42NZefOnXz44Yc8+eSTvPbaazz33HM9ssGTGEWUlPJNKeULgFlK+Zxh/OuoFNghRVQUfM5yjmMzz32WQd7Sy1i+HD79FEwV5ZSRQC2RhNj883AMzdmPGSdMnUp0NLzMpYTWlYPxLaZHHDkC48ZBYmLXCyIMGhqUUFjMUXyKmnYLLs3H6SZk4qytAyCgXgcpNEOH3Nxcvv32WwBefvlllixpOw18/PHH880333D48GEA6uvrOXjwIJMmTSIrK4sjR440n9sZK1as4KmnngJUPKGmpobIyEhq3WSFLF26lBdffBGAgwcPkpub26X4lZWV4XQ6ueCCC3jwwQfZtm2bF+++c7wNZn/Rw/MHPJGR8AknE4CDcHs1s/a/wil8xE9+ArKsnHLiqTd1IxRSwl//CocOdXs9c7labB6QkUpgIOSFTVI73C3684bDh2HsWCUUXXgUS5fCqlUtQrGNueSThhPBSEee21OlRQlFkJ8ywDSagcDkyZN54YUXmDFjBhUVFc3TRC4SExNZvXo1l156KTNmzOD4449n//79hISE8PTTT7Ny5UqWLFniNpD++OOP8/nnnzN9+nTmzp3Lnj17iI+PZ/HixUybNo077rijzfE33HADDoeD6dOnc/HFF7N69eo2nkR7CgoKWLZsGbNmzeKqq67iz3/+c89viruysq4X8AkQ2cn2EcCm7s7vj5evZcallHLlSinBKX+a9r6Mp1QeZJw8EjxJmrHJsuCR8iUukU+E/1o2iSD3g+TnSwlS3nVXt9f734/ekBJk03fbpJRSTk2pUOf+/e8+vwcppbzzNpu0iQBlw2WXSTl6dKfHOZ1Sms1SXnedlM882SibCJQPcacEKWujRspnuEZu2dL5NT66fo2UIF8J/nGPbNVopBwYZcazsrLk1KlT/WrHQMTbMuPdegRSypOllJ19fW4EPFp1PZiIjAQQhJx3BuUkcC8PMqZpP7/hT8Q3FfEuZ+EMjyRIWsFq7XwQI9uAVpkL7pD1ahl2YLSqdGmOi8YhzB7FFLoi68s8AqSdpvSxOOPdexS1tSrbqb4ewrJ2E4SNLcwDwDEynTTy3a+lqFMeRYhNexQazVDG56kjKWWVlNI/Ed0BhBIKOEUl/fAmP8AeFct9PICVQN7lLGSEcZC7lWZ7jAV07dOmOkE01Kuf4UooomNNVAfEexRT6IrIEjVPuqlsLH95LkHZ6lr40ArXKvD6eggoUQXUcsjAZILA0Wmkk0dxsZuLGLnj4c7azobWaPqV0aNHM3q0d+XmMjMzm9NKNS34LBRCiLOFEL8WQlwrhDhOCOF+0mwQkZgIoaFq3h5AhIRguvwyAnDwMadQQ7SKeIOKIxgPyza4hMIDj6K5sFNoKACxsVBpSuixRxFfpYTizqfHcdRiVNPtZMzWQmGuVhVSKogjNhaCxqUroTjWedaFaFAeRRQ1enW2xi9IP1bEDAoKIigoyG/jDRV8uce+lhl/AlXJ9UHgaeA7oNYoOb5aCHGzL+MOBG67Db78UmWUJibC7Nlguu5aHJh4iR8BKoUWgFNPhc5ypV3fSIqL2fh5fZfXc3kUGE1WYmKghK6Dz51dzmZTr++/V7H05LojNBLMxoJUykhQB3bipVRWSN7iHBYf/Q8BNS1CER8PARlpRGKhOq/zqSVTvXuhsNlg506P34JGQ0hICOXl5X4Ti4qKCioqerU83KBDSkl5eTkhIR2WI3aJrx3uLkOtr7gNCAVmArNbvS4GnvBx7H4lPl69AO66C0aNAmbO5L7Ls3jpv+mEhNAy9VRcrJ7MrXE6VTlVIyX1/qtz+CB7stvrmZoMj8L4h4uNhRJHApTt88je8nK14PT550EIuOoqlWw1w7GdbDEaKU2U4t6jcO7YxTm8gyiPIyBaZWlUE82keMBoJenMyUMto2lne2OLUJS205JXX4Uf/xj274cJetG2xgPS0tLIz8/H18Zj7Tl27BgAI0aM8Mt4Q4WQkBDS0tK8OsdXobACb0spnUAdqj/FBtdOIcRAb7HqEbfd1vJ7xJRRgPri74xotdIxN1dFg83mlr8tFmznXkjgi6sJzM/C4ZjcvLs9pqZ6GkUIISbl3MXEQJE9AVlaiidLdyor1eWLi5VQOBxw7P8+4hQ+4b2Ff+TcRIjIS4BtdOpRxH7xJgDRjSXY6iKpIgYnZiWWhlAEFOYA0zqcG9Cgpt2iqOFIO6HIzlaezUcfaaHQeEZgYKDXMYWucKW1rl+/3m9jDld8jVG8Bix1t1NK6f26+QGOS4DDwlp5FAB2u+ry48KIT+zOWKnOc2R3uSQioKmeJlNo89+xsaipovJy3K50a0W9MXNlsahXADYm/vMmDjCBpptu5803IWa84VF0IhRpm9cCEG0rJaSugpqAOBISlEPEZOUJJRV/3+E8ZbvyKCKoo6ZSVdQ8fBgcf/gTC9f8CtBNjTSaoYCvQnEPcKYQ4jx/GjOQMb5cExoKjtgEnAjkCqNoYE5Oy4FGfOLN2hU0EsxosrpMfjJbG2gytzSBj4mBUhIRTiee1Bt3CUVdnXpdzKvElR3iVzxCTLLKLwhNicWJ6Dj1lJVFUtFO7JiJtZcS0lhJTWAcr70Gv/kNEBtLeWQmY6q3d3ptl1AANJRaqK6GqVOh8dFVrNjxNxbwHZ9/rrRUo9EMXnwVinhU69PXjYKBDwkhfiiEGO9H2wYUrT0Ke3wyC/mWpoceA6BkczagnutN2/ZAairvbYglPyCTTLI5etT9uAG2+jZC0exRAJbs7gPabTyKWsmd/IXDodN4l7OINTqXJySbKSceW2E7j2Kzquu0nmXEO0sJa6zAEhjH8uWq8gdAadpsptm2d5r+GmhtEYqm0hrKyyHJmkd4pXKhHuFX1NRIjv3kN3Dttd2+F41GMzDxVSj+CywG1gCFwI+BV4D9QohqIUT7Uh+DntZCERICm1hAQ8pYAJ68I5uqKrjuOsh9fzeOydPYtg0co0YzmX1dehSBtgZsAS1TTzExLULxxH0e1GeqauJjTiYpexMZhz9lBt/zV3kHIIiLU8ckJKgxrUXthMfwhDYxn3DqiW/Ipz44ts0hlvGzmcAhSo92zH9tLRTWshosFlhkhKrWRF3NEr5hNtuJWfu8ClZoNH3I66+/PqCa/wxmfBWK2cD1UsofSilXSilTgJHASuBhwN0SrUFLSIiat3cJBUCjCKUqJJl0RzYVFVCU7yDNso+KlKlICXVLTmcae7Bt63yOHyDQXo8toMWjmD8fTr9cxRSKdnfvUTgLijiZT5mY8xGpRcpD+G/jBQDNHkVioprOch5rJzzZ2dQGxHAEJXhJ1gLqQ+LaHOKYPgsAy4ZdHa4dZLNgM/Ih7BVKKBbyLQ2mMH7rfBCAu4P/TkTtMSgq8ijmotH4i4SEBBISEvrbjCGBr0KRhZp6akZKWSylXCel/JOU8oc9N23gMW2a8iyahaIRjjrV9JLFAjEVRwmlkQPmqQCIKy7HKoKYve1Zt2MG2RuwB7Z4FCEh8Ms/qg93Y16Z2yohLuxVKvMouiaP6Oo8yomjnnDM5pZV5omJhpdS1k4ocnIoDMpsSZ8FGsLaCkXQgtnqOps7ximC7XVUBKnUQ3tlbbNHsc10HAcsqRSlzOGCphcNQ+09Xm2u0XjD6tWrWb16dX+bMSTwVSj+DvzEn4YMBt58U1VZdQnF0aNw0JpJBjnU1UFqtcp4+rBApZJmzo1nR+YPOPnYfzotnwEQ7KjHHhTWdqPxLSjWWYZRUt8tjio1JRRXl0dcXR55qKh7XJxKl3UNV0wygRXtHL2cHHJFRhuhsIa3FYrYaamUkEjojg20J9heR0XwSACc1TXUVzQym+18YV8EQPHsMzDRavFU6+wwjaaX0ULhP3wVisXAHCHES0KIcf40aCATFaWmnlwVftevV3WRMsjBUuMks1ZlPP1n6xRiY9XUT+7xPyROVtC4sfNlykHOBhxBoW03hoXhDAklkdIO6/na42oelNCYR0JDi1DEtgo1JCYqoQixlKsl06AWOWRnc9SRQVNkK6GIaBujSB4heI0fkrnlddpXBwxx1FEVooRC1NQgjh4hEDvfMx2AuqVnAHDA1SZVC4VGMyjxVSjmoGISlwAHhBBZQog1QojfCiHOEEIk+8/EgYfLo/j8c8gmkyBs2POKGNu4hywyySmPYKya9id8pkoEK/g2p/OxnPU4gsM6bBcjkhkvjrCrY2igDbJGeRTJ1jySrG09ChfR0VBqMlanuqZ/KivBYuFgUyaBqS39p+yRbT2K0FB4KvwOpFNy9Ma/td3nrKM63BCK2hrMuSpqf5QxAASdsICj8y/h9/xOnaCFQqMZlPgkFFLKmUAEMBf4KfAukAz8GngPlQk1ZHEJxaZNUButHswyN48MxxEOoYTBlV563IWqLMahj7I7H0s24AzpRCjOP58z5bsUbcrr0hZZa6yOdlYT66ygQHQUCiGgIcrQbqOsgatgYZbMICY9kiZU8TR7VFuhAAiekMFL8lKS3v43lgojaGK1Eiht1IYpATJZagguVEKRhVpdm5waQN5fXuZ/XKTO0UKh0QxKelJm3Cal3C6lfE5KebOUcgmqINBkMKrn+QkhxC+EELuFEHuEELf6c2xfcAmFzQaTT1F5s/bsfDLIIQclDC6PImFsNDUBsZRvzUb+/bE26wkcDgijHhnSbuoJ4JZbMAsnCzb/s0tbRF3b6rX1CR2nngCscYZH4aoZbqTG5pBBappojlPI2I5C8dFHkHTN2URQR847hotj9KKwhsXQZA7FXF9LWEkWdYQ1j5WcDGPGgJ1A6iOTtFBoNIMUv7YyNRolHZBSvuqvMYUQ01Bey3xU8cGz+nthX+vCiydebtRDyj5EMiUdhALAOjKTmOps6p97Gd5+u3l7U6MklAacoR09CjIyODjtAi6x/JvKCvfVNE11bdc3mEZ19CgAZFI7j8IQimwySUujJaDdXmFQwfCJV8wHoPpTlYLrEgpHSDiNQVEENtYQVXqUHNNooqIEMTEqlpOSAkFBUBWa0iIU//0v3H+/2/ek0fiD999/n/fff7+/zRgS+Fpm/Gf+NqQLJgPfSSnrjRpSXwD9WjrEJRQjR8LxZ8ZRTygjj6qsoMYkVTywtVBETs9kHIcJ2r+rTQ2nxlobATiae1G0x7lwMXFUsu/rcre2mBvaehQh4zv3KCLGKqGw5RdTVAT2I9nYQ8KpII7U1K6FAmDUklGUkEjAtk1qgyEUztBwbCFRBDfVEFOVRX7gGNLTlTcBqlZiZiYUyBTsuYZQrFoFT3hQXHjHDhV012h8ICwsjLCwTr6EabymW6EQQpzT/gX8vtXvvc1uYKkQIl4IEQacCUbEtq2d1wkhtgghtvirTLE7XFlPK1dCQKAgX6QztkQJRfqiUSQnqzUXzcdPzGQiBwm0NyqRMGo4NVUa3e3cfJiT56pprbxv3fUiVUJRT6iq5QQkzkpl9GjVR6M1P/ppOLVE8N1bxYwdC/nv7qR65CRAMGaMEop6QgmK7ly0zAGCA1HzSc42hMJo2OQMDcceFkWMrCS+JotjoaM54QQ4/viWcydMgB2lKZTuKiTnqEM1qqio6LqW1ZYt6k18+aX7YzSaLli1ahWrVq3qbzOGBJ6UA38T+BZVWtxFNPBLQAJvd3KO35BS7hNCPAx8DFiAnUCHMnNSyqdRTZSYN29er34NTU2Fk09WJTsAjgWkM8F2EIA552VwbG27EzIz2/5dVgZxcVirVS8KEdb5wzluhhKKsh35wKxOjwlsrKWSWEyqTCExycGd1pZauhTygpLJ33oMGzZG5m1k5/yfQhZMmQKrORMrQe6cGwBKMuezeNf7qq2q4VHI8Agqx8xlecFqgu1WSiJG89RTbc/7xz+gsCGF5E+L+eB/+8hwFajKyqLkX2sJO/cUIs44oe1J+4x+HNnZcOKJ7o3SaNzw2muvAXDDDTf0syWDH0+mnlwL626TUi6XUi4Hjhm/n9SLtjUjpXxWSjlHSrkUqAAO9cV13REcDB9/DMcdp/4uCTYa/CAIyEjteEJ7oTA8HmtV237Z7RHpSijqDrj3KAKtFmqJJJdR5DKK8PDOjxMCgjNGkEwxSyN3EOxoYHvYEpKTVaOml7iMa3ierjx159zjMCGxrN+Cs9YQirBw8lf+jGDje0R59JgO540eDcefn4IJifPdljljx+ZtJP3rQXbc9EzHi7kq8rpt2K3RaPqKboVCSvk8cCnwFyHEfUIIM9CnE8dCiCTj5yjgfODlvrx+d5SHqgd6ESMJi+mkR68hFI0Yc1ZGuW9bjfIoTBFuns4jRuAQZkRBvtsyScHWWupEBLfzN27nb0REuLczeXoyS8Yd4/ppXwPwuXUxmZlK+FyruLvyKOKWqvm0Y18dwlathEJEhsOcOWzECHbHdt54xrxQ7V+y8ZHmJk/1LynXKzhrX8fqHlooNJoBg0fBbCllLnAqqpvd1+B64vUZa4QQe4F3gBullJXdndCXVEYojyKHjM4f1BkqE+orjOkVQyjsNcqjMEe4eTqbzTTEpJBozW/T8qI1ITYL1qAIvmEJX3OCW48CgBEjCKooZoblG7LIZP3BFDIylEi4PImuhGLispE4MFG+Mw+7SyjCw4mNhT/yW3YzldpkNwv1Z8/mcOqJxNpKkTNmImNiCNuguhpNlPt5/rl23z1cb7ikBD79FG4etG3YNZpBj8dZT0bq69+Aa4EHe8+kTq99gpRyipRyppTy0768tifUGIvuchnVuVBER1N782/4M3erv42vz/Za5VGYI93P98jUNNLId/VD6kCIw4ItpKXjXlceBcnJUFFBZvZ6vmYJxcUts2KeCEVaZgDF5hTqD+ThMIoRmqIiiImBdziH6ewmOMb9APmXqK53b+fN5pB9DGabqn8VRS3rnlU9LBYsgIcfpq1H8cor8M9/uq2XpdFoehev02OllHuklP+vN4wZrNTFdSMUQMTjf2RzxElYA0KbPQpHrfIoAiLdP1zNmUoo3K1VC3PU4gxtuWiXHoWRsxrYWMu/UBnO7YWiu2zCurh0zIV5zcUITZHhxMS07O9KqFKuPZPHuYWHy65hp0XFMiwmJXLhefuRErZtgy+/kKr3OCihMFaR6+qzGm9Yv3697pftJ7wSCiFEqBDiViHE50KIYiGE1XgVG9tuNVJYhxWWxNFUEMsW5rn9Ri6EShOtCkhoEQqL8igCo93fsuCxSiiOFXUeFgpzWlrqidONRzF9OoSFUf/cq3zDEqBFKFwC05VHAWDOSGeELY+abYcpIRFzlOdCMW6CibdPepwldyxqLvOxNV0ticls3EdFhapGXrm/WNVwN5nU1JOr81NJSdfGaTSaXsGT9FgAhBDpwGdAJvAN8DoqA0kAscAU4C/AjUKIFUZcY1gQGBNOMsUEhwVg6kJ6Z82C/O2JiP1lJO7di7mkSJ0f1YVHMSqNCOqozq0GYtrss9kgAgsiykOPYtEiqK4mIiCAmJvVMgYjfOLR1BNA7PQ0Qra8zbHde9nLFIKDISBACYSlrWZ1wGRS4QaAB14cA4VQftzpNJW8xeSGfRwyctlErjHtNG0a7NmjFimCDmxrvOKRRx4B4Fe/+lU/WzL48cajeAxoAMZLKZdJKW+UUt4rpbzH+H05MAEV8P57L9g6YImIUPWMIiJFl8c99BA0hidQuCkf5/wFzHxVxSyCYrpwwowerM7cjimyDfWSCCwExngoFKCe6qiUVfBeKGKmpxNKI6nFW9nH5ObFhy6vokuPphXRK0/gIOMJO+NEatMmM5kWoUh1GEIxf74qiOUqja49Co0XvPvuu7z77rv9bcaQwBuhOBn4rZQy290Bxr77jGOHDa6HY3cPycREGL8ogZlyJ6Y6C0GNap7fE6EwF3R00BrK6zEhEVGRBAermkqBgZ7ZPHasssclLJ7GKIRRSypIWtnH5OZyJt4Kxco7p3LjyQeZ/4MUmsZNYw7byN5Tx3X8i2t4DoA7X5/f9iTtUWg0/YI3QuHN2olhVaDH9bDt9ts8EJbesYdvV5lCTJ4MwMjijq1IG8tU5pGIjCAiwvOHNMC998Lzz7eyK0zFUYI6WQbSBkO4gOapJ2gpEeWpDePGqUWLcXFQd9FVRFPD0ldv5F9cz+l8yDHTSDZVtav9qD0KjaZf8DhGAXwC/FEIsVtKmdXZAUKITFTq7Md+sG3Q4KlHARA6SgmFNSCUIHsDTgQh0V0sS4mNpSh+GjMqv0bKloVxAI2lRuZRVATh4d7Vz5sxQ71chIWpaSfR9ewZpLeU2eps6qmrGIU7gpcvYgtzOTH7BQoZyUliPRZnGJG0qow7YoT2KDSafsIbj+JWIBQ4KIT4SgjxlBDiT0KIPxq/fwkcNI75ZS/YOmDxRihMSapK6/pRV2IzB9NAKIFBXT+dj004gQXODViqHW22WyuUR2GOifTao2hPbCxtspfckpyM0xxADZEUkuJzjKI18QmCvxsfmd/yR4KnT6CANEowOu+NHKmCKdqj0HhBaGgood0F3TQe4c2Cu3xgBvAroAn4AXC78fd5gA24A5hlHDts8EYoSFAexSemU8kduYB6wrr9Fm+ZuYRoaqj4om0DbVuF+sYdEKM8Ck+mvtxx113w5pseHGg24xiRyl6mAMLnqafWhIfD/wJ+xAK+Y03EVUyZoraPnh2LjQCVw5uUpD0KjVd88MEHfPDBB/1txpDAm6knpJQNwOPGS2PgTYyC007j7dm/49WCM5gwV1JTtoXbujlFLl4C/w9sn39N2eJZnHwy/OtfIIzV0YFxkcyYgdt6UJ6QkqJenmC+9Rb+dVciOPCLRyGE8io2HVtARjz85Ccq2G6zmSjYnoqdcezfEsxKttDdzJgLq1UVnX3wQVXpV6PR+I5fO9wNV7zyKCIj2Xne/eSWhPBO4Pk8nvSnbk+JmTGKHEYR+dmbrHldsnMnfPIJOKqVUATFRfDMM/Dccz14E15g+tVtbJxwBdAiFIlG3yOPpq86wdWRLz5ePdj/8Ae1QPEHvMlFh//MzqIkNfXkiRqWllLzu0fY+101+gvl8OXBBx/kwQf7tNrQkMXvQiGEWCqE+Mzf4w5kvBIKWtYuvPceLF/e/fHJyfAYt5L8/acUPPUWAAcP0lxGIzi+B8EJHxlvJCS5hOLKK2Hduo4tWD0lPl79bH3+hAmwk1nsKE2lmGSEwwGVHtSDfOEFEh66g++ZTsPWvb4ZpBn0fPrpp3z66YArDTco6Q2PIhEYVp1mvBUKV9kMhwPOPbf74xMS4ElxM/lx07l21y0kUMrBgxCeq5r7BCdGeW90D5kwQf10CUVkJJx2mu/jtfYo2l8DoCnKCGx7EqfIzsYerLKmztl6n1d2/Oc/cM01Xp2i0Qx5vCnhMcrDQxN9tGXQ4hIIT4PJLo8iJAROPbX7481miE8O4NLKZ/mQE/kifCWv7ziPmY1/41VxMedmdN7nujf58Y+VXT3JtGpNZx5FUhJERSnBmJaWBG+CraCEQFe02x05OVTGj+PZwjO4w/JXbEdyCRzr2cf3889hzZq+m8bTaAYD3ngU2UCWB69h16Q2MVGV57joIs+OT01VD9mTT/ZcXE44AXKTj2PtD19hYsN27mv8DbtCFrBq7nPNq6P7kunT1Xvudt2Fh3TmUQgBjz0GjzwCU1eMAODw18e6Hywnh7KwDFahWmDWPuz5R7KxUXV67UligEYz1PAm66kB+BJVDLAr5gHX+WzRIEQI+PWvPT8+IACefFKVMvIUo/0vcA4fv3KMay+1kN+Yxq9OMntj6oClM48C4Oqr1c/saJWSZTlQ0OHc+nrYuxfmzTM25ORQkHIieYziY05h0YfvAg95ZEdjo1q4aLEob0YzeIlv/a1D0yO8EYqdgENK+WxXBwkhqhhmQuELP/uZ7+eOnhdPLuo/wdKlfjKon+nMo2hNwtho6giDgo5C8eyzcPvtKs79zCNV/KKmhqwRGYwdC3uOTGVF0ZfKReiqtK9Bg6r8TnW1ForBzpo1a/rbhCGDN1NPW4G5Hh7rpwkJTWdkZqrif0LAkiX9bY1/cOdRuAiPEBSKVAJLOgpFYaEqMFtfD1vfUJVn9zdmMmUKFIePJdDWAEVFHtkxonwPP2At1dU+vQ2NZkjijVA8BFzS3UFSyjVSSr0+oxcJCFBF9WbNgujo/rbGP0ybpkTCXZxaCCgLSiWssqNQVFSon01NEGdRQrGpOIORI8GWoXp4V2454pEd52X/nae5jpoa79+DZmBx9913c/fdd/e3GUMCj6eepJQFQMf/pZp+YdUq+iWI3VtMnNjSn8gd1eEpZFq+7bDdtbSisRES65VQHGjKYMVIWH77WPgJPHTtYe4+cWm3CwLDrFXEUkl1lUQ7xoObb7/t+FnR+Ib+5j9IWbYMjj++v63oW+piUolrLOxQJtclFE1NMKIhm3pCKSWRkSPhxB9n4DQHEFV2hH//u/trhNpqCMBBXWl9L7wDjWZw4rFQCCHeEkLM9uL4ECHEbUKI630zTaNpS1NCKsGyqYPrMf3oWxxgAlaLlRFNOeQyChCMHAkEBGDKzGBR0mH+8Y+WZnnuCLOrOafGY1W98h40msGINx5FLvCdEGKjEOIWIcQcIUSbqSshRIoQ4gdCiGeBIuAaYJsf7dUMY5wjUwGQ+W1nQMeVb2QCh7CXVZFoL6IQlUo7cqTrgHHMjjpCfj688UbX1wh3KKGwlupotkbjwpsy4zcDU4BNwP3AZqBRCFEhhCgSQjQCecAbwFRU/4oZUspN/jZaMzwxj1JCUXewrVBE1Ks+FY5qC6FOCxah8lqbm/GNHUt06WFCQySbN3d9jXCnEgp7WZXf7Nb0D2lpaaS16sio8R1vy4wfAW4WQtwOLAQWAClACFAO7Ae+lFLm+NNIIcQvgWtRLVa/B66WUjb68xqagU/wmBahcFUOcTgg1qbqP9mr6wh11jFyYgTvPdrWoxDV1cwaW0rQtqPwQSWccUan14iUSigcFdqjGOz897//7W8ThgxeCYULKaUV+MJ49SpCiFTgFmCKlLJBCPEaKk13dW9fWzOwiByvyng0HW3xKKqqIIkWjyICC1Xh4Zx5ZqsTT1Q1Kq80/5ezv/kHbKlQxQXbdT+TdgdRrvarVVW99TY0mkHHYMl6CgBCjZhIGFDYz/Zo+oHE1CCKScKZZwhFaSmVFbJZKKyVdURgwRHWrlLhnDmwcCHXHPkNKdYcVcypk3Z+TeWW5t9FjfYoBju33nort956a3+bMSQY8EJhrN94BBVMLwKqpZQftT9OCHGdEGKLEGJLaWlpX5up6QOSkiCfNMyFeZCfD6mpON9+l2TU1JOtopYw6pHthQLgppsIdDSxl8k4R2VQ/cQLHQ5pLGlZZWeqreavfwXdzmDwsmPHDnbs2NHfZgwJBrxQCCFigXOB0ah4SLgQ4vL2x0kpn5ZSzpNSzktMHHaVzocFCQmQTSahJTmwbx/YbAR++wVhGAWaSksxIXF2JhQXXkjB9NP4NQ/zzegriPj2Y45+27a3ha28RSjMlip++1v4v//rzXek0QwOBrxQACcDWVLKUimlDZVVtaifbdL0A0FBUBycQVRVDmRlARC585vm/QFlRgnyzmq3BwVx+Il1vMvZPHPgBMw4qdp8CFAL9m6+GSyFLUJhK6vGZtOhCo0GBodQ5ALHCyHChBACWAHs62ebNP1ETWwGQfYG2KSyrmOztjbvC6o0PAQ33ZRcDaN2HEsGoDFHHb9uHfzzn7BvY4tQRDmrAPedVz/7DOx2X9+FRjO4GPBCIaXciOqBsQ2VGmsCnu5XozT9xtSVmQDUf7AeALOjZal1aK0hFJGdC0Vqqqo0fgyVPeUoUB5IXp7a32DEKBpFCNGoYHZnHsXBg7BiBbz/fg/eiKbXmTBhAhNa99PV+IxP6bF9jZTyd8Dv+tsOTf9z2nUZ8CyEFXasBhtuUUJhiui8bWBgIKSkQGF+Ag5Mzf23XUJhLVHiUBqSTkxDFWnkYa+IBto2pnC17XbnbWgGBk8/rb9P+gufPQohxJVCiHVCiL1CiKPtXp7VdNZovCRofEbz7474lqSFGiKJblAeginKfSPvjAwwB5opIxGzEdPIz1f7bBXKo6iMHEUMVXzLQm4uuafDGC4vw9XkSNO7OBzd1+jS9C4+CYUQ4l7geVQW0g5aFt+5Xl/6yT6Npi0xMdjD1Tf8gkknA1BtjqVKxBJrVV/1zdHuhWLlSrj8cqgISia4Sh0vDh1kC3OJKTkIQENcGmM5QhoFTLJ93yEWoYWib3nggVZtbr3guuuu47rrdLNNf+Dr1NNPgMellL/0pzEaTbcIgWl0Buz+nu8iVjCKl6kOSqLBaiLCkQt0LRSuPjbfrRlBTK3yKGZlv8lctpFWcoxaIpBxcYTQBMA4DlNd3bZFa1UVnMh6miyLgcDeeJeDmj/8QTXUuvlm/4z31VewZ4/H3WybOXjwoH8M0Pg89RQPvONPQzQaTzFlqumn945OIV+k0RidRIO5RRwCojuPUbSmLiKZ6IZjNDXBzDqVYptsL6SaaKLSW9oGppNPVVFb1yFi5zesZzmjdr3rj7cz5Pjf/7qv0usN+/ap6achHxM6ehR27epvKzrFV6H4ApjpT0M0Go/JzATgw0OjeUpeT/BVP2ojFIGx7j0KF40xI4izFlOQ52QRG5q31xDFyIlt+8s27Dna5u+MnW8DNE9dadpSX++/9SdVVXDMWB5TUuKfMQcst92m5kUHIL4Kxa3A1UKIHwshEoQQpvYvP9qo0bTl7LPJO+48iknm0wW/JePP19NkbvEigmLCuh3CljCCYJqo+mQLiZTRRBCghMIcHwNAQ+pYABwHDrc5d+Lh9wAIqB3qX3F9o64Oqv1UKmtfqxVTQ14ocnOhcGCWsfP1gX4QmIYKaBcDtnYvq1+s02g649RTMa19g5AQwR13qE2NgcqLqCOM4FAPPtZJatGd+S01R/J24AWAEoqAeOVR1J5+kTr2cCuhyM4mtWoPAIF1VR2GLSqCf/3L2zc0tPCnR9H4wqus4ufcxBNeC8WsWbOYNWuWfwzpCwoLVffGAZji5Wsw+wFUbwiNpl9ITVVz1iEh6m9roPIoLEQQHNz9+QFpatFd6jevUkEs28ZcxEUHXqaGKIJGq74XnHY65c8+TWBuK6EwVtnZCCC4vqNH8eKLcMcdcPbZas3GcGRU3T7qHcE4nWO8Cj53xqLnfsJy6rAQzgsl3kXHH3vssZ5dvC+x21tcprKyVs1UBga+9qO43892aDRe4xIJAFuQ8igsRDAixM0JrQgepTyKhNps/hV8M9UZM+AA1BKF+fjjYMcOwsbOZA/jSC5sJRTbtlEekESpPZaQxqoO47qmXAoKhqdQ2GzwjP1KKonFYvmQqKjuz3FLUxPBtjrqTeFEOOuoLKhHdRkYghQXgzS+e5eUDDih6MmCu5FCiEeEEJuFEEeEEJuEEH8RQozwp4EajSfYgrzzKMLGqI+plUA+m3MHjSNHU0IixwLSECYBM2cSHg5HxDiiig/xj3+AxQIcOMCRgIlUEktoY0ePosYoF1VQ0GHXsKC+HlIpYDL7eh6nMNKciqInAdCQ6137gMsvv5zLB2hwuAOtYxOt59hqauCee8Dav7P5vi64mwDsRHWes6D6aNcBvwB2CCHG+81CjcYDbMGuGEU4AR74ydGj46gimue5mhVXpRMZbWIO23gy8q7mY4SAQ6EziavJ4c+/KOLvfwcOHuSgnKCEwlrVYdzWHsVwpL5ONZIaRR7Vx3q4ItEQiqoRSijsBd5lmeXn55PvWnY/0GktFMWt3uc778Af/wjffNPxnD7EV4/iYaAamCClXC6lvFRKuRyYYGx/2F8GajSeYA9WHkWDqfvUWICEJBOz2c7tAf/gggsgKgoKSEOGtp3a2BanVn+fzCf854kqKCnhe+tEqoghwqYeZFKqvhW1tVBb7SSJ4oGavNLrNB6rIhC1lL1p39Fuju4aR2kFADUjJqoNQzjtyZHnxqNwJVJ0883jt7+F885TmtLY6H/7fBWK5cC9Usrs1hullDnA/cZ+jabPcIQqgag3eyYU8fGQzWiWnx5MfDxERqrtIe3iG0XJsyglgTMDPia6VPWv2G94FBH2KgCOHIErr1QLzZbs+zdHGUN5Vg3DEWt+y0POeeBQj8ZqOqaE2JKqhMJcPjSFwmaDx+8qwilMqnJlSQlvv620odLomVLxvXuhkBIefxw+/hgeeUT1bfE3vgpFELi60Heg1tiv0fQZzlDlUTR6KBSBgfC3v6lyE0Bz0DU0tO1x0bEmPuYUzgz6mKXJBwA4yASqiCHSUQVSNn8BLC2FaSWfEk69Uo9hiL2w5WFuPtozobAWK6FoyFBTT8HVXQtFP0/jN1NVBePGNbdM6ZayMoiqK6Q8IBmSk3EeK+H88+Hhh6Fxt/Iocja4n0IrKoKn637EJyf9iYIC78qceIqvQ+4Abm6/sM5oLHSDsV+j6TNc7U+bArov3+HitttgplFfwCUU7T2K2Fj4mFOIrj/GFQGv4MDEEcbSEBJLAA6wWCgvV8dWVMDU2u8ACC7M6tH7Gaw4j7U8zIPyDndxZPfYSoxkgdRUmoIiiGwscSsGxcXq3/Drr1u2LVy4kIULF/bIBl/IylLfEz79FCq2ZbPrp090eXxZGaRQSI4tBWtMEtb8YhwOVc0j8pi6h/UH3XsUBw/C6awjVeYT1ktJYT1ZR/EusE8I8SpQBIwALgLGAyv9Y55G4xkyTAlEU6BnHkV73AlFTAys5Syc0THMKniPw4zFRhAiJgaOAZWVVFSoeStnXgEpdtXcIrJseAqFLFWZSVlkElHYM4/CFaMITIyhMSqJ5LJiSkvVGpr2lJRAU5N6aC5Zorb9+c9/7tH1AXjrLfXEvvdej09xJTTs3w+5r9zHrF3/4fAVFzBuaef50i6hyCOdBLudJENsc3dWEtGkvoUElRawY4fyWk85pe35WbvrWEYlYnK612/PU3zyKKSU64CzUNNMvwWeBO5BZUCdJaX8yG8WajQeIMMNjyLIv0Jx0kmw9PxETE+r5dYHUPPlpvhYdUBVFeWlTjLJIvlIS82oEY1Z1NX5ZEq/UFXln+oRplL1kPuWhcSU9UwonOWVVBNFRLQZR1wSSZS4jWc7HOqnxdKjS3bk6adR6W6e40qRzttby6Q9awDY+F/398IlFKWBKeyvTG6+h3FVavqy0hTHSFnA/PlwwQWqim5rSrepLyfR0waYUIASCynlPCASSAcipZTzpZQf+s06jcZDXEJhC/R86qk17oLZl1wCa9YAP/whTX98hCe4BYDg5BgAnJ98ytV/GEMWY7h+67U0EcThoMmMJmtQZT7ddZdaTd5TzOUllBPHPiYTU5vPSfMtPmd2yspKKohTLdCTlFC4u6euniG1rSKnF1xwARdccIFvFzewfb9Ppel6UFZj0yaVpOTyKCbtWUOIox6ArI8P8913amF/+/4mFcU2kiglOGMkRy1JBFYWcyWrOQtVnbh08lJGUoRw2KmthZwcdd7TTyvvqWaPEgpTxgAUChdSynopZYGUst4fBmk0viBj1Df8htA4n85351G0Jvg3t5Mz6TQAQlPU9cTDDxNSX8FfuINQh4WtzKUsbiKZZA+qtRQlJf7JPg2sLKGEJPZHzgfAvPlb3nvPt7FMlRVUEkt4OISMUkLheki2x+VRtBaK8vJyyl0BJC84eBDmzIGSnAbMedlqY1lZl+dUVsLJJ6u1cZZKG09wE79vuIPDjMVKIAHZhzjhBNU4a/r0tk2v6nPUdF3Y6GSy6pMw25pYzdXcz+8BEEuXYsbJu8+q9RWuSuTvv6+WVxzbbPTyTR/AQqHRDAQcCcmcxKd8lXapT+d7IhSgHiAAkekxAIiSYg7ELeLX/IWFfMc1PIc9fTSZZJOXK9XE+csvqzZtrubcA5CmJv/k3wdVK6HIG7UYO2aWsZ49e3wby1xTqdKQIyA0M5lESsk+6uz0WIfVwYPcg7Ok6wd6V3zzjUpI2LIFtm+H79ccxGSUtJPFXavok08qkSopgYjvv+UmnmQ7s7mc/1KXNIYJHGLJEpVlt38/fP89HDoEe/eCtcAQiswkjklVWuYDTqfMlEgu6SQuUuuXF2cWIESLUOzdq36mSCMjqrPgjZ/wOJgthHAAC6WUm4QQTrouCiillL4GyjUarwkOhs85iZU+Zn24S49tzzXXQEQEBCbFNm/bGXo8AJs5DoCQKaMJ31zPy4+XcJllLaYbf64ObGpSK6IGII2N/hGK0JoSSplCdGoEm/ccxzLWs3qvb2MFWCqpZArTI0AkJxGAg7KDFUBCh2PDd3zDPfyR7R/txJeeana7ikfdey8kGMNXfbe/eX99dgnhszo/t74eXPUHKyogXm4E4DJepIxEwmaOZ2XuYc76ELKzldexdy/UPfA3HFYHzgmz1XsYnch7TGNV2p/4U90vOH3WMfK2l/HhVNVFMWzb1/wwxcquXUtobIQJh9/nV0EfIKyNNEQlEepJ7Rof8eZh/gCQ3+p3XT1WM2Bw/R/x9f9KcLBaW9GdR7FihXr99/+icSIwIdkkFrQ5JmDcaAAqtmVxOGIrE+LisESMoOLdXVRdDDNm+GZjb+IvjyKsroRy8zLi4mA9y/gVj1B0uI6GhvBuRbg9QXUqRhEeDiQlAVB7pITOhMIarIJMKZW7fbK7tlatwygpUZ8DgMpWQmHJLsVd9GvbNlUdPClJTUGNqN1IlmkMdcGJjIiG4Gnj4ZvPIFAyZowgOEiS/2UWv866iywxljWx9wEQMyGJSuL4VfndjBoFv3xiDEVFYyDV8GZuv51nA6KYu7OSAwdMXCxf5grrf8kOn9Kr8QnwQiiklL9v9fv9vWKNRuMjLoHo7kHfFb/8ZcfUQ3eEhpuoIYoYqvmycT5CtBT/NBtCsTwjC+vWXVhnzeStb0ayJPdrrrgCdu703cbeYnnBfzndvh+H4w+YzT4OYrcT3lBOVUgSMTFKKO7mIRbxDQcOnIpXrSGkJKS+gipilcAkqykZe/4xYEqHw502FaRIrs9u3rZixQqPL+eKbVRVKY8RICJvHxXEEkcljTnup55yc2EJXzF1QhwvbZ9MhtzIN2EnMGMqjBgBjB+v3I4DBwh49FGKHG+Q/98MArEzUhbQmKvGTpiUCKj4RWIiTJ2qXjgT1Ae7qYlwew2mQwfYsmUyk1AlUjLr9sLYH3j8Xn3B16KAR4UQnbZCFUJME0L0rMhL2/EmCiF2tHrVCCFu9df4mqGBSyB64n0//LAKSHpCaChUEktD+niOVMW3iSMGTxkLoaGsjPmGMXXfU5g0k13MIINcig9UtUlv3LxZTXu5C9L2FUvL13IlL9DU1INBjMBxjSEUG1iEU5hYxIbm+XSPaWggwGGlLihWrTQeNQqA6JrcNgFrF06rvcO2e++9l3s9XP/gGrO6GhrLLNzJwyxgI99xPDYCsBW6r1xbt3E3X7GU//f1NN6pW058fT4Hohfw5pvw7LOoZdoA8+fDs89SET2G6bZtlJBIJBYSao7gEGYSJ8Q2i3RCa6fJZFL1YdauBWAem3n+eRhNq7U6vRjIBt+D2ZmAu/+SIUCGj+N2QEp5QEo5S0o5C5gL1ANr/TW+ZmjQ06knbwkNVSu280+8nIYGmDChZV9UUggsW8b8g/8hjAbWVyihAJjQtKtNiue334KttoEvv+wbu90RYrcQSW3Ppp+M5ta1YcnExICFSKzjprCATd4HtI3KsXXBRhZbejpSCDLJJju74+HS1koofKjl0dqjmLbzRR7mLkaTzTbmUEZCczD7pZfg9ksL4YQTlCsB2A6qB/bB4y7jRNQ/ZFbSAkaMUDXFmDIFzGbVY+Lrr3n5l5uYym7u4BEAZrGDurBEzIEm5YGgPIo2nHUWnHUWMiKCZeGb2fpNAykUqRLHxv3pTXqS9eQuRjEPqOrBuF2xAjhiFB/UaJrxx9STN4SGws94mi9OVPPL41sV1o+KAk4/naAGtfLq+a0zOJaohOIs3qXxwb/y/VYrFgsEf/YB1UST9Xl23xjuhhCHIRQNPQg9GgpYE5HCZZfBqlUQvGQ+x5s3sWe3l+NWqFXZTWFG0kBQENbEVLdC0cajMOpsnXHGGZxxxhkeXa622sl+JnLSkX8zNv8LChnJDHayZuJvKSEJUV6KlPC730HDq2+rWiFffAGAI1+9731XPsRzXE0lMZSkzGoZPDVVpSpt3w4LFzJ1KuxlKlHT1ffpmeykMTKx+VDoRCgAzGbE3Ln8YOQmMjFuwqmnqp8DRSiEEL8UQuQKIXJRIvGO6+9Wr1LUKu11vWTvJcDLvTS2ZhDTHx4FgKvdgUsozGZjn/GAsmNmo2UKSbNScMTEcSd/ZdzTd7JqwWoeeQTmbXicIGw0frejbwx3Q5jDghknTZU9WA5lCEVtZAppafDzn4NYMJ9YRznyqJclTQyPwhrekl0mRmeSSTZZnQzVxqM4oIo3NjQ0cOxYAxs3dn+5hpJaJnKQC0ueZGrZenbFLuN7ZjBrYShlJBJYWcLXX6sFdSdIJRAuQQooLsSJIGzMCK7lGcZwlLC4dt9YpkzBVYhpihFiST9eqUIUtdhiVbDe1RWxU6EAOO44YnN38LuL1Xvkl7+E66/3PLjmI954FEeBT42XALa0+tv1WgP8Evipf80EIUQQcA7wPzf7rxNCbBFCbCkt9a4TlmbwM1CEIjramA0YNw7GjCEreBJNhDBjpsA0ZzaNBJMTOI47HX+m4IvDzC41qt0cOdy8aKw/CHOq2he28h6URy8qAqAxplWTywUqI2xUkQdP69YYC9yaIuKbNwWOz2S06F4oHPsPNi8ePHAAbvag1barUu1U204SrEUcTT+Rhx5SYlcdnERobQnPPw8gORFDKI4eRUoIqSzCEpZEbGIAEhNVxHbZAnb8eLUS/gc3tqx7kPEeeBQA8+cjrFYuCVSlQZg5E556ypjj6j28yXp6C3gLQBWJ5UEppd+C1h5wBrBNStlpmysp5dPA0wDz5s3TqbvDDH8Es72hvVCMGqXSKpsfEELA00/z6oMSvlApseLaJ7n8tFqacop4h3N48MsTAagnlFHWwxw6BJMm+dHIXbtUg4LnnqO7tn/hUk3S2ypqAR/7NRcWUmmOJzCi1T/C1KlYA0KZWL0J8GIxpEt0YltsEZmZpMqXKSm00/7R1Voo9r2xn4V/VBlDMQ2FzN7xPA7H1V1mczVXqjXIyljGX3+tfj8QnkR4TSlvvAE/mHaElN3KNtuBI5QXQ6K9kIbkFOJaFQWIjnZ/LZMJVL3CUOqCYwlvqsQ0wkOPYsUK1XDi5ZfVh9DIButtfC0KeHUfiwSoT5medtJ0Sn/EKKCl8Vh8vHq1eUCsWIHpVJVGNWMGMHEi1hnzeJezeJB72OucyF+4k+KkGYzjMFu3qhTb3b4tBejIu+/Cf/5Dp1/BW+F0QgTKo7BXumsz4wGFhRSbU9S6BxeBgZSkzGKafTv13sxqFRXhwIQ9ttUTMzNTlXbvpL2ptKpaTHmkkbznMywWSW4ujCKPe233cuhg198dneVKKGqIpIAUGtJbshMaoxIJt9fQUN3EzyYrb6IgYxGVW49y2mmqoJ+znVB05VG0piFOuRABKep9pqWp7W6FIi5OtbJzOCAzsyWY3cv4mh77ayFEp0XWhRD/EELc0TOzOowZBpwCvOHPcTVDh/6aenIFVuPj1f/h9g+Iq66CBx9U9X3AlSkp+GDhg6zgM+7mIYImj2UcR9i1S8VIp09XabNtePhh+OAD74x0pVd1U3Sqqd5BGKr4kKOyZ1NPxxjZoSdCU3IGaeTj1YxwURFl5mTCIlu5AZmZAIQcy+5wuDQq7b3GD0msz2EO26gsOZULaCSNArLf+b7Ly8kKJRSX8SJn8AHRMS0PYFuM+rafSCkLit/hmBjBNzFnkuQ4xuFddaRQiDk9haiolqZBXXkUrYmcpIQiYbK6xvnnq251rj4pnfKTn6ifY8Z4dhE/4GvW09XALjf7dhj7/YZReDBeSlntz3E1Q4cRI2DhQpg3r2+u5xIKiwUmT1aezMqVHWOKKSmqZIPrAeJKqb/llpZjQqaNI51cSvObmlsk79oFlmoHBUcawWpF3ncftv/3jFt7ioub478cOWKUojamb7oVioqWeujOat88iuxssBwqpECmdBAKmZJKKgWUlngxI1xUxDExsnnxG9AsFFEV2R2PN6ae1nABdsyczxtMcpxB8zfWdV2LrKhWN28nM/meGW0f9MbX+8XiW2K+eZd3467ko8NjAZjAQZIoIWzsSEwm1egKPPcogkcroTAlq2tERKjPRpdd6lasgLlzYelSzy7iB3wVilGAuwLrR/HjOgqNxhNCQmDDhubYaa9jMrX0Jj5elXriL3/pvr/NJZeo4y66SJV8EAKi5ozDjBOZle1aisChQ7Bxxd1YJ05D7t6DsFrJ/ya30zEdDlVu+sYbVWObSZPglVfwWCisFS1NHGRNLeedp6bAveGF550EVx4j29ZRKMyjUgilkarsKs8HLCqi0Dmy7TRWejpOBHE12c2r4JvtNoSimGTWs4wLWMNk9gFQY4omdWfXQmE2hKIS9aRvLRRVkxdSQSz/4XKEw8GGKdeys04JxfUzvsWEJGycCi64pp889Siao9dGiRKPMJlU5cI77/T8nB7iq1DUA+5KFaYBPVnfqdEMClxehUsoPCEuDu64Q6XRzpyp5qQDJ6mHTmjh4WahOHLAzuydqxntOELR318BILIip8MDkupqqmYtI+zwTvLz1Zo3u92oLOqaeupkTr81tsrWQlHDO+80LxHwGFlaRiB2imj3cAeCx6hHRcNhz+uuy6Ii8p3tPIqgICwxaWQ6jzQ3B2rGmHqyE8AaLmASB9jFL1gGfDPhGiZVfEOnS7oNAi2V2DFjQV2wtUcQkpHMVawmSFrhpJMImDSOo6hpn59M/AoAU5oSCm89CjKM79QjfUwg6CN8FYqvgDuEEG1mhI2/bzf2azRDGpdQ+OrFPPQQ/PvfNM9HrSx6hvmfP8QNPEnSlveJs6tJ/ZjXngYgQZayZ0tD20E2biR+9xfcyJNUVamVxQA52dJjj6K1UDgqa3E4WqaxPCWoTIlSIR09ioiJSiis2R52crLboaSEItoJBVCbNpnJ7OsQ73B5FHYCeJMfIIUggTIIDaXpxFMJxM6fL9jiWsfX0f66SqpFLCrzv61HEB8P73AOr13+NjzzDOnpUEEcloBoAr5arw5K8dGjuPRS1RmrD+MNvuCrUNyP6o19UAjxRyHEDUKIPwIHje33+ck+jWbAEhoK4eFG4TYfmDMHTjsNSEykLH4CK61vctn3d/MkN/Fo/kXUEEkRIwizVjWfs/kNo6dFdTXU11P1lQrSns8bWCptzUJReaSipZRFN0Jhr2oRCnuF+qrurVAEVyhRKuokmB05QT1EZRd2yFa69unLJQgpO/VOrGMnM4n9lJW060vRyqM4xkgqJi5S28PCOP0+1USp7tPvuOYaOnplQEhDBXVBLYv7Wj/oXbNCEZeeDaNHG4ugBbtnXtZctsTlEbiEwmOPIixMRbAHOL6mx+4ElgM5wK+Bfxo/s4Blxn6NZkgTGQnHHdftEoXuEYI3HtxLCA3EhzVwGS9ixsEbnM8XppMA2B84DYDDn+fCiy8i09KwX/dzLN+pXNoEyplZ/lmzUDRlG0/d8PBuhcJR1TIl4zCC2d4KRVhVi0fRfu2XSFVCEXDMvR3r16tpuKwsWPd8i+i09yjElClEUIdlX7smUHaVHms31lfUnW60QA0LIyQlDiZO5KpJ3/HWW/Dy/9ngu+/a2t9USWNY50Jx8snwzDOGqNMcU+fYLx6C0aNVzMBQE689ikFCT3pmb5JSLkX1zE5D9cxeJqXc4jfrNJoBzP/7f/DPf/pnrOQUM02EUFEfwu4ZP2IS+7kt8J9UzlwGwK7R5wIwatubcPnlWOtsNL7+LoH7dvIlJ9AQFMXZDa9SXWDhbc5mbvH7auA5c9RX9S6WfTtrWjwKampZzmcElXrXxzW8Vj3c13w9gnPPbbczJIRKczzB5e6nnvLyVKbW4cMgjqmxCknpIBTBs1X9C+fuduVoW009AQT/6AL1AHc9sY8/nrFl3zF9mqT4vidVipxRggMgwlpJU1hsc+/01g/6wECVkepasLd0KbzwAqy8JBLeeks1rza+LaSlKU/TNc5QwR89sxuklIVSyobuj9Zohg4LF/o+7dSe1rHME06AI4wjc1oE9pXn8ibnUnDmdUgh+JHtBaQQ3CkfJqKpguSC7ewOnkfWjHM5j7XEf/YaZ/Mud8iH1WDz5imRKO60oAHQIhS1RBBoqeR9zuTK4oe9sj/ScoyagFjmLQ5uzgZrTUVIChHV7sWnvh4CsTL32ln8+OjvADqdeoqcPxmAkH3bVPqYK0DtUELhNAViMkH87FH88NFH+eH116v9CxYgSko4fVI2xx0zOuBt2NAyrqMSa3gsMTHq766mjkwm+PGPjQZH06e3rGtAZZ5t3uwHL3OA4dPbEUJ81s0hUkrpedcQjWaYM6JVeaS5c9U30jlzYNLSJE7lTd4+CWwvpRBZUkBOwjxeK/0hj3MrAJWp0yhcksyULf/hzC/uAiAeFbW9/ZXj+Buo6SdXfYh2yFolFIWkkFKznxCaSGnMQkrPF/5GNpRQHZyEu+drTWQqMZXuPYq6OriQ14nL3YlrgXMxyc1ZRC7CR8VTTBILPvszfFjHnQ/FEXLTtZxoeBQRMQFEhagH9Q2/+EXLiUZq2rLad5hvNXJtNm6EK65ASoh2VlIaEUtMsEoS89UjiIjw35eHgYSvHoUJlR7Q+pUALAYm4Eod0Gg0HtG6ZE9KCnz4oVrRvWIFvPkmnHkmBIxRzXv+V3MaxxjJbtQTyT55OvWLT6GCWKKtpeQbmevVRLG+yChF0VWcwqKEooiRjGo6CMAocrrKJu1AdFMxNaHu6w7Vx6aSYHVvQ10d3MiTVESMooZI6sISeP2tIObObXucEHA0eDLBNrVIcGLltxw4AMLwKMKiApr1sL6+nnpX3ZAZM2DqVE775FcEYcMRHYurrGy9xUkMVTiiY4mOViLR5YK3YYivwexlUsrl7V4zUD0KK4E/+dVKjWaIExzcEgh1rTIfOVI9sM49V82PmzKUULzVdFpz4yQbAYQfN4XoxCDWch4AD45cBagHfz6qeJD9aK777nUWC00EUU48ZlQ2UQY5XgW046zFWMLdC4U9MYUkWYytoWMnOoCo7F0sZgMvJf6CK3mB3Svv4pxzOvdociKnY8fMbjGNpQEbVMKT3Y4TQWq6qbmw4plnnsmZZ56p/jCb4emnMTtsVBHNsTN/Ajt2QEMDlqJa9b5j1NTTUAtE+wO/6qaU8gjwEPBXf46r0QwHXNNPraeh2jBrFlVhI/mO41m6FJ5KuI9lrGf0tHBiYuAB7uMGnmTvmLPZGTCHLEZz8U1JFJPEq7/e1jHIbCDqLFiIwELLfEs0NdTkVnlse7yjmPpI90Ih09Iw46R4R1Hn5+duB+C50rN5k/Mo/fHtbsdaO/UeTuQLtk38EePt+wmuqwCHHTsBvPFGFwkGixZx7Bd/5k/8hqzUxSqldvt26guUIoq4WM44Q9Xc07SlNxysUtT0k0aj8YIRI5QH0aZfcmvuuIPXHjyInUBmz4Yxc2PZwGImToSYGMglg6e4gZhYwQNz3uLv057lD38U7I+azwKxkc8+o6WC6zvvwOrVAJjqlVA0BreNMDQe8LCRZFMTMbKKxij3QpFx4mgAdqztvJJtUI3qP3HYosboqqJFYFoyG1jMyAvUWolxZd9hstuwE0BCQtceQfDv7uKv3MmecGOV5MaNNBYpoTAnxHLDDaoon6YtfhUKIUQccBtwpLtjNRpNW9LTVXzCbd8Es5m5J6p80QUL1CskRC3sdmXrgPr90dfSePZ9VdH0xDsWMM62n1BbdUu3t3vugQceAMDUoITCHqI8imojJG0/4plQuPpJW2PdP90zT1Irj49+0nl3guDaUqwEUmt4NV21WUhPV+vUjr/5OOyYmVT+DdjtzamxXRETo87dXz2SmthRWD7d2Ny0KCAxtuuThzG+lhnPEkIcbffKB4pRfa3v8auVGs0w4IEHYO3aro+ZO1elX557rqoJt3WrEovIyJb5/JgYVUKouY3yfLUy+Ti28NVXQHm5Kk+bnw9OJwENtdQSiSNMPaS/xKhKmuuZUDTlqtRbe5z7p7vIGIVTmKj7/iiNjR33h9WVUkoirjyYroTirrtg2zaITA7jWMhokuuPIhx27CKwW1uFUGsdPvgA1lUuwPr1RuwlKkMsaIQWCnf4mu37BapvdmsaUSu1/2fEKjQajReMGqVe3eEqpR4e3tJ/2bW2rKqqrXfR+oRzR27irS9XwAwjPdRmg+JiAhoNjyJMeRI7Ao9jhe1TAgs8FIq8EkIAR0IXT/fAQBqTRpFefJT16+H009vujqh3CYVaw9BVA6ro6JbpJas5BLPDinDYcbR7nF111VWdnp+eDp9+ChtZwA+r/0ftJ69QTyjBU8Z1/UaHMT4JhZTyKj/bodFoekhMjBuhiIuD8eM50bGRX28Ax+T1NM9u5eUR2GShwZSAPVR5FFVxY8ktHkVIsWdCYctXHoVM6rotZ9DE0YwpPspXOzsRiqYyig2h8Ka7p8MURIDDinTYsQvPhMLVRW4jKk6RsWUNa8SFnDMtotPjNb0TzNZoNP2ASyA6CAXA0qVMKvoce4MV6ydftESLc3MJbLJQb46gPkI9qEtiJlAYkEFEZ2XNO8FZpITC1ffZHeZxYxjD0U7TbqOtpVhCVBTfK6EwBymPwmnH0U4oysrKKCsr63COSyj2hczBbkjmhvSL1UprTad4LBRCiM+8eH3am0ZrNJqOdCkU55xDUEMNP+b/CDmwEy67TG3PyyPIaqExIIL9aadwGuvITZpHUdhY4soOEhvlYM+erq8rjxVjIZyQ+PAujxNjxzCCYupL6zrsi7WXYo9RQuVNDx+7OQiz06amntoJxYUXXsiFF17Y4RxXRe+Lrw5jJzOxEE75gjM9v+gwxBuPov1q7EnAMiATCDV+LgMmoldmazR9TpdCcfLJOENCeYKbcZoC4LbbVPpPXh7BNgtNAREEh5n5iNOIiBTsj19MlLOa0ZZdblt1W62qlbetoJhikjuUF++A8YQOLMjuMFCUsxqR5P3Uk9MchNlpxeSwdRAKd/zoR/DNN3DBBfA7fs+NPMnE2d0ZP7zxWChar8YGHgdswPFSyjFSyoVSyjHAQmO7zkTWaPqYLoUiLAxxyimE0sj2KZer+ZdRo2DLFkLsdVQHJzUHkCMi4HDqiQAsYz1ff9359V57TWUgVR9QQtG+gF8HDKEIL26XIuuaHkpM5OyzVVlvT3GYAwl0WjF14lG4IyQEFi2CCRPgPc7i/7iS6dM9v+ZwxNcYxYPAvVLKTa03Sik3opoa/aGHdmk0Gi/pUigAccnFWAni5bQ71Ib0dFS+LGyKObWNUDhGpnGIcZwT/hknf3gHzvdauRVFRbBlC68/pdrMRVXlcIwRHnsU0eVthUKWKqGwxyTw9tve9fFxmoMIcLpiFN4FGVJTW7Krpk3z6tRhh69CMR61ArszSgCdZ6bR9DHdCQWXXsoPTyhiQ6Uq1e1aaFEakkZOzMw2QjFjBuyMW87yune5qfER6h/6R8s4S5fCccfx/IYJLOIb0puO8Ckruvco4uNpMocSW5vbZrO1QD1KnPGJHr9XF86AIAKk4VGYvEviNJlg/Hi1BsXVulrTOb6uo8gCfgZ0Nnv5MyDbV4M0Go1vrFyp1tC1L83djBDEjYtj0zrjb2PRxrdxZxESKtoIxT33gDNzGVzxb5oIwvHNd0wY5+Tlx0uYe/gw+yefx6R9a3nF9COcTsEaLuDe7oRCCCojR5FQ31YomgpKCcZ3oQiUVkydZD39/Oc/7/b8U0+FwkLPy6kPV3wVit8DLwohdgOvo1ZkJwMXooLcl/nHPI1G4ynz5rUsxnNHRoaaObrlFpixdRTXAl9EnU1wsKpgCzR3lTNdeD6y7DEe/qOJ+8puIb3hAA+ec5g3gdVxt3FBWDnH1X/J5yyj2JOpJ6A2ZhQjqnLb9LqwFyqPwpTcM6FwtvMoLr744m7Pf+QRry85LPG1zPgrwGlANXA38KTxswo4TUr5qr8MBBBCxAghXhdC7BdC7BNCLPTn+BrNcMHV7/mJJ+ChA+fBX//KlyEqPtHaowAgJARx6y+440MVXX79tm+Z49yMU5h4O2826+fcBsCrqAeyJ0LRkDiKdHKpa5Uh6yguw4kgICnO/YluaCMU7TyKvLw88vLy3Jyp8QafG/ZJKT8BPhFCmFBNi8qklE6/WdaWx4F1UsoLhRBBgM5l02h8oPVc/JHyGCzX/4r655U34RKK9t3dQmep8rSxB75jaWge2eap7MsNx/6zc/h/Cet49s2TCAryrP2ndeQoRnKM/OImIiKUCyNLSqkgjtAId9UQ3SMDXUJhw2kKbbPviiuuAGD9+vVej6tpiz96ZjullCW9JRJCiChgKfCscT2rlLKqN66l0Qx1XELh6uCWlQWNjXTuUbgwmVQr0c8/Z45jM59bVJHBGTMFNQtPw05g94FsA5mqAuiWgy3d7kRpCaUkejxGa5yBQQRhxez0Ppit8RyfhUIIMVII8YgQYrMQ4ogQYpMQ4i9CCHdtV3xlDCrD6nkhxHYhxDNCiA4fKSHEdUKILUKILaWl7hKyNJrhTXq6qkB7u9EXKCsLmpraehQdhALgqqvg6FGirOVs4jhAZUaNHKl2ezLtBGDKVAF066GWgHbgsVzySPdJKDCEQsUodA2O3sLXMuMTgB3ALYAF2ATUAb8AdgghxvvLQNT02BzgKSnlbOM6d7U/SEr5tJRynpRyXmKi90ExjWY4EBAAW7aoEuXgoUcBcPHF8NVXlJ58KW/yA2Jj1Zo9l1B4+pAPGqeEwn60RShCinPIIcMnoZCBQQRhM6aetEfRW/jqUTwM1AATjNXalxortiegAtwP+8tAIB/INxbzgcqymuPH8TWaYUd8vBKEo0eVRxESArNmKW/D1XO6A4sWEf7WS5Sbk5kxQ2UteSsU4RNVRT6RbwSZGxoIqS4hhwyPvZLWyKAgAIIcDVooehFf7+xy4HopZXbrjVLKHCHE/cCqHtrVesxjQog8IcREKeUBVGOkvf4aX6MZjggBo0croWhsVFNPY8Yob6MrwsLghhtg9mz1d0pKy3ZPiB4RSjFJBBQaHkWu+umrR0GgEopgZwNOc9vH2e23u++7rfEOX4UiCKh1s6/W2O9Pbkat2wgCjgJX+3l8jWbYMWYMrFsHdntLAyRP+EerRdoxMUpkPH3IR0fDDtKJLjWEIkf1vPBdKFRcIsRZj2znUZx99tk+DKjpDF+nnnYANxupsc0IIQRwg7Hfb0gpdxjxhxlSyh9IKTupaK/RaLxh9Gg17ZScDBdd5NsYQiivwtOHfEAA5ASMIzJvL8uXQ+OBFqEIDe3m5M4wpp5CnXUdpp4OHDjAgQMHfBhU0x5fPYoHgHeBfUKIV4EiYARwEaoO1Er/mKfRaHqL0aPVz+uvb1mV7QtPPAHe5I/sjjieC6pe5eD6AorTckgTZsqDUjF7v4wCgo2pJ6zIdlNPP/vZzwC9jsIf+NoKdZ0Q4ixUldjfovpPSGArcJaU8iP/majRaHqDFStUfb8bbujZOCu9/Fp4MGERVMFCvqXxQA7V4amEBPv2nVUEtcxyO806Pba36MnK7HXAOiFEGBALVEop6/1mmUaj6VWmToUvvuj76xaPnEXD4RBOCPgWU0EupeEZhPvo0YjgFqFo71Fo/IfXMQohRJAQYq0QYimAlLJeSlmgRUKj0XjCeRcHUZI+jxUhG4gsz6Eo0MdANjTHKEALRW/itVBIKa3Ayb6cq9FoNDfeCBmXLGRy3WaSmnLZXJrJccf5NpYI0ULRF/h6Z78BjgfW+88UjUYzbDj/fGqfe4NXy1fwWNP1rPKiq11rTF1MPd1zzz09sVDTCl+F4nbgTSGEBXgTlfUkWx/Qi5VkNRrNYOf449n44mGuP10t1jv1VN+GaROjaFe+9mRvmm9rusTX6aPvgbGo8t85gBWwtXpZ/WKdRqMZskydqn6efjq+raEATK2mnmjnUezYsYMdO3b4NrCmDT1ZRyG7PUqj0WjckJoKv/wlXHKJ72O0FgoZ0DY99tZbbwX0Ogp/4Os6ivv9bIdGoxlmCAGPPtqzMcwhLeKgg9m9R4/urNFUaBqQChQAu6WUNf4wTKPRaLqjzdSTJy32ND7h850VQtyHCmpHoFZmA9QKIf4qpfyDP4zTaDSarjCHaqHoC3y6s0KI3wP3As8ArwDFQDJwKfB7IUSAnp7SaDS9jfYo+gZf7+xPgb9JKe9otW0P8JkQohq4Dri/h7ZpNBpNl3TlUfzpT3/qY2uGLr4KRTTwoZt964Cf+ziuRqPReExXQrFo0aI+tmbo4us6io2Au0X3xxn7NRqNplcJCGslFIFt02M3bNjAhg0b+tiioYmvHsUtwFohhB34Hy0xih8C1wDntm5qpFdpazSa3qArj+I3v/kNoNdR+ANfhWKX8fMh49UagVq57UL24DoajUbjlsAQM04EJiQiUD9megu9Mluj0QxaAgIFVoIIoUlnPfUiemW2RqMZtAQG0iwU2qPoPXRPCY1GM2gJCFBCAWih6EX0ndVoNIOWwECwoLKd2gvFY4891g8WDU20UGg0mkFLG48iqG167KxZs/rBoqGJnnrSaDSDFrPZ/dTTJ598wieffNIfZg05BoVHIYTIBmoBB2CXUs7rX4s0Gs1AQAiwGUJBO6H4wx9UbVLd6a7nDAqhMFgupSzrbyM0Gs3AwiaCQIJJB7N7DY/vrBDCiedrJ6SUUv+raTSaXsclFDrrqffw5s725yI7CXwkhJDAv6SUT7c/QAhxHapqLaNGjepj8zQaTX9hMwWBE0zBWih6C4/vbD8vslsspSwUQiQBHwsh9kspv2x9gCEeTwPMmzdPrxrXaIYJdpOKUeipp95jUNxZKWWh8bNECLEWmA982fVZGo1mOGAXnafH/utf/+oPc4YkA14ohBDhgElKWWv8fipqGkyj0WhaPIqgto+ziRMn9oc5QxJvgtkOYKGUcpMHgW1/BrOTUSXNQdn7kpRynZ/G1mg0gxx3QvHOO+8AcPbZZ/e5TUMNb4PZ+a1+75M4gJTyKDCzL66l0WgGHw6zEgpzu2D23/72N0ALhT/wJpj9+1a/398r1mg0Go2XOEwqNtHeo9D4D59LeAghRgohHhFCbBZCHBFCbBJC/EUIMcKfBmo0Gk1XuDwKvY6i9/BJKIQQE4CdqJaoFmATUAf8AtghhBjvNws1Go2mC9xNPWn8h6939mGgGpgvpcx2bRRCZAAfGfvP77F1Go1G0w2OACOYHRzYzZEaX/FVKJYD17cWCQApZY4Q4n5gVQ/t0mg0Go9wGh5FQLC5zfb//Oc//WHOkMRXoQhCVXPtjFpjv0aj0fQ6peEZ5JOKObDtTHp6eno/WTT08DWYvQO4WQjR5nyhFjvcYOzXaDSaXufDjJ8xliOY2zoUvPrqq7z66qv9Y9QQw1eP4gHgXWCfEOJVoAgYAVwEjAdW+sc8jUaj6ZqAIBNWgglo9zR76qmnALj44ov7waqhhU9CIaVcJ4Q4C/gD8FtAoBbgbQXOklJ+5D8TNRqNxj2BRgy7vUeh8R8+55MZZTTWCSHCgFigUkpZ7zfLNBqNxgNcnkR7j0LjP3p8aw1x0AKh0Wj6Be1R9D4+r8zWaDSagYDLk9BC0XtoZ02j0QxqXB5F+6mn119/ve+NGaJoodBoNIMadx5FQkJC3xszRNFTTxqNZlDjzqNYvXo1q1ev7nN7hiJaKDQazaDGnUehhcJ/aKHQaDSDGp311PtoodBoNIMal1CY9NOs19DBbI1GM6i55BKIjwch+tuSoYsWCo1GM6iZNk29NL2HFgqNRjMkef/99/vbhCGDFgqNRjMkCQsL628Thgw6/KPRaIYkq1atYtUq3WzTHwwaoRBCmIUQ24UQ7/a3LRqNZuDz2muv8dprr/W3GUOCQSMUwC+Aff1thEaj0Qw3BoVQCCHSUF3znulvWzQajWa4MSiEAngMuBNw9rMdGo1GM+wY8EJhtFwtkVJu7ea464QQW4QQW0pLS/vIOo1Goxn6CCllf9vQJUKIPwNXAHYgBIgC3pBSXt7FOaVAjo+XTADKfDx3qKHvRVv0/WhB34sWhsq9yJBSJna2Y8ALRWuEEMuAX0kpz+rFa2yRUs7rrfEHE/petEXfjxb0vWhhONyLAT/1pNFoNJr+ZVCtzJZSrgfW97MZGo1GM6zQHkVHnu5vAwYQ+l60Rd+PFvS9aGHI34tBFaPQaDQaTd+jPQqNRqPRdIkWCo1Go9F0iRYKAyHE6UKIA0KIw0KIu/rbnv5ACJEthPheCLFDCLHF2BYnhPhYCHHI+Bnb33b2BkKI54QQJUKI3a22uX3vQoi7jc/KASHEaf1jde/g5l7cL4QoMD4bO4QQZ7baN5TvRboQ4nMhxD4hxB4hxC+M7cPqs6GFAlWZFngSOAOYAlwqhJjSv1b1G8ullLNa5YXfBXwqpRwPfGr8PRRZDZzeblun7934bFwCTDXOWWV8hoYKq+l4LwD+bnw2Zkkp34dhcS/swO1SysnA8cCNxnseVp8NLRSK+cBhKeVRKaUVeAU4t59tGiicC7xg/P4C8IP+M6X3kFJ+CVS02+zuvZ8LvCKlbJJSZgGHUZ+hIYGbe+GOoX4viqSU24zfa1EVrFMZZp8NLRSKVCCv1d/5xrbhhgQ+EkJsFUJcZ2xLllIWgfpPAyT1m3V9j7v3Plw/LzcJIXYZU1OuqZZhcy+EEJnAbGAjw+yzoYVCITrZNhzzhhdLKeegpuBuFEIs7W+DBijD8fPyFDAWmAUUAX8ztg+LeyGEiADWALdKKWu6OrSTbYP+fmihUOQD6a3+TgMK+8mWfkNKWWj8LAHWolzmYiHESADjZ0n/WdjnuHvvw+7zIqUsllI6pJRO4N+0TKcM+XshhAhEicSLUso3jM3D6rOhhUKxGRgvhBgthAhCBaPe7meb+hQhRLgQItL1O3AqsBt1H640DrsSeKt/LOwX3L33t4FLhBDBQojRwHhgUz/Y12e4HooG56E+GzDE74UQQgDPAvuklI+22jWsPhuDqtZTbyGltAshbgI+BMzAc1LKPf1sVl+TDKxV/y8IAF6SUq4TQmwGXhNC/ATIBS7qRxt7DSHEy8AyIEEIkQ/8DniITt67lHKPEOI1YC8qK+ZGKaWjXwzvBdzci2VCiFmoaZRs4Gcw9O8FsBjV5uB7IcQOY9tvGGafDV3CQ6PRaDRdoqeeNBqNRtMlWig0Go1G0yVaKDQajUbTJVooNBqNRtMlWig0Go1G0yVaKDSaLhBCSA9e2UKITOP3q/rbZo3G3+h1FBpN1yxs9/daYCdwf6ttTaiyFguBI31jlkbTd+h1FBqNFwghsoGvpZSX97ctGk1foaeeNBo/0NnUkxBitRAiXwgxTwixQQjRYDSzWWnsv82YtqoRQrwlhEhsN2aA0QRnvxCiSQhRKIT4mxAipI/fnmaYo4VCo+ldooD/A55B1UgqAdYIIf4GLAduBG41fn+y3bn/Be4BXgJWAn8GfgK82BeGazQudIxCo+ldIoHrjWZACCEKUTGOs4AprjpAQohpwM1CCLOU0iGEOAG4GLhSSvl/xlifCCEqgP8KIWZJKXf09ZvRDE+0R6HR9C51LpEw2G/8/KRdsbj9qC9uriqtpwNWlPcR4HoBHxn7da8QTZ+hPQqNpnepav2HlNJqVOitbHec1fjpij8kAUGAxc248X6yT6PpFi0UGs3ApBxoBE5ws3/QN8PRDB60UGg0A5N1wK+BaCnlp/1tjGZ4o4VCoxmASCnXGw2EXhdCPIrqkuYEMoEzgV9LKQ/2o4maYYQWCo1m4HI5cDNwDfBb1ArwbFQnxuL+M0sz3NArszUajUbTJTo9VqPRaDRdooVCo9FoNF2ihUKj0Wg0XaKFQqPRaDRdooVCo9FoNF2ihUKj0Wg0XaKFQqPRaDRdooVCo9FoNF3y/wH+ofwAbuwEWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# oil static.py bi lstm \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "# from keras.optimizers import sgd\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences = True  , )))\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences = True  )))\n",
    "    model.add(Bidirectional(LSTM(32 ,activation=tf.nn.swish )))\n",
    "    # model.add(Dropout(0.3))\n",
    "   # model.add(Dense(10 ))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size  , verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=2\n",
    "\tneurons=[ 8,7,6,4,2] \n",
    "\tn_epochs=1200\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2d67dd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3078440297.py, line 86)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [18]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for i in range(nb_epoch):\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# oil static.py d-lstm \n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='swish', ))   \n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=5\n",
    "\tneurons=[5,4,2] \n",
    "\tn_epochs=800\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdce0de5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (697428843.py, line 86)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [19]\u001b[0;36m\u001b[0m\n\u001b[0;31m    model.add(Dropout(0.5))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# oil static.py d-lstm \n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "#from deap import base, creator, tools, algorithms\n",
    "from keras import regularizers\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import random\n",
    "\n",
    "\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y%m')\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], X.shape[1],1 )\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='swish', batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')   \n",
    "    for i in range(nb_epoch):\n",
    "        print('Epoch:',i)\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, len(X), 1)\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataset = np.insert(dataset,[0]*look_back,0)    \n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\tdataY= np.array(dataY)        \n",
    "\tdataY = np.reshape(dataY,(dataY.shape[0],1))\n",
    "\tdataset = np.concatenate((dataX,dataY),axis=1)  \n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "# compute RMSPE\n",
    "def RMSPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += ((x[i]-y[i])/x[i])**2\n",
    "\tresult /= len(x)\n",
    "\tresult = sqrt(result)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "# compute MAPE\n",
    "def MAPE(x,y):\n",
    "\tresult=0\n",
    "\tfor i in range(len(x)):\n",
    "\t\tresult += abs((x[i]-y[i])/x[i])\n",
    "\tresult /= len(x)\n",
    "\tresult *= 100\n",
    "\treturn result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def experiment(series,look_back,neurons,n_epoch):\n",
    "\n",
    "\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\traw_values = series.values\n",
    "\t# transform data to be stationary\n",
    "\tdiff = difference(raw_values, 1)\n",
    "\t\n",
    "\n",
    "\t# create dataset x,y\n",
    "\tdataset = diff.values\n",
    "\tdataset = create_dataset(dataset,look_back)\n",
    "\n",
    "\n",
    "\t# split into train and test sets\n",
    "\ttrain_size = int(dataset.shape[0] * 0.8)\n",
    "\ttest_size = dataset.shape[0] - train_size\n",
    "\ttrain, test = dataset[0:train_size], dataset[train_size:]\n",
    "\n",
    "\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "\t\n",
    "\t\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, n_epoch, neurons)\n",
    "\t\n",
    "\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\tprint('Forecasting Training Data')   \n",
    "\tpredictions_train = list()\n",
    "\tfor i in range(len(train_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = train_scaled[i, 0:-1], train_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(raw_values)-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_train.append(yhat)\n",
    "\t\texpected = raw_values[ i+1 ] \n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance\n",
    "\trmse_train = sqrt(mean_squared_error(raw_values[1:len(train_scaled)+1], predictions_train))\n",
    "\tprint('Train RMSE: %.5f' % rmse_train)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_train = RMSPE(raw_values[1:len(train_scaled)+1],predictions_train)\n",
    "\tprint('Train RMSPE: %.5f' % RMSPE_train)\n",
    "\tMAE_train = mean_absolute_error(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAE: %.5f' % MAE_train)\n",
    "\tMAPE_train = MAPE(raw_values[1:len(train_scaled)+1], predictions_train)\n",
    "\tprint('Train MAPE: %.5f' % MAPE_train)\n",
    "\n",
    "\t# forecast the test data\n",
    "\tprint('Forecasting Testing Data')\n",
    "\tpredictions_test = list()\n",
    "\tfor i in range(len(test_scaled)):\n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions_test.append(yhat)\n",
    "\t\texpected = raw_values[len(train) + i + 1]\n",
    "\t\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "\t# report performance using RMSE\n",
    "\trmse_test = sqrt(mean_squared_error(raw_values[-len(test_scaled):], predictions_test))\n",
    "\tprint('Test RMSE: %.5f' % rmse_test)\n",
    "\t#report performance using RMSPE\n",
    "\tRMSPE_test = RMSPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test RMSPE: %.5f' % RMSPE_test)\n",
    "\tMAE_test = mean_absolute_error(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAE: %.5f' % MAE_test)\n",
    "\tMAPE_test = MAPE(raw_values[-len(test_scaled):], predictions_test)\n",
    "\tprint('Test MAPE: %.5f' % MAPE_test)\n",
    "\n",
    "\tpredictions = np.concatenate((predictions_train,predictions_test),axis=0)\n",
    "\n",
    "\t# line plot of observed vs predicted\n",
    "\tfig, ax = plt.subplots(1)\n",
    "\tax.plot(raw_values, label='original', color='blue')\n",
    "\tax.plot(predictions, label='predictions', color='red')\n",
    "\tax.axvline(x=len(train_scaled)+1,color='k', linestyle='--')\n",
    "\tax.legend(loc='upper right')\n",
    "\tax.set_xlabel('Time',fontsize = 16)\n",
    "\tax.set_ylabel('oil production '+ r'$(10^4 m^3)$',fontsize = 16)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "\t#load dataset\n",
    "\tseries = read_csv('oil_production.csv', header=0,parse_dates=[0],index_col=0, squeeze=True,date_parser=parser)\n",
    "\tlook_back=5\n",
    "\tneurons=[7,6,4,2] \n",
    "\tn_epochs=800\n",
    "\t\n",
    "\t\n",
    "\n",
    "\texperiment(series,look_back,neurons,n_epochs)\n",
    "\n",
    "\n",
    "run()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6d756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
